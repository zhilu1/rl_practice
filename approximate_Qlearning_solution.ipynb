{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload \n",
    "# %aimport rl_envs.grid_world_env\n",
    "\n",
    "%autoreload 2\n",
    "import math\n",
    "\n",
    "from agents.approx_Q_Learning import ApproxQLearningAgent\n",
    "from tools.helper import *\n",
    "import  gymnasium  as gym\n",
    "from rl_envs.new_gym_grid_world_env import GridWorldEnv\n",
    "from collections import defaultdict\n",
    "from torch.utils.tensorboard import SummaryWriter # type: ignore\n",
    "import itertools\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCOUNTED_FACTOR = 0.999\n",
    "FORBIDDEN_REWARD = -10\n",
    "HITWALL_REWARD = -10\n",
    "TARGET_REWARD = 15\n",
    "NORMAL_REWARD = -1\n",
    "\n",
    "SEED = 666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = GridWorldEnv(\n",
    "#     size=3,\n",
    "#     fixed_map=True,\n",
    "#     forbidden_grids=[(1, 1), (1, 2)],\n",
    "#     target_grids=[(2, 2)],\n",
    "#     forbidden_reward=FORBIDDEN_REWARD,\n",
    "#     hit_wall_reward=HITWALL_REWARD,\n",
    "#     target_reward=TARGET_REWARD,\n",
    "#     normal_reward=NORMAL_REWARD,\n",
    "# )\n",
    "env = GridWorldEnv(fixed_map = True, forbidden_grids=[(1,1),(1,2), (2,2),(3,1),(3,3),(4,1)], target_grids=[(3,2)], forbidden_reward=FORBIDDEN_REWARD, hit_wall_reward=HITWALL_REWARD, target_reward=TARGET_REWARD, normal_reward=NORMAL_REWARD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0/300000 ( TD_error: -11.080687917718185, reward: -14.0,0.0)\n",
      "Episode 100/300000 ( TD_error: -10.019152515903361, reward: -10.0,-28.0)\n",
      "Episode 200/300000 ( TD_error: -10.170356538652534, reward: -10.0,-27.0)\n",
      "Episode 300/300000 ( TD_error: -10.132695912817876, reward: -10.0,-24.0)\n",
      "Episode 400/300000 ( TD_error: -3.743118625424478, reward: -55.0,-10.0)\n",
      "Episode 500/300000 ( TD_error: -10.10662452094772, reward: -10.0,5.0)\n",
      "Episode 600/300000 ( TD_error: -7.176641704933494, reward: -18.0,-36.0)\n",
      "Episode 700/300000 ( TD_error: -2.953028389241632, reward: -11.0,-24.0)\n",
      "Episode 800/300000 ( TD_error: 1.075519145906107, reward: -99.0,-13.0)\n",
      "Episode 900/300000 ( TD_error: -5.5540859114656325, reward: -10.0,-12.0)\n",
      "Episode 1000/300000 ( TD_error: -0.917047412038851, reward: -25.0,-18.0)\n",
      "Episode 1100/300000 ( TD_error: -2.3055723134172, reward: -74.0,-13.0)\n",
      "Episode 1200/300000 ( TD_error: 6.9962024513018415, reward: 15.0,-10.0)\n",
      "Episode 1300/300000 ( TD_error: -3.108541950922315, reward: -50.0,-11.0)\n",
      "Episode 1400/300000 ( TD_error: -0.25970391464050024, reward: -19.0,-10.0)\n",
      "Episode 1500/300000 ( TD_error: -4.057913982439507, reward: -10.0,-20.0)\n",
      "Episode 1600/300000 ( TD_error: -2.7129737359895607, reward: -21.0,-49.0)\n",
      "Episode 1700/300000 ( TD_error: -4.1045416919960465, reward: -74.0,15.0)\n",
      "Episode 1800/300000 ( TD_error: 0.6387632750689907, reward: -13.0,-10.0)\n",
      "Episode 1900/300000 ( TD_error: -3.788938356640127, reward: -63.0,-14.0)\n",
      "Episode 2000/300000 ( TD_error: -2.8965482814193253, reward: -56.0,15.0)\n",
      "Episode 2100/300000 ( TD_error: -10.466219981700643, reward: -10.0,-11.0)\n",
      "Episode 2200/300000 ( TD_error: -4.669965495268043, reward: -46.0,-19.0)\n",
      "Episode 2300/300000 ( TD_error: -5.778497825352018, reward: -61.0,-22.0)\n",
      "Episode 2400/300000 ( TD_error: -2.9885790863265433, reward: -32.0,-32.0)\n",
      "Episode 2500/300000 ( TD_error: -3.024666842571933, reward: -35.0,-29.0)\n",
      "Episode 2600/300000 ( TD_error: 4.904214635640056, reward: 15.0,-19.0)\n",
      "Episode 2700/300000 ( TD_error: -4.70393860769598, reward: -39.0,-23.0)\n",
      "Episode 2800/300000 ( TD_error: -1.59194883386002, reward: -10.0,-24.0)\n",
      "Episode 2900/300000 ( TD_error: -5.217402475190585, reward: -10.0,-28.0)\n",
      "Episode 3000/300000 ( TD_error: -4.599182574226629, reward: -19.0,-24.0)\n",
      "Episode 3100/300000 ( TD_error: -1.556597424117709, reward: -17.0,-42.0)\n",
      "Episode 3200/300000 ( TD_error: -4.169861793370453, reward: -41.0,-22.0)\n",
      "Episode 3300/300000 ( TD_error: -4.104183514167233, reward: -44.0,-17.0)\n",
      "Episode 3400/300000 ( TD_error: 0.8365566300192757, reward: -146.0,-35.0)\n",
      "Episode 3500/300000 ( TD_error: -1.3622248060055826, reward: -37.0,-34.0)\n",
      "Episode 3600/300000 ( TD_error: 0.46189238130777177, reward: -60.0,-90.0)\n",
      "Episode 3700/300000 ( TD_error: 0.5489643870332923, reward: -41.0,-16.0)\n",
      "Episode 3800/300000 ( TD_error: 0.5438220824207729, reward: -40.0,-12.0)\n",
      "Episode 3900/300000 ( TD_error: 0.5223692049392863, reward: -85.0,-34.0)\n",
      "Episode 4000/300000 ( TD_error: -2.8097898310475404, reward: -126.0,-18.0)\n",
      "Episode 4100/300000 ( TD_error: -1.3340318194318357, reward: -13.0,-34.0)\n",
      "Episode 4200/300000 ( TD_error: 0.3307522370789915, reward: -51.0,-57.0)\n",
      "Episode 4300/300000 ( TD_error: -0.3090457854158384, reward: -24.0,-42.0)\n",
      "Episode 4400/300000 ( TD_error: -2.3868800617033363, reward: -15.0,-114.0)\n",
      "Episode 4500/300000 ( TD_error: -4.094944202688495, reward: -27.0,-14.0)\n",
      "Episode 4600/300000 ( TD_error: -2.1959603910117735, reward: -48.0,-87.0)\n",
      "Episode 4700/300000 ( TD_error: 0.7317706617194375, reward: -29.0,-10.0)\n",
      "Episode 4800/300000 ( TD_error: 0.5166128754523527, reward: -56.0,-22.0)\n",
      "Episode 4900/300000 ( TD_error: -10.481823726873003, reward: -10.0,-44.0)\n",
      "Episode 5000/300000 ( TD_error: -1.912009108100504, reward: -18.0,-14.0)\n",
      "Episode 5100/300000 ( TD_error: -2.4212335958304507, reward: -47.0,-14.0)\n",
      "Episode 5200/300000 ( TD_error: -2.2632279747863633, reward: -18.0,-90.0)\n",
      "Episode 5300/300000 ( TD_error: 0.3049615975956499, reward: -18.0,-63.0)\n",
      "Episode 5400/300000 ( TD_error: -0.2890204178683131, reward: -53.0,-126.0)\n",
      "Episode 5500/300000 ( TD_error: -1.0584587182557774, reward: -16.0,-27.0)\n",
      "Episode 5600/300000 ( TD_error: -3.63906395778319, reward: -74.0,-68.0)\n",
      "Episode 5700/300000 ( TD_error: -0.47197507826700935, reward: -62.0,-60.0)\n",
      "Episode 5800/300000 ( TD_error: -1.4757115594319004, reward: -19.0,-20.0)\n",
      "Episode 5900/300000 ( TD_error: -3.0529854800354794, reward: -60.0,-40.0)\n",
      "Episode 6000/300000 ( TD_error: -4.19701134901628, reward: -18.0,-19.0)\n",
      "Episode 6100/300000 ( TD_error: -0.9117215264039764, reward: -107.0,-10.0)\n",
      "Episode 6200/300000 ( TD_error: -2.799940562252667, reward: -33.0,-18.0)\n",
      "Episode 6300/300000 ( TD_error: -0.4350329801819175, reward: -21.0,-47.0)\n",
      "Episode 6400/300000 ( TD_error: -1.6957977230827659, reward: -15.0,-35.0)\n",
      "Episode 6500/300000 ( TD_error: 8.100066666295966, reward: 15.0,-16.0)\n",
      "Episode 6600/300000 ( TD_error: -1.4823295852622476, reward: -23.0,-47.0)\n",
      "Episode 6700/300000 ( TD_error: 6.43617333322291, reward: 15.0,-10.0)\n",
      "Episode 6800/300000 ( TD_error: -2.375112238946901, reward: -18.0,-25.0)\n",
      "Episode 6900/300000 ( TD_error: -2.3400367826703983, reward: -10.0,-16.0)\n",
      "Episode 7000/300000 ( TD_error: 5.391718695520332, reward: 15.0,-13.0)\n",
      "Episode 7100/300000 ( TD_error: -10.526507101323418, reward: -10.0,-52.0)\n",
      "Episode 7200/300000 ( TD_error: -1.5067924809928677, reward: -128.0,-25.0)\n",
      "Episode 7300/300000 ( TD_error: -0.30480831174873124, reward: -34.0,-76.0)\n",
      "Episode 7400/300000 ( TD_error: -0.7748315159930463, reward: -27.0,-10.0)\n",
      "Episode 7500/300000 ( TD_error: -1.667950200877411, reward: -29.0,-63.0)\n",
      "Episode 7600/300000 ( TD_error: -4.16738406391647, reward: -28.0,-11.0)\n",
      "Episode 7700/300000 ( TD_error: -3.189152535311292, reward: -11.0,-17.0)\n",
      "Episode 7800/300000 ( TD_error: -0.28013890708265343, reward: -11.0,-12.0)\n",
      "Episode 7900/300000 ( TD_error: -0.2843675098152225, reward: -50.0,-13.0)\n",
      "Episode 8000/300000 ( TD_error: -1.279421258242035, reward: -24.0,-65.0)\n",
      "Episode 8100/300000 ( TD_error: 3.4808083927755007, reward: 15.0,-10.0)\n",
      "Episode 8200/300000 ( TD_error: -5.633281829882142, reward: -10.0,-18.0)\n",
      "Episode 8300/300000 ( TD_error: -1.0049897451403513, reward: -31.0,-45.0)\n",
      "Episode 8400/300000 ( TD_error: -3.411123138502486, reward: -12.0,-12.0)\n",
      "Episode 8500/300000 ( TD_error: -1.3723818941625403, reward: -16.0,-48.0)\n",
      "Episode 8600/300000 ( TD_error: 2.7008431906812573, reward: 15.0,-10.0)\n",
      "Episode 8700/300000 ( TD_error: -2.3019466490851617, reward: -27.0,-25.0)\n",
      "Episode 8800/300000 ( TD_error: -0.1772772074031579, reward: -37.0,-16.0)\n",
      "Episode 8900/300000 ( TD_error: -3.656657190642738, reward: -23.0,-18.0)\n",
      "Episode 9000/300000 ( TD_error: 4.348834693275096, reward: 15.0,-54.0)\n",
      "Episode 9100/300000 ( TD_error: -1.161631310420482, reward: -166.0,-15.0)\n",
      "Episode 9200/300000 ( TD_error: -2.4711723943401527, reward: -21.0,-10.0)\n",
      "Episode 9300/300000 ( TD_error: -2.8083933876234592, reward: -19.0,-17.0)\n",
      "Episode 9400/300000 ( TD_error: -0.2524647810825851, reward: -13.0,-100.0)\n",
      "Episode 9500/300000 ( TD_error: 1.9596251262522442, reward: 15.0,-23.0)\n",
      "Episode 9600/300000 ( TD_error: -0.3625657725486171, reward: -72.0,-10.0)\n",
      "Episode 9700/300000 ( TD_error: -10.654886656039984, reward: -10.0,-40.0)\n",
      "Episode 9800/300000 ( TD_error: -1.7860129789777925, reward: -66.0,-136.0)\n",
      "Episode 9900/300000 ( TD_error: -0.36283241750318496, reward: -53.0,-36.0)\n",
      "Episode 10000/300000 ( TD_error: -0.16360564458030957, reward: -93.0,-10.0)\n",
      "Episode 10100/300000 ( TD_error: -0.2445543376646846, reward: -29.0,-10.0)\n",
      "Episode 10200/300000 ( TD_error: -0.23922423580577856, reward: -15.0,-30.0)\n",
      "Episode 10300/300000 ( TD_error: -0.14286536311947629, reward: -37.0,13.0)\n",
      "Episode 10400/300000 ( TD_error: -1.3130959729779974, reward: -25.0,-26.0)\n",
      "Episode 10500/300000 ( TD_error: -0.3113079158343126, reward: -59.0,-56.0)\n",
      "Episode 10600/300000 ( TD_error: -1.9703467086353994, reward: -27.0,-36.0)\n",
      "Episode 10700/300000 ( TD_error: -10.642989973724255, reward: -10.0,-41.0)\n",
      "Episode 10800/300000 ( TD_error: -1.2795256640573722, reward: -22.0,-67.0)\n",
      "Episode 10900/300000 ( TD_error: -0.4260207123509474, reward: -56.0,-102.0)\n",
      "Episode 11000/300000 ( TD_error: -0.16299924800617838, reward: -21.0,-25.0)\n",
      "Episode 11100/300000 ( TD_error: -0.22705419899785184, reward: -45.0,-15.0)\n",
      "Episode 11200/300000 ( TD_error: -1.122025726985921, reward: -43.0,-30.0)\n",
      "Episode 11300/300000 ( TD_error: -0.3870159415377721, reward: -45.0,-112.0)\n",
      "Episode 11400/300000 ( TD_error: -2.297835725762562, reward: -12.0,-26.0)\n",
      "Episode 11500/300000 ( TD_error: -1.1637543574872709, reward: -17.0,-53.0)\n",
      "Episode 11600/300000 ( TD_error: -1.096395440836318, reward: -16.0,-33.0)\n",
      "Episode 11700/300000 ( TD_error: -0.8879337988055287, reward: -66.0,-11.0)\n",
      "Episode 11800/300000 ( TD_error: 3.4243856580359946, reward: -10.0,-112.0)\n",
      "Episode 11900/300000 ( TD_error: -5.091265278664401, reward: -10.0,-10.0)\n",
      "Episode 12000/300000 ( TD_error: -0.623495306358036, reward: -57.0,-110.0)\n",
      "Episode 12100/300000 ( TD_error: 15.84707177082391, reward: 15.0,-23.0)\n",
      "Episode 12200/300000 ( TD_error: -1.2249032613744237, reward: -41.0,-10.0)\n",
      "Episode 12300/300000 ( TD_error: -0.76523688086281, reward: -33.0,-10.0)\n",
      "Episode 12400/300000 ( TD_error: -1.3215499290327148, reward: -13.0,-24.0)\n",
      "Episode 12500/300000 ( TD_error: -0.37338201870837295, reward: -11.0,-20.0)\n",
      "Episode 12600/300000 ( TD_error: -0.8419643361263383, reward: -31.0,-21.0)\n",
      "Episode 12700/300000 ( TD_error: -0.8280171657898983, reward: -28.0,-65.0)\n",
      "Episode 12800/300000 ( TD_error: -1.5910792635511761, reward: -25.0,-19.0)\n",
      "Episode 12900/300000 ( TD_error: 1.2149224496108735, reward: 15.0,-74.0)\n",
      "Episode 13000/300000 ( TD_error: -1.2771768956870186, reward: -29.0,-40.0)\n",
      "Episode 13100/300000 ( TD_error: -0.8242265376472346, reward: -27.0,-27.0)\n",
      "Episode 13200/300000 ( TD_error: -1.2014647163636774, reward: -29.0,15.0)\n",
      "Episode 13300/300000 ( TD_error: -2.3409455699854718, reward: -23.0,-18.0)\n",
      "Episode 13400/300000 ( TD_error: 1.1315727942564902, reward: 15.0,-48.0)\n",
      "Episode 13500/300000 ( TD_error: -0.5036176197043822, reward: -21.0,-21.0)\n",
      "Episode 13600/300000 ( TD_error: -0.746468972820038, reward: -48.0,-11.0)\n",
      "Episode 13700/300000 ( TD_error: -0.7248024217018756, reward: -49.0,15.0)\n",
      "Episode 13800/300000 ( TD_error: -9.958096542022025, reward: -10.0,-33.0)\n",
      "Episode 13900/300000 ( TD_error: -0.4912026742345823, reward: -15.0,-64.0)\n",
      "Episode 14000/300000 ( TD_error: -1.162595810849588, reward: -34.0,-10.0)\n",
      "Episode 14100/300000 ( TD_error: 1.5399877769604577, reward: 15.0,-10.0)\n",
      "Episode 14200/300000 ( TD_error: 0.3880702673075671, reward: -44.0,-10.0)\n",
      "Episode 14300/300000 ( TD_error: -1.08290140726964, reward: -45.0,15.0)\n",
      "Episode 14400/300000 ( TD_error: -1.0874480129895083, reward: -145.0,-21.0)\n",
      "Episode 14500/300000 ( TD_error: -1.3219363811098024, reward: -24.0,-26.0)\n",
      "Episode 14600/300000 ( TD_error: -2.444658775327131, reward: -22.0,-85.0)\n",
      "Episode 14700/300000 ( TD_error: -9.98793862976891, reward: -10.0,-55.0)\n",
      "Episode 14800/300000 ( TD_error: -0.5885307907172468, reward: -13.0,-23.0)\n",
      "Episode 14900/300000 ( TD_error: 1.2811226584709257, reward: 15.0,-10.0)\n",
      "Episode 15000/300000 ( TD_error: -9.944323221021506, reward: -10.0,-10.0)\n",
      "Episode 15100/300000 ( TD_error: -0.2717731563135395, reward: -40.0,-28.0)\n",
      "Episode 15200/300000 ( TD_error: 4.254197767952653, reward: 14.0,-52.0)\n",
      "Episode 15300/300000 ( TD_error: -0.7443815280309511, reward: -75.0,-19.0)\n",
      "Episode 15400/300000 ( TD_error: -2.9646390010810078, reward: -10.0,-10.0)\n",
      "Episode 15500/300000 ( TD_error: -0.300774811557762, reward: -62.0,-84.0)\n",
      "Episode 15600/300000 ( TD_error: 1.4766949223250414, reward: 15.0,-146.0)\n",
      "Episode 15700/300000 ( TD_error: -2.977367197012309, reward: -10.0,-48.0)\n",
      "Episode 15800/300000 ( TD_error: -10.551495658162501, reward: -10.0,-10.0)\n",
      "Episode 15900/300000 ( TD_error: 0.08155865801981399, reward: -12.0,-49.0)\n",
      "Episode 16000/300000 ( TD_error: -0.13947600069491983, reward: -28.0,-20.0)\n",
      "Episode 16100/300000 ( TD_error: 0.03968576272280089, reward: -63.0,-30.0)\n",
      "Episode 16200/300000 ( TD_error: -2.1679327223696916, reward: -35.0,-24.0)\n",
      "Episode 16300/300000 ( TD_error: -0.6757412066946618, reward: -10.0,-27.0)\n",
      "Episode 16400/300000 ( TD_error: -10.540595545964443, reward: -10.0,-21.0)\n",
      "Episode 16500/300000 ( TD_error: -0.6817112251475343, reward: -63.0,-55.0)\n",
      "Episode 16600/300000 ( TD_error: 4.149797013085942, reward: 15.0,15.0)\n",
      "Episode 16700/300000 ( TD_error: 0.12114281200299537, reward: -67.0,-10.0)\n",
      "Episode 16800/300000 ( TD_error: -0.10076130440812214, reward: -21.0,-27.0)\n",
      "Episode 16900/300000 ( TD_error: -2.3991746272389634, reward: -18.0,-21.0)\n",
      "Episode 17000/300000 ( TD_error: -9.945398281718473, reward: -10.0,-19.0)\n",
      "Episode 17100/300000 ( TD_error: -0.968170687665511, reward: -11.0,-10.0)\n",
      "Episode 17200/300000 ( TD_error: 0.05003649432703661, reward: -47.0,-15.0)\n",
      "Episode 17300/300000 ( TD_error: -2.1707594074096086, reward: -21.0,-94.0)\n",
      "Episode 17400/300000 ( TD_error: -0.6941445671505111, reward: -17.0,-53.0)\n",
      "Episode 17500/300000 ( TD_error: -0.2133980838933205, reward: -41.0,-13.0)\n",
      "Episode 17600/300000 ( TD_error: 0.5219686934569863, reward: -32.0,-10.0)\n",
      "Episode 17700/300000 ( TD_error: -9.894887250751928, reward: -10.0,-10.0)\n",
      "Episode 17800/300000 ( TD_error: -1.6106512861746314, reward: -38.0,-14.0)\n",
      "Episode 17900/300000 ( TD_error: -10.531084814945352, reward: -10.0,-38.0)\n",
      "Episode 18000/300000 ( TD_error: -0.6173553619622822, reward: -11.0,14.0)\n",
      "Episode 18100/300000 ( TD_error: -10.543482453112075, reward: -10.0,15.0)\n",
      "Episode 18200/300000 ( TD_error: -0.46653408455949474, reward: -12.0,-11.0)\n",
      "Episode 18300/300000 ( TD_error: -0.37812544841150775, reward: -14.0,-33.0)\n",
      "Episode 18400/300000 ( TD_error: -0.02728005504146047, reward: -25.0,15.0)\n",
      "Episode 18500/300000 ( TD_error: -0.1174628407597762, reward: -39.0,-13.0)\n",
      "Episode 18600/300000 ( TD_error: -0.034196898173760815, reward: -31.0,-10.0)\n",
      "Episode 18700/300000 ( TD_error: -1.0939229611604588, reward: -21.0,-10.0)\n",
      "Episode 18800/300000 ( TD_error: -0.11355912341274088, reward: -10.0,-26.0)\n",
      "Episode 18900/300000 ( TD_error: -0.31450007029804894, reward: -18.0,-10.0)\n",
      "Episode 19000/300000 ( TD_error: 0.5587010573479505, reward: -20.0,-14.0)\n",
      "Episode 19100/300000 ( TD_error: -0.9586943027349548, reward: -28.0,-14.0)\n",
      "Episode 19200/300000 ( TD_error: -0.551085175160674, reward: -12.0,-72.0)\n",
      "Episode 19300/300000 ( TD_error: 15.964886172712255, reward: 15.0,-10.0)\n",
      "Episode 19400/300000 ( TD_error: -0.3876458529704365, reward: -23.0,-26.0)\n",
      "Episode 19500/300000 ( TD_error: -0.195152301661345, reward: -14.0,-325.0)\n",
      "Episode 19600/300000 ( TD_error: -0.21743470632569384, reward: -13.0,-10.0)\n",
      "Episode 19700/300000 ( TD_error: -0.45027954778406, reward: -10.0,-10.0)\n",
      "Episode 19800/300000 ( TD_error: -0.1533890024707132, reward: -13.0,-10.0)\n",
      "Episode 19900/300000 ( TD_error: -2.5300122194216463, reward: -15.0,-39.0)\n",
      "Episode 20000/300000 ( TD_error: 0.34259760166083275, reward: -25.0,-119.0)\n",
      "Episode 20100/300000 ( TD_error: 0.015527748302858413, reward: -41.0,-16.0)\n",
      "Episode 20200/300000 ( TD_error: -9.879710638295013, reward: -10.0,-10.0)\n",
      "Episode 20300/300000 ( TD_error: 0.6955722132111459, reward: -12.0,-10.0)\n",
      "Episode 20400/300000 ( TD_error: -2.4305875550462357, reward: -28.0,-10.0)\n",
      "Episode 20500/300000 ( TD_error: -3.0232514361054186, reward: -18.0,-17.0)\n",
      "Episode 20600/300000 ( TD_error: 1.7985641435308537, reward: 15.0,-13.0)\n",
      "Episode 20700/300000 ( TD_error: -0.08407033756377658, reward: -18.0,-20.0)\n",
      "Episode 20800/300000 ( TD_error: -10.544875451660644, reward: -10.0,-12.0)\n",
      "Episode 20900/300000 ( TD_error: 0.15126524902422567, reward: -32.0,-26.0)\n",
      "Episode 21000/300000 ( TD_error: -0.0803836077628306, reward: -13.0,-38.0)\n",
      "Episode 21100/300000 ( TD_error: 0.18746173124981702, reward: -78.0,-11.0)\n",
      "Episode 21200/300000 ( TD_error: -5.161693041250903, reward: -12.0,-46.0)\n",
      "Episode 21300/300000 ( TD_error: -0.16469376092738042, reward: -10.0,-13.0)\n",
      "Episode 21400/300000 ( TD_error: 0.516548064583497, reward: -13.0,-10.0)\n",
      "Episode 21500/300000 ( TD_error: -1.7034349638639457, reward: -10.0,-22.0)\n",
      "Episode 21600/300000 ( TD_error: -4.200809861566629, reward: -10.0,-85.0)\n",
      "Episode 21700/300000 ( TD_error: -0.1811114597011576, reward: -18.0,-12.0)\n",
      "Episode 21800/300000 ( TD_error: 4.119969037914499, reward: -10.0,-57.0)\n",
      "Episode 21900/300000 ( TD_error: -2.6389534544964803, reward: -17.0,-10.0)\n",
      "Episode 22000/300000 ( TD_error: 3.99343076461631, reward: -10.0,-12.0)\n",
      "Episode 22100/300000 ( TD_error: -0.7775770287051973, reward: -14.0,-10.0)\n",
      "Episode 22200/300000 ( TD_error: 0.7943212320651742, reward: -10.0,-28.0)\n",
      "Episode 22300/300000 ( TD_error: 0.8427657860320252, reward: -10.0,-17.0)\n",
      "Episode 22400/300000 ( TD_error: 0.7868222796717239, reward: -10.0,-10.0)\n",
      "Episode 22500/300000 ( TD_error: 0.010944271515647586, reward: -11.0,-10.0)\n",
      "Episode 22600/300000 ( TD_error: -0.6506208080528317, reward: -31.0,-29.0)\n",
      "Episode 22700/300000 ( TD_error: -1.8296463439778368, reward: -10.0,-10.0)\n",
      "Episode 22800/300000 ( TD_error: 0.10521490972309788, reward: -13.0,-31.0)\n",
      "Episode 22900/300000 ( TD_error: 0.06811211513986315, reward: -12.0,-10.0)\n",
      "Episode 23000/300000 ( TD_error: -2.1731770197773645, reward: -10.0,-90.0)\n",
      "Episode 23100/300000 ( TD_error: -0.5880067646628024, reward: -55.0,-13.0)\n",
      "Episode 23200/300000 ( TD_error: -0.29209270782168417, reward: -45.0,-10.0)\n",
      "Episode 23300/300000 ( TD_error: -1.978444928832701, reward: -10.0,-25.0)\n",
      "Episode 23400/300000 ( TD_error: -1.1775270741296886, reward: -24.0,-12.0)\n",
      "Episode 23500/300000 ( TD_error: -1.8867179841253954, reward: -32.0,-63.0)\n",
      "Episode 23600/300000 ( TD_error: 0.02394049485855998, reward: -82.0,-11.0)\n",
      "Episode 23700/300000 ( TD_error: 0.06809900413081671, reward: -14.0,-25.0)\n",
      "Episode 23800/300000 ( TD_error: 0.05688604335944003, reward: -10.0,-10.0)\n",
      "Episode 23900/300000 ( TD_error: -0.34306952638374355, reward: -132.0,-28.0)\n",
      "Episode 24000/300000 ( TD_error: 2.056636141825569, reward: 15.0,-12.0)\n",
      "Episode 24100/300000 ( TD_error: 2.2508016537879243, reward: 15.0,-10.0)\n",
      "Episode 24200/300000 ( TD_error: -9.830978120075239, reward: -10.0,-26.0)\n",
      "Episode 24300/300000 ( TD_error: -1.7619056766975643, reward: -18.0,-11.0)\n",
      "Episode 24400/300000 ( TD_error: -9.908668466944658, reward: -10.0,-10.0)\n",
      "Episode 24500/300000 ( TD_error: -2.1516060456712136, reward: -13.0,-19.0)\n",
      "Episode 24600/300000 ( TD_error: -0.3474228135585786, reward: -26.0,-22.0)\n",
      "Episode 24700/300000 ( TD_error: -1.7833659737011534, reward: -10.0,-32.0)\n",
      "Episode 24800/300000 ( TD_error: 1.7628579781778853, reward: 15.0,-52.0)\n",
      "Episode 24900/300000 ( TD_error: -0.05172798696155034, reward: -12.0,-68.0)\n",
      "Episode 25000/300000 ( TD_error: -0.45887043574329844, reward: -16.0,-11.0)\n",
      "Episode 25100/300000 ( TD_error: -1.5581825213636429, reward: -10.0,-10.0)\n",
      "Episode 25200/300000 ( TD_error: -0.0023813880242489205, reward: -11.0,-64.0)\n",
      "Episode 25300/300000 ( TD_error: -10.570185296904878, reward: -10.0,-13.0)\n",
      "Episode 25400/300000 ( TD_error: 0.019611927426886666, reward: -10.0,-42.0)\n",
      "Episode 25500/300000 ( TD_error: -9.899733195826261, reward: -10.0,-11.0)\n",
      "Episode 25600/300000 ( TD_error: 0.6698876279119119, reward: -45.0,-14.0)\n",
      "Episode 25700/300000 ( TD_error: 1.3155841829658796, reward: 15.0,-14.0)\n",
      "Episode 25800/300000 ( TD_error: -0.49142796958607526, reward: -10.0,-30.0)\n",
      "Episode 25900/300000 ( TD_error: 0.012421302160005254, reward: -12.0,-23.0)\n",
      "Episode 26000/300000 ( TD_error: -0.07347046425281878, reward: -37.0,-14.0)\n",
      "Episode 26100/300000 ( TD_error: -9.797874506705659, reward: -10.0,-11.0)\n",
      "Episode 26200/300000 ( TD_error: -9.886860887552753, reward: -10.0,-11.0)\n",
      "Episode 26300/300000 ( TD_error: -9.88409412956337, reward: -10.0,-34.0)\n",
      "Episode 26400/300000 ( TD_error: -1.5615750824927073, reward: -17.0,-24.0)\n",
      "Episode 26500/300000 ( TD_error: -0.10206097688933369, reward: -23.0,-46.0)\n",
      "Episode 26600/300000 ( TD_error: -9.785681897892795, reward: -10.0,-35.0)\n",
      "Episode 26700/300000 ( TD_error: -0.7116818130910438, reward: -11.0,-10.0)\n",
      "Episode 26800/300000 ( TD_error: -0.406693974227581, reward: -18.0,-46.0)\n",
      "Episode 26900/300000 ( TD_error: -9.776436889442767, reward: -10.0,-93.0)\n",
      "Episode 27000/300000 ( TD_error: 0.10598612507046656, reward: -12.0,15.0)\n",
      "Episode 27100/300000 ( TD_error: 0.7635022201257131, reward: -138.0,-11.0)\n",
      "Episode 27200/300000 ( TD_error: 1.5493449222724154, reward: 15.0,-10.0)\n",
      "Episode 27300/300000 ( TD_error: 0.07090858520846233, reward: -13.0,-22.0)\n",
      "Episode 27400/300000 ( TD_error: 0.009037917558357478, reward: -12.0,-28.0)\n",
      "Episode 27500/300000 ( TD_error: -0.5163138151169733, reward: -35.0,-20.0)\n",
      "Episode 27600/300000 ( TD_error: 3.6336962045630012, reward: 15.0,-10.0)\n",
      "Episode 27700/300000 ( TD_error: 2.5452445962459054, reward: 15.0,-31.0)\n",
      "Episode 27800/300000 ( TD_error: 2.4594772171332253, reward: 15.0,-10.0)\n",
      "Episode 27900/300000 ( TD_error: 0.8660909411058171, reward: -10.0,-10.0)\n",
      "Episode 28000/300000 ( TD_error: -9.770893559928266, reward: -10.0,-24.0)\n",
      "Episode 28100/300000 ( TD_error: -0.24996829965913747, reward: -67.0,-36.0)\n",
      "Episode 28200/300000 ( TD_error: -0.03325094315026522, reward: -12.0,-34.0)\n",
      "Episode 28300/300000 ( TD_error: 1.300666322140179, reward: -10.0,-15.0)\n",
      "Episode 28400/300000 ( TD_error: 2.1779953136534362, reward: 15.0,15.0)\n",
      "Episode 28500/300000 ( TD_error: -0.35854982951864933, reward: -33.0,-45.0)\n",
      "Episode 28600/300000 ( TD_error: 0.024304361861149815, reward: -12.0,15.0)\n",
      "Episode 28700/300000 ( TD_error: 1.3370562981808973, reward: -10.0,-48.0)\n",
      "Episode 28800/300000 ( TD_error: -1.8356451451060813, reward: -23.0,-13.0)\n",
      "Episode 28900/300000 ( TD_error: -0.04082715306254148, reward: -12.0,-43.0)\n",
      "Episode 29000/300000 ( TD_error: -0.23002243962940838, reward: -68.0,-10.0)\n",
      "Episode 29100/300000 ( TD_error: -0.03327168265396807, reward: -13.0,-12.0)\n",
      "Episode 29200/300000 ( TD_error: 2.2241848575090746, reward: 15.0,-11.0)\n",
      "Episode 29300/300000 ( TD_error: -10.54426342602018, reward: -10.0,-114.0)\n",
      "Episode 29400/300000 ( TD_error: 0.9635097647526969, reward: -10.0,-14.0)\n",
      "Episode 29500/300000 ( TD_error: -0.16741252687670816, reward: -20.0,-10.0)\n",
      "Episode 29600/300000 ( TD_error: 1.1908154082048403, reward: -10.0,-14.0)\n",
      "Episode 29700/300000 ( TD_error: 6.015500889290139, reward: 14.0,-10.0)\n",
      "Episode 29800/300000 ( TD_error: -0.18959556076011275, reward: -31.0,-16.0)\n",
      "Episode 29900/300000 ( TD_error: -9.751887987106551, reward: -10.0,-45.0)\n",
      "Episode 30000/300000 ( TD_error: -1.4772739274014457, reward: -10.0,-40.0)\n",
      "Episode 30100/300000 ( TD_error: 0.08856959883034143, reward: -17.0,-10.0)\n",
      "Episode 30200/300000 ( TD_error: 2.360000869216489, reward: 15.0,-10.0)\n",
      "Episode 30300/300000 ( TD_error: -0.39980561652115654, reward: -29.0,-10.0)\n",
      "Episode 30400/300000 ( TD_error: -0.34304429129875125, reward: -12.0,15.0)\n",
      "Episode 30500/300000 ( TD_error: -0.37846341216462065, reward: -21.0,-10.0)\n",
      "Episode 30600/300000 ( TD_error: 0.06886192004324254, reward: -13.0,-28.0)\n",
      "Episode 30700/300000 ( TD_error: -0.2878624484655816, reward: -21.0,-21.0)\n",
      "Episode 30800/300000 ( TD_error: -0.49151597888599774, reward: -13.0,-30.0)\n",
      "Episode 30900/300000 ( TD_error: -1.548127275961427, reward: -11.0,-13.0)\n",
      "Episode 31000/300000 ( TD_error: -0.1576981004993261, reward: -22.0,-11.0)\n",
      "Episode 31100/300000 ( TD_error: 0.8219767155032685, reward: -15.0,-12.0)\n",
      "Episode 31200/300000 ( TD_error: 4.330872883036858, reward: 15.0,-66.0)\n",
      "Episode 31300/300000 ( TD_error: 0.03689967225780677, reward: -12.0,-13.0)\n",
      "Episode 31400/300000 ( TD_error: 4.116351897336598, reward: 15.0,-11.0)\n",
      "Episode 31500/300000 ( TD_error: -0.24316438270363605, reward: -47.0,-14.0)\n",
      "Episode 31600/300000 ( TD_error: -2.0306683707187965, reward: -25.0,-11.0)\n",
      "Episode 31700/300000 ( TD_error: 0.029318648187401486, reward: -11.0,-18.0)\n",
      "Episode 31800/300000 ( TD_error: 0.05456744238127165, reward: -10.0,-15.0)\n",
      "Episode 31900/300000 ( TD_error: -9.829005035910587, reward: -10.0,-20.0)\n",
      "Episode 32000/300000 ( TD_error: 2.328444862045299, reward: 15.0,-16.0)\n",
      "Episode 32100/300000 ( TD_error: -0.058941419765385916, reward: -10.0,15.0)\n",
      "Episode 32200/300000 ( TD_error: -0.32940127148851595, reward: -13.0,-29.0)\n",
      "Episode 32300/300000 ( TD_error: 0.0038119534964975443, reward: -12.0,-49.0)\n",
      "Episode 32400/300000 ( TD_error: -0.28773393490467036, reward: -72.0,-28.0)\n",
      "Episode 32500/300000 ( TD_error: 0.020833796297353935, reward: -42.0,-58.0)\n",
      "Episode 32600/300000 ( TD_error: -0.06469040765182399, reward: -12.0,-10.0)\n",
      "Episode 32700/300000 ( TD_error: 1.118936889529465, reward: -11.0,-10.0)\n",
      "Episode 32800/300000 ( TD_error: -0.11820466427477427, reward: -98.0,-10.0)\n",
      "Episode 32900/300000 ( TD_error: -0.19719184419048208, reward: -11.0,-34.0)\n",
      "Episode 33000/300000 ( TD_error: 3.09538872041266, reward: 14.0,-13.0)\n",
      "Episode 33100/300000 ( TD_error: -0.30152589517095496, reward: -12.0,-34.0)\n",
      "Episode 33200/300000 ( TD_error: 1.3758241774273579, reward: -10.0,15.0)\n",
      "Episode 33300/300000 ( TD_error: 2.8482688790186206, reward: -40.0,-10.0)\n",
      "Episode 33400/300000 ( TD_error: -10.501771009969815, reward: -10.0,14.0)\n",
      "Episode 33500/300000 ( TD_error: -0.4189790010844616, reward: -11.0,15.0)\n",
      "Episode 33600/300000 ( TD_error: -1.210705059116739, reward: -10.0,-10.0)\n",
      "Episode 33700/300000 ( TD_error: -0.5061771347767516, reward: -12.0,-12.0)\n",
      "Episode 33800/300000 ( TD_error: -0.6736482416946616, reward: -10.0,14.0)\n",
      "Episode 33900/300000 ( TD_error: 2.5445218727975987, reward: 14.0,13.0)\n",
      "Episode 34000/300000 ( TD_error: -9.775662351365408, reward: -10.0,-12.0)\n",
      "Episode 34100/300000 ( TD_error: -0.3643450823201153, reward: -13.0,-10.0)\n",
      "Episode 34200/300000 ( TD_error: 0.8854045858849724, reward: 15.0,-16.0)\n",
      "Episode 34300/300000 ( TD_error: -0.12166810132874062, reward: -13.0,-10.0)\n",
      "Episode 34400/300000 ( TD_error: -0.1504732746185118, reward: -11.0,-12.0)\n",
      "Episode 34500/300000 ( TD_error: 9.220604390936106, reward: 15.0,-44.0)\n",
      "Episode 34600/300000 ( TD_error: -0.1478478757357049, reward: -16.0,-12.0)\n",
      "Episode 34700/300000 ( TD_error: 2.2337787307554593, reward: 15.0,-10.0)\n",
      "Episode 34800/300000 ( TD_error: -9.764345024954881, reward: -10.0,-10.0)\n",
      "Episode 34900/300000 ( TD_error: 2.0523676881554023, reward: 13.0,-37.0)\n",
      "Episode 35000/300000 ( TD_error: 2.8998093448285216, reward: 15.0,-13.0)\n",
      "Episode 35100/300000 ( TD_error: 1.410981139971311, reward: 15.0,-16.0)\n",
      "Episode 35200/300000 ( TD_error: -0.07818973584794975, reward: -10.0,-53.0)\n",
      "Episode 35300/300000 ( TD_error: 2.142489192596269, reward: 13.0,-12.0)\n",
      "Episode 35400/300000 ( TD_error: -0.0679433178654989, reward: -12.0,-10.0)\n",
      "Episode 35500/300000 ( TD_error: -0.0502555095864885, reward: -10.0,-12.0)\n",
      "Episode 35600/300000 ( TD_error: 2.056297813259073, reward: 13.0,12.0)\n",
      "Episode 35700/300000 ( TD_error: -0.06819677652577116, reward: -12.0,-11.0)\n",
      "Episode 35800/300000 ( TD_error: -0.10648264189585088, reward: -11.0,-11.0)\n",
      "Episode 35900/300000 ( TD_error: -0.19079196902362927, reward: -15.0,-10.0)\n",
      "Episode 36000/300000 ( TD_error: -0.2272056853358677, reward: -17.0,-12.0)\n",
      "Episode 36100/300000 ( TD_error: -0.1227184256907572, reward: -15.0,-12.0)\n",
      "Episode 36200/300000 ( TD_error: 0.5561341159379936, reward: -12.0,-15.0)\n",
      "Episode 36300/300000 ( TD_error: 1.3029130237902005, reward: 15.0,-14.0)\n",
      "Episode 36400/300000 ( TD_error: 1.7694445242196983, reward: 13.0,-16.0)\n",
      "Episode 36500/300000 ( TD_error: -0.07704447591863861, reward: -17.0,-12.0)\n",
      "Episode 36600/300000 ( TD_error: 2.4815648276459057, reward: 14.0,-10.0)\n",
      "Episode 36700/300000 ( TD_error: -0.22006732870650048, reward: -10.0,-16.0)\n",
      "Episode 36800/300000 ( TD_error: -0.2520365364885695, reward: -10.0,-10.0)\n",
      "Episode 36900/300000 ( TD_error: -9.789099681638536, reward: -10.0,-11.0)\n",
      "Episode 37000/300000 ( TD_error: -0.08110724458556717, reward: -13.0,-12.0)\n",
      "Episode 37100/300000 ( TD_error: 0.5653849923226071, reward: -22.0,-12.0)\n",
      "Episode 37200/300000 ( TD_error: -0.4777350400163183, reward: -12.0,-12.0)\n",
      "Episode 37300/300000 ( TD_error: -0.3930574889907037, reward: -44.0,14.0)\n",
      "Episode 37400/300000 ( TD_error: -1.767197541586354, reward: -12.0,15.0)\n",
      "Episode 37500/300000 ( TD_error: 6.955524405264404, reward: -10.0,14.0)\n",
      "Episode 37600/300000 ( TD_error: 2.0315560459338364, reward: 13.0,-10.0)\n",
      "Episode 37700/300000 ( TD_error: -0.6210753324680525, reward: -11.0,15.0)\n",
      "Episode 37800/300000 ( TD_error: 0.9336918409063584, reward: 15.0,-13.0)\n",
      "Episode 37900/300000 ( TD_error: -0.25432583826006194, reward: -12.0,-10.0)\n",
      "Episode 38000/300000 ( TD_error: -0.1456931538174988, reward: -11.0,-10.0)\n",
      "Episode 38100/300000 ( TD_error: -0.10549372160812531, reward: -13.0,12.0)\n",
      "Episode 38200/300000 ( TD_error: 2.543579848367877, reward: 14.0,13.0)\n",
      "Episode 38300/300000 ( TD_error: 0.5948725931505656, reward: -11.0,-15.0)\n",
      "Episode 38400/300000 ( TD_error: 3.099046129502601, reward: 12.0,-11.0)\n",
      "Episode 38500/300000 ( TD_error: -0.22495786459344735, reward: -11.0,12.0)\n",
      "Episode 38600/300000 ( TD_error: 0.4261400904334991, reward: -16.0,-12.0)\n",
      "Episode 38700/300000 ( TD_error: -0.23568856000334826, reward: -12.0,13.0)\n",
      "Episode 38800/300000 ( TD_error: 2.1543179785861444, reward: 12.0,-15.0)\n",
      "Episode 38900/300000 ( TD_error: 0.7201752579162584, reward: -14.0,-12.0)\n",
      "Episode 39000/300000 ( TD_error: -9.642881484765116, reward: -10.0,13.0)\n",
      "Episode 39100/300000 ( TD_error: 2.405714339336559, reward: 12.0,-13.0)\n",
      "Episode 39200/300000 ( TD_error: -10.292201361771179, reward: -10.0,-16.0)\n",
      "Episode 39300/300000 ( TD_error: -0.20404766528306428, reward: -11.0,-10.0)\n",
      "Episode 39400/300000 ( TD_error: 2.797870660814848, reward: 15.0,-10.0)\n",
      "Episode 39500/300000 ( TD_error: -2.1411331667291904, reward: -14.0,-12.0)\n",
      "Episode 39600/300000 ( TD_error: -0.3865315729580967, reward: -10.0,13.0)\n",
      "Episode 39700/300000 ( TD_error: -9.816995672948, reward: -10.0,13.0)\n",
      "Episode 39800/300000 ( TD_error: -0.3998082563844365, reward: -15.0,-15.0)\n",
      "Episode 39900/300000 ( TD_error: 0.3212801713986737, reward: -10.0,-14.0)\n",
      "Episode 40000/300000 ( TD_error: 8.087519966833904, reward: -10.0,-13.0)\n",
      "Episode 40100/300000 ( TD_error: -0.6981869563404111, reward: -10.0,-10.0)\n",
      "Episode 40200/300000 ( TD_error: 5.060700441398511, reward: -10.0,13.0)\n",
      "Episode 40300/300000 ( TD_error: 0.06232644694712519, reward: -10.0,-10.0)\n",
      "Episode 40400/300000 ( TD_error: -0.13388088659970698, reward: -16.0,-11.0)\n",
      "Episode 40500/300000 ( TD_error: -1.143659895897212, reward: -12.0,-10.0)\n",
      "Episode 40600/300000 ( TD_error: 1.9537986217505765, reward: 12.0,-12.0)\n",
      "Episode 40700/300000 ( TD_error: 1.6690879690746123, reward: 12.0,-11.0)\n",
      "Episode 40800/300000 ( TD_error: -0.19395573144148415, reward: -12.0,-10.0)\n",
      "Episode 40900/300000 ( TD_error: -0.1320014534909122, reward: -18.0,-10.0)\n",
      "Episode 41000/300000 ( TD_error: -2.460908336210318, reward: -13.0,-11.0)\n",
      "Episode 41100/300000 ( TD_error: 2.2467017842721795, reward: 12.0,-12.0)\n",
      "Episode 41200/300000 ( TD_error: -0.4141292847868181, reward: -10.0,7.0)\n",
      "Episode 41300/300000 ( TD_error: -0.5611587214560121, reward: -13.0,13.0)\n",
      "Episode 41400/300000 ( TD_error: -0.5155177419613874, reward: -13.0,-14.0)\n",
      "Episode 41500/300000 ( TD_error: -0.28855075582063083, reward: -30.0,-14.0)\n",
      "Episode 41600/300000 ( TD_error: -9.603805057904113, reward: -10.0,13.0)\n",
      "Episode 41700/300000 ( TD_error: -0.33580147223230217, reward: -12.0,-10.0)\n",
      "Episode 41800/300000 ( TD_error: -0.27153885540497846, reward: -10.0,-13.0)\n",
      "Episode 41900/300000 ( TD_error: -0.44511490011027277, reward: -14.0,-10.0)\n",
      "Episode 42000/300000 ( TD_error: -0.26667239259001807, reward: -16.0,-14.0)\n",
      "Episode 42100/300000 ( TD_error: 0.2737670887801045, reward: -13.0,14.0)\n",
      "Episode 42200/300000 ( TD_error: -10.559237900119491, reward: -10.0,15.0)\n",
      "Episode 42300/300000 ( TD_error: 1.6311161125265818, reward: 15.0,-12.0)\n",
      "Episode 42400/300000 ( TD_error: 2.0705081612106477, reward: 13.0,-10.0)\n",
      "Episode 42500/300000 ( TD_error: -9.599211887902122, reward: -10.0,15.0)\n",
      "Episode 42600/300000 ( TD_error: -0.6552770306852853, reward: -82.0,-10.0)\n",
      "Episode 42700/300000 ( TD_error: -0.37481038578273473, reward: -12.0,-10.0)\n",
      "Episode 42800/300000 ( TD_error: -0.325250360973393, reward: -16.0,-12.0)\n",
      "Episode 42900/300000 ( TD_error: 0.0306587144260968, reward: -10.0,-13.0)\n",
      "Episode 43000/300000 ( TD_error: -0.920264617581152, reward: -11.0,-11.0)\n",
      "Episode 43100/300000 ( TD_error: -0.23830536309097372, reward: -14.0,-13.0)\n",
      "Episode 43200/300000 ( TD_error: -0.26505411619743224, reward: -11.0,-10.0)\n",
      "Episode 43300/300000 ( TD_error: 0.3238182015868878, reward: -10.0,-11.0)\n",
      "Episode 43400/300000 ( TD_error: -9.596407079030037, reward: -10.0,15.0)\n",
      "Episode 43500/300000 ( TD_error: -3.167311207750801, reward: -58.0,13.0)\n",
      "Episode 43600/300000 ( TD_error: 0.34844289444557663, reward: -18.0,-16.0)\n",
      "Episode 43700/300000 ( TD_error: -0.31865564509879185, reward: -14.0,-15.0)\n",
      "Episode 43800/300000 ( TD_error: -0.38646286589191714, reward: -15.0,-12.0)\n",
      "Episode 43900/300000 ( TD_error: -0.50048351654595, reward: -12.0,-10.0)\n",
      "Episode 44000/300000 ( TD_error: -0.6750620914862724, reward: -15.0,-24.0)\n",
      "Episode 44100/300000 ( TD_error: -0.10410911820440916, reward: -10.0,13.0)\n",
      "Episode 44200/300000 ( TD_error: -1.852679180107689, reward: -14.0,-13.0)\n",
      "Episode 44300/300000 ( TD_error: -1.3409927217004807, reward: -12.0,-14.0)\n",
      "Episode 44400/300000 ( TD_error: 1.2969267018664576, reward: 13.0,15.0)\n",
      "Episode 44500/300000 ( TD_error: -4.658082895826945, reward: -10.0,-10.0)\n",
      "Episode 44600/300000 ( TD_error: 1.6343324258127574, reward: 15.0,-10.0)\n",
      "Episode 44700/300000 ( TD_error: 1.6136722907557366, reward: 13.0,-10.0)\n",
      "Episode 44800/300000 ( TD_error: -0.39908090715381395, reward: -14.0,-10.0)\n",
      "Episode 44900/300000 ( TD_error: 1.6104350223749178, reward: 14.0,-10.0)\n",
      "Episode 45000/300000 ( TD_error: -4.7462137522876, reward: -25.0,-19.0)\n",
      "Episode 45100/300000 ( TD_error: 1.5097091092351704, reward: 14.0,-12.0)\n",
      "Episode 45200/300000 ( TD_error: -0.611465464389326, reward: -10.0,-10.0)\n",
      "Episode 45300/300000 ( TD_error: -0.561785808930078, reward: -14.0,-16.0)\n",
      "Episode 45400/300000 ( TD_error: 1.426622219707774, reward: 13.0,-11.0)\n",
      "Episode 45500/300000 ( TD_error: 1.3139166854538618, reward: 13.0,-14.0)\n",
      "Episode 45600/300000 ( TD_error: 0.15989949051307129, reward: -11.0,-12.0)\n",
      "Episode 45700/300000 ( TD_error: 0.24116353905243848, reward: -11.0,-10.0)\n",
      "Episode 45800/300000 ( TD_error: 1.3834617664193036, reward: 15.0,-16.0)\n",
      "Episode 45900/300000 ( TD_error: -0.22387802086371522, reward: -12.0,-10.0)\n",
      "Episode 46000/300000 ( TD_error: -0.2197453727687444, reward: -12.0,-13.0)\n",
      "Episode 46100/300000 ( TD_error: -0.1961829584806436, reward: -13.0,-13.0)\n",
      "Episode 46200/300000 ( TD_error: -0.18484668845242425, reward: -13.0,-12.0)\n",
      "Episode 46300/300000 ( TD_error: -0.19823555004845073, reward: -12.0,15.0)\n",
      "Episode 46400/300000 ( TD_error: -0.112859900638834, reward: -13.0,-13.0)\n",
      "Episode 46500/300000 ( TD_error: 1.576357489670333, reward: 13.0,-14.0)\n",
      "Episode 46600/300000 ( TD_error: -0.16877518287334325, reward: -11.0,-14.0)\n",
      "Episode 46700/300000 ( TD_error: 0.1644404060326874, reward: -39.0,-10.0)\n",
      "Episode 46800/300000 ( TD_error: -0.2511978893691218, reward: -10.0,-12.0)\n",
      "Episode 46900/300000 ( TD_error: -9.833214834462416, reward: -10.0,-10.0)\n",
      "Episode 47000/300000 ( TD_error: -0.12083948592883953, reward: -16.0,-13.0)\n",
      "Episode 47100/300000 ( TD_error: 2.0027481902427557, reward: 15.0,11.0)\n",
      "Episode 47200/300000 ( TD_error: -0.16847733993460068, reward: -11.0,-12.0)\n",
      "Episode 47300/300000 ( TD_error: -0.13269049343191242, reward: -14.0,-12.0)\n",
      "Episode 47400/300000 ( TD_error: -0.1267336606352174, reward: -13.0,-11.0)\n",
      "Episode 47500/300000 ( TD_error: -2.0738711048077683, reward: -10.0,15.0)\n",
      "Episode 47600/300000 ( TD_error: -10.550392502118239, reward: -10.0,-12.0)\n",
      "Episode 47700/300000 ( TD_error: 0.14607229339962302, reward: -10.0,-16.0)\n",
      "Episode 47800/300000 ( TD_error: 2.882142599451961, reward: 12.0,-17.0)\n",
      "Episode 47900/300000 ( TD_error: -2.093864447920339, reward: -21.0,15.0)\n",
      "Episode 48000/300000 ( TD_error: 2.223375003457301, reward: 14.0,-14.0)\n",
      "Episode 48100/300000 ( TD_error: -2.118033711120326, reward: -36.0,-43.0)\n",
      "Episode 48200/300000 ( TD_error: 0.5618996313596405, reward: -15.0,-13.0)\n",
      "Episode 48300/300000 ( TD_error: -0.17792719454971362, reward: -18.0,-13.0)\n",
      "Episode 48400/300000 ( TD_error: 2.276812571436144, reward: 13.0,-10.0)\n",
      "Episode 48500/300000 ( TD_error: 1.9605049953398108, reward: 13.0,-10.0)\n",
      "Episode 48600/300000 ( TD_error: 2.187999545099832, reward: 14.0,-13.0)\n",
      "Episode 48700/300000 ( TD_error: -0.9480346915588376, reward: -14.0,-14.0)\n",
      "Episode 48800/300000 ( TD_error: 1.9910290137908322, reward: 14.0,-16.0)\n",
      "Episode 48900/300000 ( TD_error: 10.573482924362834, reward: 15.0,-10.0)\n",
      "Episode 49000/300000 ( TD_error: -0.6540430622804081, reward: -11.0,-13.0)\n",
      "Episode 49100/300000 ( TD_error: -0.500056366019928, reward: -10.0,-14.0)\n",
      "Episode 49200/300000 ( TD_error: -2.4498547460873787, reward: -12.0,-11.0)\n",
      "Episode 49300/300000 ( TD_error: 0.28824213104860164, reward: -10.0,15.0)\n",
      "Episode 49400/300000 ( TD_error: -0.20826070729090151, reward: -11.0,15.0)\n",
      "Episode 49500/300000 ( TD_error: -0.4650608560760041, reward: -10.0,13.0)\n",
      "Episode 49600/300000 ( TD_error: -2.050494106387763, reward: -30.0,-18.0)\n",
      "Episode 49700/300000 ( TD_error: -0.14923710088459963, reward: -16.0,-11.0)\n",
      "Episode 49800/300000 ( TD_error: 0.1118310412519481, reward: -10.0,-10.0)\n",
      "Episode 49900/300000 ( TD_error: -0.17916638398150297, reward: -14.0,-14.0)\n",
      "Episode 50000/300000 ( TD_error: -1.7513656561168016, reward: -17.0,-17.0)\n",
      "Episode 50100/300000 ( TD_error: -0.15972908342350056, reward: -10.0,14.0)\n",
      "Episode 50200/300000 ( TD_error: 2.500239005501488, reward: 13.0,-13.0)\n",
      "Episode 50300/300000 ( TD_error: -0.19578174627938338, reward: -11.0,-10.0)\n",
      "Episode 50400/300000 ( TD_error: 1.9789425713612971, reward: 15.0,-15.0)\n",
      "Episode 50500/300000 ( TD_error: -0.6826942267780192, reward: -12.0,-10.0)\n",
      "Episode 50600/300000 ( TD_error: -0.38252048397021543, reward: -11.0,-14.0)\n",
      "Episode 50700/300000 ( TD_error: -9.867312271679644, reward: -10.0,15.0)\n",
      "Episode 50800/300000 ( TD_error: -0.3837424124633193, reward: -14.0,-11.0)\n",
      "Episode 50900/300000 ( TD_error: 1.229993628425507, reward: 12.0,15.0)\n",
      "Episode 51000/300000 ( TD_error: -9.879597109521738, reward: -10.0,15.0)\n",
      "Episode 51100/300000 ( TD_error: 1.1836216690566996, reward: 13.0,15.0)\n",
      "Episode 51200/300000 ( TD_error: -0.2584092995275107, reward: -13.0,-12.0)\n",
      "Episode 51300/300000 ( TD_error: 1.1587603557373518, reward: 12.0,-16.0)\n",
      "Episode 51400/300000 ( TD_error: 1.8800508035740007, reward: 12.0,15.0)\n",
      "Episode 51500/300000 ( TD_error: -1.6084307056095284, reward: -15.0,-21.0)\n",
      "Episode 51600/300000 ( TD_error: -0.13088729010956524, reward: -13.0,-99.0)\n",
      "Episode 51700/300000 ( TD_error: -0.1005171670171503, reward: -12.0,-13.0)\n",
      "Episode 51800/300000 ( TD_error: 1.6434454035450266, reward: -11.0,-10.0)\n",
      "Episode 51900/300000 ( TD_error: 1.2399633905441894, reward: 13.0,-13.0)\n",
      "Episode 52000/300000 ( TD_error: 5.0419013575166005, reward: -10.0,15.0)\n",
      "Episode 52100/300000 ( TD_error: -0.42710870730542094, reward: -11.0,13.0)\n",
      "Episode 52200/300000 ( TD_error: -10.477158916071286, reward: -10.0,-10.0)\n",
      "Episode 52300/300000 ( TD_error: -0.5764327944111987, reward: -16.0,-10.0)\n",
      "Episode 52400/300000 ( TD_error: -9.882302884838607, reward: -10.0,-10.0)\n",
      "Episode 52500/300000 ( TD_error: 2.00580832071375, reward: 12.0,-10.0)\n",
      "Episode 52600/300000 ( TD_error: -0.13994737605173846, reward: -10.0,-10.0)\n",
      "Episode 52700/300000 ( TD_error: -0.113363149206263, reward: -14.0,-10.0)\n",
      "Episode 52800/300000 ( TD_error: 1.9003314997923182, reward: 15.0,-15.0)\n",
      "Episode 52900/300000 ( TD_error: -0.12493025757946175, reward: -12.0,13.0)\n",
      "Episode 53000/300000 ( TD_error: 2.2822846667250345, reward: 14.0,-10.0)\n",
      "Episode 53100/300000 ( TD_error: 1.8424507197061342, reward: 13.0,-11.0)\n",
      "Episode 53200/300000 ( TD_error: -0.19026600226810952, reward: -14.0,-10.0)\n",
      "Episode 53300/300000 ( TD_error: -0.15075329909855117, reward: -12.0,-13.0)\n",
      "Episode 53400/300000 ( TD_error: -0.14261861635078876, reward: -12.0,15.0)\n",
      "Episode 53500/300000 ( TD_error: 1.187631102264488, reward: 15.0,-16.0)\n",
      "Episode 53600/300000 ( TD_error: -0.13748672836222475, reward: -13.0,-10.0)\n",
      "Episode 53700/300000 ( TD_error: -2.295592934743432, reward: -12.0,-13.0)\n",
      "Episode 53800/300000 ( TD_error: -0.16464404456247816, reward: -13.0,-10.0)\n",
      "Episode 53900/300000 ( TD_error: -0.14455392073377915, reward: -11.0,-12.0)\n",
      "Episode 54000/300000 ( TD_error: -0.1468631699594134, reward: -13.0,-12.0)\n",
      "Episode 54100/300000 ( TD_error: 0.11438016257731753, reward: -11.0,-12.0)\n",
      "Episode 54200/300000 ( TD_error: 1.9823312042787393, reward: 7.0,-11.0)\n",
      "Episode 54300/300000 ( TD_error: 0.2758502275804595, reward: -11.0,-14.0)\n",
      "Episode 54400/300000 ( TD_error: 1.9605048272292511, reward: 13.0,-10.0)\n",
      "Episode 54500/300000 ( TD_error: -0.12270361702466825, reward: -16.0,13.0)\n",
      "Episode 54600/300000 ( TD_error: 1.4271064542444494, reward: 15.0,13.0)\n",
      "Episode 54700/300000 ( TD_error: -5.786724396315087, reward: -10.0,-13.0)\n",
      "Episode 54800/300000 ( TD_error: 1.2339806536065243, reward: 15.0,-24.0)\n",
      "Episode 54900/300000 ( TD_error: 0.5284351008668136, reward: -13.0,-12.0)\n",
      "Episode 55000/300000 ( TD_error: -0.15862532801260887, reward: -12.0,-14.0)\n",
      "Episode 55100/300000 ( TD_error: 1.6308100622861215, reward: -10.0,14.0)\n",
      "Episode 55200/300000 ( TD_error: 0.8554449994960116, reward: -39.0,-21.0)\n",
      "Episode 55300/300000 ( TD_error: 0.8533806159764978, reward: -15.0,-15.0)\n",
      "Episode 55400/300000 ( TD_error: 0.30253176099991386, reward: -26.0,-12.0)\n",
      "Episode 55500/300000 ( TD_error: -0.2300302126880469, reward: -10.0,-11.0)\n",
      "Episode 55600/300000 ( TD_error: 0.6157520593217463, reward: -11.0,15.0)\n",
      "Episode 55700/300000 ( TD_error: -0.3030039189567706, reward: -13.0,-10.0)\n",
      "Episode 55800/300000 ( TD_error: -0.2122307941281436, reward: -12.0,-19.0)\n",
      "Episode 55900/300000 ( TD_error: -0.1705550764999808, reward: -12.0,13.0)\n",
      "Episode 56000/300000 ( TD_error: 2.245327432829469, reward: 14.0,15.0)\n",
      "Episode 56100/300000 ( TD_error: 1.2938543243680205, reward: 15.0,-12.0)\n",
      "Episode 56200/300000 ( TD_error: -10.534667747025589, reward: -10.0,-12.0)\n",
      "Episode 56300/300000 ( TD_error: 2.038358682245909, reward: 13.0,14.0)\n",
      "Episode 56400/300000 ( TD_error: -1.225430483308898, reward: -13.0,-16.0)\n",
      "Episode 56500/300000 ( TD_error: -0.14549437273023713, reward: -13.0,13.0)\n",
      "Episode 56600/300000 ( TD_error: 2.9563314672135697, reward: 15.0,-10.0)\n",
      "Episode 56700/300000 ( TD_error: 1.1968922135416236, reward: -11.0,15.0)\n",
      "Episode 56800/300000 ( TD_error: -0.0982806098411162, reward: -16.0,14.0)\n",
      "Episode 56900/300000 ( TD_error: -0.08721034562716135, reward: -11.0,15.0)\n",
      "Episode 57000/300000 ( TD_error: 0.018287452740255894, reward: -11.0,-11.0)\n",
      "Episode 57100/300000 ( TD_error: 0.6439921429852049, reward: -24.0,-10.0)\n",
      "Episode 57200/300000 ( TD_error: -9.895230208535896, reward: -10.0,-12.0)\n",
      "Episode 57300/300000 ( TD_error: -0.11695155641989441, reward: -13.0,-14.0)\n",
      "Episode 57400/300000 ( TD_error: 0.06048184826563752, reward: -10.0,15.0)\n",
      "Episode 57500/300000 ( TD_error: -0.16657522779530165, reward: -17.0,-10.0)\n",
      "Episode 57600/300000 ( TD_error: 2.974774243955066, reward: 15.0,-12.0)\n",
      "Episode 57700/300000 ( TD_error: -0.12951537194188667, reward: -12.0,15.0)\n",
      "Episode 57800/300000 ( TD_error: 1.3534964642903478, reward: 15.0,-12.0)\n",
      "Episode 57900/300000 ( TD_error: 0.47213996306587624, reward: -12.0,-11.0)\n",
      "Episode 58000/300000 ( TD_error: -0.1699293499553356, reward: -15.0,15.0)\n",
      "Episode 58100/300000 ( TD_error: 0.08440739592044455, reward: -10.0,-13.0)\n",
      "Episode 58200/300000 ( TD_error: 1.7288462653422068, reward: 14.0,-11.0)\n",
      "Episode 58300/300000 ( TD_error: 0.5610091522976006, reward: -11.0,15.0)\n",
      "Episode 58400/300000 ( TD_error: -10.511804065800282, reward: -10.0,-43.0)\n",
      "Episode 58500/300000 ( TD_error: 1.2759993061649388, reward: 13.0,-18.0)\n",
      "Episode 58600/300000 ( TD_error: -0.4221530426645703, reward: -11.0,-10.0)\n",
      "Episode 58700/300000 ( TD_error: -10.496226156303834, reward: -10.0,13.0)\n",
      "Episode 58800/300000 ( TD_error: -0.5255179602126923, reward: -11.0,13.0)\n",
      "Episode 58900/300000 ( TD_error: -0.6748101386102672, reward: -15.0,-16.0)\n",
      "Episode 59000/300000 ( TD_error: -0.6208106481013624, reward: -13.0,-15.0)\n",
      "Episode 59100/300000 ( TD_error: -0.45162808007574107, reward: -10.0,-11.0)\n",
      "Episode 59200/300000 ( TD_error: -0.28299725633084005, reward: -17.0,13.0)\n",
      "Episode 59300/300000 ( TD_error: -0.3429646600442604, reward: -13.0,-11.0)\n",
      "Episode 59400/300000 ( TD_error: -0.2651949907680766, reward: -12.0,-11.0)\n",
      "Episode 59500/300000 ( TD_error: -0.24616563449484197, reward: -12.0,15.0)\n",
      "Episode 59600/300000 ( TD_error: 1.3264945123056884, reward: 13.0,-11.0)\n",
      "Episode 59700/300000 ( TD_error: -0.2946699429212085, reward: -16.0,-17.0)\n",
      "Episode 59800/300000 ( TD_error: -0.20734139366225257, reward: -11.0,-10.0)\n",
      "Episode 59900/300000 ( TD_error: -0.1676545552136437, reward: -12.0,13.0)\n",
      "Episode 60000/300000 ( TD_error: -0.12357280591710751, reward: -12.0,13.0)\n",
      "Episode 60100/300000 ( TD_error: 1.1666049726022951, reward: 12.0,13.0)\n",
      "Episode 60200/300000 ( TD_error: -9.860310565639471, reward: -10.0,-10.0)\n",
      "Episode 60300/300000 ( TD_error: -0.3703558780876408, reward: -11.0,-10.0)\n",
      "Episode 60400/300000 ( TD_error: -0.44520895997271825, reward: -15.0,12.0)\n",
      "Episode 60500/300000 ( TD_error: 1.334631551046325, reward: 13.0,-21.0)\n",
      "Episode 60600/300000 ( TD_error: 0.5251964127352213, reward: -10.0,-10.0)\n",
      "Episode 60700/300000 ( TD_error: -0.36507621599079965, reward: -17.0,-11.0)\n",
      "Episode 60800/300000 ( TD_error: 1.195376075415827, reward: 12.0,-13.0)\n",
      "Episode 60900/300000 ( TD_error: 1.2260003517203328, reward: 14.0,-20.0)\n",
      "Episode 61000/300000 ( TD_error: -0.6385187209324545, reward: -15.0,-12.0)\n",
      "Episode 61100/300000 ( TD_error: -2.6577225646812366, reward: -11.0,10.0)\n",
      "Episode 61200/300000 ( TD_error: -0.24137194429510167, reward: -10.0,14.0)\n",
      "Episode 61300/300000 ( TD_error: 0.7589696001222332, reward: -78.0,-14.0)\n",
      "Episode 61400/300000 ( TD_error: 0.709861835798085, reward: -15.0,-10.0)\n",
      "Episode 61500/300000 ( TD_error: -0.621477888061607, reward: -11.0,-13.0)\n",
      "Episode 61600/300000 ( TD_error: 1.2166948811536629, reward: 13.0,13.0)\n",
      "Episode 61700/300000 ( TD_error: -0.9303949940413716, reward: -43.0,-16.0)\n",
      "Episode 61800/300000 ( TD_error: -0.7464713031921821, reward: -14.0,12.0)\n",
      "Episode 61900/300000 ( TD_error: -0.5903690374842654, reward: -10.0,-13.0)\n",
      "Episode 62000/300000 ( TD_error: 1.1257563261727541, reward: 13.0,-10.0)\n",
      "Episode 62100/300000 ( TD_error: -0.3792787352395157, reward: -15.0,-14.0)\n",
      "Episode 62200/300000 ( TD_error: 2.067115060485219, reward: 14.0,15.0)\n",
      "Episode 62300/300000 ( TD_error: -9.855850194743777, reward: -10.0,-10.0)\n",
      "Episode 62400/300000 ( TD_error: 2.005415869745891, reward: 15.0,-11.0)\n",
      "Episode 62500/300000 ( TD_error: -0.22642778530664298, reward: -12.0,13.0)\n",
      "Episode 62600/300000 ( TD_error: 0.7349820800235012, reward: -13.0,-11.0)\n",
      "Episode 62700/300000 ( TD_error: -0.250128708517261, reward: -16.0,12.0)\n",
      "Episode 62800/300000 ( TD_error: 1.4565814479630417, reward: 13.0,-10.0)\n",
      "Episode 62900/300000 ( TD_error: -0.3014324355384108, reward: -11.0,-12.0)\n",
      "Episode 63000/300000 ( TD_error: -0.4107928971845807, reward: -14.0,-20.0)\n",
      "Episode 63100/300000 ( TD_error: 1.0468066067778787, reward: 13.0,-15.0)\n",
      "Episode 63200/300000 ( TD_error: -0.25258189969265565, reward: -15.0,15.0)\n",
      "Episode 63300/300000 ( TD_error: 1.072984692005185, reward: 13.0,14.0)\n",
      "Episode 63400/300000 ( TD_error: -0.7722727867149182, reward: -22.0,-16.0)\n",
      "Episode 63500/300000 ( TD_error: 6.808358301463164, reward: -10.0,-14.0)\n",
      "Episode 63600/300000 ( TD_error: -1.6464744809017535, reward: -15.0,15.0)\n",
      "Episode 63700/300000 ( TD_error: -1.5046436046947633, reward: -20.0,15.0)\n",
      "Episode 63800/300000 ( TD_error: -0.25418801115638257, reward: -10.0,-26.0)\n",
      "Episode 63900/300000 ( TD_error: -0.22963253094439828, reward: -10.0,15.0)\n",
      "Episode 64000/300000 ( TD_error: -0.3615040601603905, reward: -10.0,-10.0)\n",
      "Episode 64100/300000 ( TD_error: -0.29988423364925243, reward: -12.0,-11.0)\n",
      "Episode 64200/300000 ( TD_error: -0.21866321726318017, reward: -14.0,15.0)\n",
      "Episode 64300/300000 ( TD_error: -0.17586876358840886, reward: -13.0,-12.0)\n",
      "Episode 64400/300000 ( TD_error: -0.19575958549447758, reward: -10.0,15.0)\n",
      "Episode 64500/300000 ( TD_error: -1.319964292395337, reward: -15.0,-15.0)\n",
      "Episode 64600/300000 ( TD_error: -2.0653112883855016, reward: -15.0,-12.0)\n",
      "Episode 64700/300000 ( TD_error: -0.15108141458304214, reward: -16.0,-17.0)\n",
      "Episode 64800/300000 ( TD_error: -0.16670525140015346, reward: -13.0,12.0)\n",
      "Episode 64900/300000 ( TD_error: 0.8069408485537277, reward: -23.0,-12.0)\n",
      "Episode 65000/300000 ( TD_error: -0.16213829909538546, reward: -10.0,13.0)\n",
      "Episode 65100/300000 ( TD_error: 2.934251634005543, reward: 12.0,-11.0)\n",
      "Episode 65200/300000 ( TD_error: 2.675042148920299, reward: 15.0,-17.0)\n",
      "Episode 65300/300000 ( TD_error: 2.9173009211129974, reward: 13.0,-11.0)\n",
      "Episode 65400/300000 ( TD_error: 2.295808977432567, reward: 15.0,-10.0)\n",
      "Episode 65500/300000 ( TD_error: -1.4095661286511465, reward: -14.0,-11.0)\n",
      "Episode 65600/300000 ( TD_error: -0.1425752359636263, reward: -11.0,-11.0)\n",
      "Episode 65700/300000 ( TD_error: 1.973759575048049, reward: 14.0,13.0)\n",
      "Episode 65800/300000 ( TD_error: -0.4488322726994669, reward: -14.0,-14.0)\n",
      "Episode 65900/300000 ( TD_error: -0.48651844277981837, reward: -14.0,-10.0)\n",
      "Episode 66000/300000 ( TD_error: -0.4068541277731548, reward: -57.0,13.0)\n",
      "Episode 66100/300000 ( TD_error: 1.8830464925901917, reward: 13.0,-11.0)\n",
      "Episode 66200/300000 ( TD_error: 0.6663263351238236, reward: -17.0,-10.0)\n",
      "Episode 66300/300000 ( TD_error: 0.5682322641162578, reward: -14.0,14.0)\n",
      "Episode 66400/300000 ( TD_error: -0.18838456087489863, reward: -13.0,-12.0)\n",
      "Episode 66500/300000 ( TD_error: -0.20475248109957533, reward: -14.0,-11.0)\n",
      "Episode 66600/300000 ( TD_error: 1.710064569014113, reward: 15.0,-10.0)\n",
      "Episode 66700/300000 ( TD_error: 2.0842644035400957, reward: 13.0,-10.0)\n",
      "Episode 66800/300000 ( TD_error: -0.16023824290983857, reward: -16.0,-10.0)\n",
      "Episode 66900/300000 ( TD_error: -0.19946401262977886, reward: -17.0,-12.0)\n",
      "Episode 67000/300000 ( TD_error: 0.48474084025114994, reward: -10.0,-16.0)\n",
      "Episode 67100/300000 ( TD_error: -0.20490577694177325, reward: -15.0,14.0)\n",
      "Episode 67200/300000 ( TD_error: -0.17087121836783226, reward: -18.0,-18.0)\n",
      "Episode 67300/300000 ( TD_error: -0.17010552950334556, reward: -11.0,14.0)\n",
      "Episode 67400/300000 ( TD_error: -1.216356381157354, reward: -30.0,-10.0)\n",
      "Episode 67500/300000 ( TD_error: 0.7869492821842865, reward: -13.0,-10.0)\n",
      "Episode 67600/300000 ( TD_error: -0.11185449067233222, reward: -12.0,-12.0)\n",
      "Episode 67700/300000 ( TD_error: -9.863840431455781, reward: -10.0,14.0)\n",
      "Episode 67800/300000 ( TD_error: -0.1979972900887521, reward: -13.0,14.0)\n",
      "Episode 67900/300000 ( TD_error: -0.14628688406766432, reward: -12.0,-11.0)\n",
      "Episode 68000/300000 ( TD_error: -0.1147064221138594, reward: -15.0,-11.0)\n",
      "Episode 68100/300000 ( TD_error: 1.1831429155012483, reward: 15.0,-16.0)\n",
      "Episode 68200/300000 ( TD_error: -0.10239563288398568, reward: -11.0,12.0)\n",
      "Episode 68300/300000 ( TD_error: 2.2808593477883066, reward: 14.0,-11.0)\n",
      "Episode 68400/300000 ( TD_error: 1.7134147064100118, reward: 12.0,14.0)\n",
      "Episode 68500/300000 ( TD_error: -0.2650587349612179, reward: -18.0,-14.0)\n",
      "Episode 68600/300000 ( TD_error: 1.9529901281286917, reward: 15.0,-10.0)\n",
      "Episode 68700/300000 ( TD_error: 1.1499459315333875, reward: 15.0,13.0)\n",
      "Episode 68800/300000 ( TD_error: -0.13986384957115838, reward: -14.0,-12.0)\n",
      "Episode 68900/300000 ( TD_error: -0.17754384451066407, reward: -13.0,-10.0)\n",
      "Episode 69000/300000 ( TD_error: -0.1693646909656339, reward: -14.0,13.0)\n",
      "Episode 69100/300000 ( TD_error: 1.4076116926697462, reward: 13.0,-15.0)\n",
      "Episode 69200/300000 ( TD_error: -10.519132021975958, reward: -10.0,-11.0)\n",
      "Episode 69300/300000 ( TD_error: -0.1392390151152263, reward: -12.0,11.0)\n",
      "Episode 69400/300000 ( TD_error: -4.967063559201913, reward: -12.0,-15.0)\n",
      "Episode 69500/300000 ( TD_error: -0.12886305904142858, reward: -10.0,-10.0)\n",
      "Episode 69600/300000 ( TD_error: 0.15047239856189965, reward: -10.0,-10.0)\n",
      "Episode 69700/300000 ( TD_error: -0.23686980457066387, reward: -12.0,-10.0)\n",
      "Episode 69800/300000 ( TD_error: -0.15908075863403948, reward: -16.0,12.0)\n",
      "Episode 69900/300000 ( TD_error: -0.4803653830365553, reward: -13.0,-11.0)\n",
      "Episode 70000/300000 ( TD_error: 0.2535982531526013, reward: -10.0,-12.0)\n",
      "Episode 70100/300000 ( TD_error: -1.166349761783012, reward: -10.0,-11.0)\n",
      "Episode 70200/300000 ( TD_error: -0.3215200751386931, reward: -11.0,-13.0)\n",
      "Episode 70300/300000 ( TD_error: 0.7014287409095008, reward: -13.0,-10.0)\n",
      "Episode 70400/300000 ( TD_error: -0.42985041580477823, reward: -10.0,-13.0)\n",
      "Episode 70500/300000 ( TD_error: -9.863212102814002, reward: -10.0,-13.0)\n",
      "Episode 70600/300000 ( TD_error: -10.452718588219913, reward: -10.0,-14.0)\n",
      "Episode 70700/300000 ( TD_error: -0.5202484966849417, reward: -12.0,-10.0)\n",
      "Episode 70800/300000 ( TD_error: 6.734281455096128, reward: -10.0,13.0)\n",
      "Episode 70900/300000 ( TD_error: -0.7632034996998494, reward: -11.0,-12.0)\n",
      "Episode 71000/300000 ( TD_error: -0.5311216989188408, reward: -18.0,-10.0)\n",
      "Episode 71100/300000 ( TD_error: 0.8102739379726511, reward: -11.0,9.0)\n",
      "Episode 71200/300000 ( TD_error: -1.27863368742066, reward: -11.0,-14.0)\n",
      "Episode 71300/300000 ( TD_error: -0.23467715785616328, reward: -10.0,-13.0)\n",
      "Episode 71400/300000 ( TD_error: -0.20035314126365122, reward: -12.0,12.0)\n",
      "Episode 71500/300000 ( TD_error: -0.17411403234729672, reward: -12.0,-11.0)\n",
      "Episode 71600/300000 ( TD_error: -0.13795772240145965, reward: -13.0,-17.0)\n",
      "Episode 71700/300000 ( TD_error: 0.00018104521594697331, reward: -11.0,-16.0)\n",
      "Episode 71800/300000 ( TD_error: -0.32464082037596675, reward: -10.0,14.0)\n",
      "Episode 71900/300000 ( TD_error: 6.4999486500673145, reward: -10.0,-11.0)\n",
      "Episode 72000/300000 ( TD_error: -10.454775771122954, reward: -10.0,-15.0)\n",
      "Episode 72100/300000 ( TD_error: 1.2286427821257178, reward: 15.0,-15.0)\n",
      "Episode 72200/300000 ( TD_error: -0.6768607979969765, reward: -12.0,15.0)\n",
      "Episode 72300/300000 ( TD_error: -0.4904473474105009, reward: -12.0,-13.0)\n",
      "Episode 72400/300000 ( TD_error: -1.078634099237732, reward: -10.0,-10.0)\n",
      "Episode 72500/300000 ( TD_error: -0.5358241070475467, reward: -11.0,-25.0)\n",
      "Episode 72600/300000 ( TD_error: -0.43235068133090504, reward: -10.0,11.0)\n",
      "Episode 72700/300000 ( TD_error: -0.2967958770314638, reward: -14.0,14.0)\n",
      "Episode 72800/300000 ( TD_error: 0.12822968363488396, reward: -11.0,-12.0)\n",
      "Episode 72900/300000 ( TD_error: 0.675232198550189, reward: -10.0,-10.0)\n",
      "Episode 73000/300000 ( TD_error: -0.2666102048901715, reward: -14.0,-15.0)\n",
      "Episode 73100/300000 ( TD_error: 6.766357362261513, reward: -10.0,-14.0)\n",
      "Episode 73200/300000 ( TD_error: -1.368365147742388, reward: -29.0,-12.0)\n",
      "Episode 73300/300000 ( TD_error: -1.2195825825517321, reward: -12.0,-10.0)\n",
      "Episode 73400/300000 ( TD_error: 1.0513086845034203, reward: 15.0,-12.0)\n",
      "Episode 73500/300000 ( TD_error: 1.6180407322754151, reward: 13.0,10.0)\n",
      "Episode 73600/300000 ( TD_error: -0.26882871232929073, reward: -15.0,-12.0)\n",
      "Episode 73700/300000 ( TD_error: 2.520972793738557, reward: 13.0,-21.0)\n",
      "Episode 73800/300000 ( TD_error: 2.128824760769637, reward: 12.0,-15.0)\n",
      "Episode 73900/300000 ( TD_error: 1.8199829804530983, reward: 12.0,-16.0)\n",
      "Episode 74000/300000 ( TD_error: 0.6705714571492427, reward: -10.0,13.0)\n",
      "Episode 74100/300000 ( TD_error: -0.15172185816973105, reward: -15.0,13.0)\n",
      "Episode 74200/300000 ( TD_error: -1.312161872058418, reward: -45.0,-14.0)\n",
      "Episode 74300/300000 ( TD_error: 1.9117718422752947, reward: 13.0,-15.0)\n",
      "Episode 74400/300000 ( TD_error: -0.20333921327273696, reward: -11.0,-11.0)\n",
      "Episode 74500/300000 ( TD_error: -0.281976423730363, reward: -14.0,-12.0)\n",
      "Episode 74600/300000 ( TD_error: 0.13460539194193277, reward: -11.0,-13.0)\n",
      "Episode 74700/300000 ( TD_error: -0.1996409040928997, reward: -13.0,13.0)\n",
      "Episode 74800/300000 ( TD_error: -0.516744555304804, reward: -13.0,-19.0)\n",
      "Episode 74900/300000 ( TD_error: -0.4320725685150544, reward: -15.0,-13.0)\n",
      "Episode 75000/300000 ( TD_error: 2.108229123850008, reward: 15.0,14.0)\n",
      "Episode 75100/300000 ( TD_error: -0.2773777564396642, reward: -10.0,-14.0)\n",
      "Episode 75200/300000 ( TD_error: 1.821826868103364, reward: 13.0,-10.0)\n",
      "Episode 75300/300000 ( TD_error: -0.18817600106230348, reward: -16.0,15.0)\n",
      "Episode 75400/300000 ( TD_error: -1.090075014241906, reward: -13.0,13.0)\n",
      "Episode 75500/300000 ( TD_error: -0.2557864937569443, reward: -13.0,15.0)\n",
      "Episode 75600/300000 ( TD_error: 2.2540360637454446, reward: 14.0,-22.0)\n",
      "Episode 75700/300000 ( TD_error: 0.030205494734443228, reward: -10.0,-10.0)\n",
      "Episode 75800/300000 ( TD_error: -0.4530575096571985, reward: -13.0,-11.0)\n",
      "Episode 75900/300000 ( TD_error: -0.5551367744507472, reward: -11.0,-10.0)\n",
      "Episode 76000/300000 ( TD_error: -0.2624810366434094, reward: -11.0,-11.0)\n",
      "Episode 76100/300000 ( TD_error: -0.5758746337316758, reward: -22.0,-12.0)\n",
      "Episode 76200/300000 ( TD_error: 1.6625017129341435, reward: 13.0,15.0)\n",
      "Episode 76300/300000 ( TD_error: 3.0107993282299677, reward: 14.0,-15.0)\n",
      "Episode 76400/300000 ( TD_error: -0.7341988123819974, reward: -10.0,-13.0)\n",
      "Episode 76500/300000 ( TD_error: -1.1303474017628954, reward: -12.0,-18.0)\n",
      "Episode 76600/300000 ( TD_error: 2.602776926161879, reward: 14.0,-13.0)\n",
      "Episode 76700/300000 ( TD_error: -0.1665422932240448, reward: -13.0,-11.0)\n",
      "Episode 76800/300000 ( TD_error: 2.839048343186545, reward: 14.0,-10.0)\n",
      "Episode 76900/300000 ( TD_error: -2.575944137106646, reward: -43.0,-18.0)\n",
      "Episode 77000/300000 ( TD_error: 0.8456415366496124, reward: -25.0,-10.0)\n",
      "Episode 77100/300000 ( TD_error: -2.681283244194752, reward: -15.0,-16.0)\n",
      "Episode 77200/300000 ( TD_error: 0.5466266649017433, reward: -10.0,-14.0)\n",
      "Episode 77300/300000 ( TD_error: -0.6297989147489922, reward: -15.0,14.0)\n",
      "Episode 77400/300000 ( TD_error: -0.39271489801688375, reward: -11.0,13.0)\n",
      "Episode 77500/300000 ( TD_error: 2.2494015186883574, reward: 13.0,-10.0)\n",
      "Episode 77600/300000 ( TD_error: 2.0041566148920436, reward: 15.0,-13.0)\n",
      "Episode 77700/300000 ( TD_error: -0.22338165838681423, reward: -12.0,-10.0)\n",
      "Episode 77800/300000 ( TD_error: 0.3247435010683013, reward: -11.0,-11.0)\n",
      "Episode 77900/300000 ( TD_error: -0.16668031103380265, reward: -11.0,-13.0)\n",
      "Episode 78000/300000 ( TD_error: -0.19227791050610232, reward: -16.0,13.0)\n",
      "Episode 78100/300000 ( TD_error: -0.16493199545419124, reward: -12.0,-11.0)\n",
      "Episode 78200/300000 ( TD_error: -0.2564768027057571, reward: -16.0,-12.0)\n",
      "Episode 78300/300000 ( TD_error: 2.8430530706291286, reward: 13.0,15.0)\n",
      "Episode 78400/300000 ( TD_error: -9.869076884986233, reward: -10.0,-12.0)\n",
      "Episode 78500/300000 ( TD_error: -0.17357301233909883, reward: -13.0,-12.0)\n",
      "Episode 78600/300000 ( TD_error: -0.3448478574660516, reward: -20.0,15.0)\n",
      "Episode 78700/300000 ( TD_error: -0.03241773285089877, reward: -11.0,15.0)\n",
      "Episode 78800/300000 ( TD_error: 1.983698071860338, reward: 15.0,-13.0)\n",
      "Episode 78900/300000 ( TD_error: 1.360470212362031, reward: 15.0,-12.0)\n",
      "Episode 79000/300000 ( TD_error: -2.385252061784577, reward: -10.0,-10.0)\n",
      "Episode 79100/300000 ( TD_error: -0.2430415977655711, reward: -16.0,14.0)\n",
      "Episode 79200/300000 ( TD_error: -0.23623453289667662, reward: -12.0,-14.0)\n",
      "Episode 79300/300000 ( TD_error: -0.9658500810795996, reward: -12.0,15.0)\n",
      "Episode 79400/300000 ( TD_error: -0.16738326924520486, reward: -12.0,-12.0)\n",
      "Episode 79500/300000 ( TD_error: 1.2113396998133594, reward: 14.0,-27.0)\n",
      "Episode 79600/300000 ( TD_error: 1.2297688581108273, reward: 12.0,15.0)\n",
      "Episode 79700/300000 ( TD_error: 0.48013780069937617, reward: -10.0,13.0)\n",
      "Episode 79800/300000 ( TD_error: 1.0978723672701793, reward: 13.0,13.0)\n",
      "Episode 79900/300000 ( TD_error: -0.5333935202160616, reward: -12.0,-10.0)\n",
      "Episode 80000/300000 ( TD_error: -0.5143916232703551, reward: -50.0,-54.0)\n",
      "Episode 80100/300000 ( TD_error: -0.6879361382980012, reward: -13.0,14.0)\n",
      "Episode 80200/300000 ( TD_error: 1.1543668076342453, reward: 15.0,13.0)\n",
      "Episode 80300/300000 ( TD_error: 0.9753031049632175, reward: 13.0,-10.0)\n",
      "Episode 80400/300000 ( TD_error: 1.0737081306492695, reward: 13.0,-11.0)\n",
      "Episode 80500/300000 ( TD_error: 1.0626842293807925, reward: 10.0,14.0)\n",
      "Episode 80600/300000 ( TD_error: -0.28284181406622366, reward: -11.0,-14.0)\n",
      "Episode 80700/300000 ( TD_error: 0.996621593462959, reward: 11.0,-12.0)\n",
      "Episode 80800/300000 ( TD_error: 1.0359808394594103, reward: 13.0,-11.0)\n",
      "Episode 80900/300000 ( TD_error: 1.224748183910362, reward: 13.0,-10.0)\n",
      "Episode 81000/300000 ( TD_error: -0.5511348187257727, reward: -10.0,-15.0)\n",
      "Episode 81100/300000 ( TD_error: 1.9175609265159421, reward: 15.0,-13.0)\n",
      "Episode 81200/300000 ( TD_error: -2.754721298065414, reward: -20.0,-10.0)\n",
      "Episode 81300/300000 ( TD_error: 1.1763580279232904, reward: 15.0,-11.0)\n",
      "Episode 81400/300000 ( TD_error: -0.36521648105703886, reward: -10.0,-11.0)\n",
      "Episode 81500/300000 ( TD_error: -4.444685659058612, reward: -15.0,-12.0)\n",
      "Episode 81600/300000 ( TD_error: 0.9222370851502029, reward: 13.0,-12.0)\n",
      "Episode 81700/300000 ( TD_error: -0.553523032491702, reward: -14.0,-10.0)\n",
      "Episode 81800/300000 ( TD_error: 0.9709732844374477, reward: 12.0,-10.0)\n",
      "Episode 81900/300000 ( TD_error: -0.5358419678564879, reward: -11.0,-13.0)\n",
      "Episode 82000/300000 ( TD_error: -0.77939289061732, reward: -13.0,12.0)\n",
      "Episode 82100/300000 ( TD_error: -0.6158823748460689, reward: -14.0,-13.0)\n",
      "Episode 82200/300000 ( TD_error: -0.3697835852856546, reward: -12.0,-13.0)\n",
      "Episode 82300/300000 ( TD_error: 1.7818640441754354, reward: 13.0,-13.0)\n",
      "Episode 82400/300000 ( TD_error: -0.17696544802526493, reward: -12.0,-14.0)\n",
      "Episode 82500/300000 ( TD_error: -0.17664805056188015, reward: -17.0,13.0)\n",
      "Episode 82600/300000 ( TD_error: 0.9828973345826171, reward: -27.0,-17.0)\n",
      "Episode 82700/300000 ( TD_error: -1.4058231792315947, reward: -32.0,-12.0)\n",
      "Episode 82800/300000 ( TD_error: 1.7026535973254657, reward: 14.0,13.0)\n",
      "Episode 82900/300000 ( TD_error: -0.026471712841955153, reward: -10.0,-14.0)\n",
      "Episode 83000/300000 ( TD_error: 1.0774715929078957, reward: 11.0,-12.0)\n",
      "Episode 83100/300000 ( TD_error: -0.17668266530555066, reward: -31.0,-14.0)\n",
      "Episode 83200/300000 ( TD_error: 1.006537476252824, reward: 12.0,-10.0)\n",
      "Episode 83300/300000 ( TD_error: 0.08825365429976983, reward: -11.0,-12.0)\n",
      "Episode 83400/300000 ( TD_error: -0.1579412452765867, reward: -11.0,-11.0)\n",
      "Episode 83500/300000 ( TD_error: 0.8967307536422542, reward: 13.0,-13.0)\n",
      "Episode 83600/300000 ( TD_error: 0.8169107884597553, reward: 13.0,-10.0)\n",
      "Episode 83700/300000 ( TD_error: 0.8283170539233096, reward: 15.0,-16.0)\n",
      "Episode 83800/300000 ( TD_error: -0.18565215835167503, reward: -15.0,-12.0)\n",
      "Episode 83900/300000 ( TD_error: 0.16854409938783022, reward: -10.0,13.0)\n",
      "Episode 84000/300000 ( TD_error: 0.08580167334747912, reward: -11.0,-17.0)\n",
      "Episode 84100/300000 ( TD_error: -0.10363410633819026, reward: -13.0,-10.0)\n",
      "Episode 84200/300000 ( TD_error: -0.15181786787639417, reward: -10.0,11.0)\n",
      "Episode 84300/300000 ( TD_error: -0.14869854747575317, reward: -12.0,-15.0)\n",
      "Episode 84400/300000 ( TD_error: 1.5169518319207462, reward: 15.0,11.0)\n",
      "Episode 84500/300000 ( TD_error: -1.1153910180479336, reward: -14.0,-12.0)\n",
      "Episode 84600/300000 ( TD_error: -9.90662438099414, reward: -10.0,11.0)\n",
      "Episode 84700/300000 ( TD_error: -0.06501592428022285, reward: -11.0,14.0)\n",
      "Episode 84800/300000 ( TD_error: -0.3914379380595081, reward: -38.0,-11.0)\n",
      "Episode 84900/300000 ( TD_error: -0.3803004577254834, reward: -12.0,-22.0)\n",
      "Episode 85000/300000 ( TD_error: 1.1527180720539687, reward: 13.0,-55.0)\n",
      "Episode 85100/300000 ( TD_error: -0.6111990865535057, reward: -10.0,-10.0)\n",
      "Episode 85200/300000 ( TD_error: -0.5424156879113395, reward: -11.0,-10.0)\n",
      "Episode 85300/300000 ( TD_error: -0.34990731669633934, reward: -12.0,15.0)\n",
      "Episode 85400/300000 ( TD_error: -0.3348408370373708, reward: -12.0,-10.0)\n",
      "Episode 85500/300000 ( TD_error: -1.4140730076657633, reward: -10.0,-16.0)\n",
      "Episode 85600/300000 ( TD_error: -0.1569014034209264, reward: -10.0,-10.0)\n",
      "Episode 85700/300000 ( TD_error: -0.014026539599591992, reward: -10.0,-13.0)\n",
      "Episode 85800/300000 ( TD_error: -9.910579671401122, reward: -10.0,-11.0)\n",
      "Episode 85900/300000 ( TD_error: -0.13897747712280584, reward: -16.0,15.0)\n",
      "Episode 86000/300000 ( TD_error: -0.10644266719523365, reward: -16.0,-10.0)\n",
      "Episode 86100/300000 ( TD_error: 0.7734894137337118, reward: 9.0,-12.0)\n",
      "Episode 86200/300000 ( TD_error: -0.5060744802319634, reward: -11.0,-10.0)\n",
      "Episode 86300/300000 ( TD_error: -0.4166811256141356, reward: -11.0,-17.0)\n",
      "Episode 86400/300000 ( TD_error: -10.458583362507351, reward: -10.0,-25.0)\n",
      "Episode 86500/300000 ( TD_error: 1.0051566859070973, reward: 13.0,-12.0)\n",
      "Episode 86600/300000 ( TD_error: -1.9446466402384495, reward: -10.0,-22.0)\n",
      "Episode 86700/300000 ( TD_error: -0.1809115667996144, reward: -10.0,-25.0)\n",
      "Episode 86800/300000 ( TD_error: -3.879283410276349, reward: -10.0,-15.0)\n",
      "Episode 86900/300000 ( TD_error: -0.10224544705781469, reward: -13.0,14.0)\n",
      "Episode 87000/300000 ( TD_error: 1.140074517468527, reward: 15.0,-10.0)\n",
      "Episode 87100/300000 ( TD_error: 1.266172377044155, reward: 11.0,-14.0)\n",
      "Episode 87200/300000 ( TD_error: 2.0348368001791974, reward: 13.0,13.0)\n",
      "Episode 87300/300000 ( TD_error: 0.006313930233770471, reward: -11.0,-10.0)\n",
      "Episode 87400/300000 ( TD_error: -0.0909524380023532, reward: -15.0,-10.0)\n",
      "Episode 87500/300000 ( TD_error: -0.04532835886887199, reward: -10.0,-14.0)\n",
      "Episode 87600/300000 ( TD_error: -9.931731610420622, reward: -10.0,-17.0)\n",
      "Episode 87700/300000 ( TD_error: 0.1520159568053483, reward: -10.0,-14.0)\n",
      "Episode 87800/300000 ( TD_error: -0.08963023134030035, reward: -10.0,-11.0)\n",
      "Episode 87900/300000 ( TD_error: -0.32414104217508655, reward: -17.0,-12.0)\n",
      "Episode 88000/300000 ( TD_error: -9.93178604272844, reward: -10.0,-15.0)\n",
      "Episode 88100/300000 ( TD_error: 0.8599096391869181, reward: 15.0,11.0)\n",
      "Episode 88200/300000 ( TD_error: -0.28274783005075577, reward: -14.0,-12.0)\n",
      "Episode 88300/300000 ( TD_error: -0.2646355412859611, reward: -13.0,13.0)\n",
      "Episode 88400/300000 ( TD_error: -0.1917489464943145, reward: -10.0,12.0)\n",
      "Episode 88500/300000 ( TD_error: -1.2750516249246306, reward: -11.0,14.0)\n",
      "Episode 88600/300000 ( TD_error: 1.619767541100504, reward: 13.0,-22.0)\n",
      "Episode 88700/300000 ( TD_error: 1.0592994509462557, reward: -10.0,-12.0)\n",
      "Episode 88800/300000 ( TD_error: 2.71899364341248, reward: -11.0,-10.0)\n",
      "Episode 88900/300000 ( TD_error: 1.862701000836502, reward: 15.0,13.0)\n",
      "Episode 89000/300000 ( TD_error: 1.1419118504757382, reward: 10.0,-10.0)\n",
      "Episode 89100/300000 ( TD_error: -0.43338133355668607, reward: -15.0,15.0)\n",
      "Episode 89200/300000 ( TD_error: -0.4084910561929007, reward: -12.0,-10.0)\n",
      "Episode 89300/300000 ( TD_error: 0.7217635463043552, reward: 12.0,-10.0)\n",
      "Episode 89400/300000 ( TD_error: 3.7765558336245917, reward: -10.0,-35.0)\n",
      "Episode 89500/300000 ( TD_error: -9.939601030580846, reward: -10.0,-16.0)\n",
      "Episode 89600/300000 ( TD_error: -0.36289537091551605, reward: -12.0,15.0)\n",
      "Episode 89700/300000 ( TD_error: 0.7795148367724041, reward: 13.0,-10.0)\n",
      "Episode 89800/300000 ( TD_error: -10.471621165085025, reward: -10.0,15.0)\n",
      "Episode 89900/300000 ( TD_error: -0.34084220775219887, reward: -13.0,-15.0)\n",
      "Episode 90000/300000 ( TD_error: -1.2689175626715912, reward: -12.0,-13.0)\n",
      "Episode 90100/300000 ( TD_error: -0.3241936522687814, reward: -14.0,-12.0)\n",
      "Episode 90200/300000 ( TD_error: 1.2459763162064692, reward: 14.0,12.0)\n",
      "Episode 90300/300000 ( TD_error: 1.0606629974271362, reward: 15.0,-13.0)\n",
      "Episode 90400/300000 ( TD_error: -0.1872656339793224, reward: -10.0,-11.0)\n",
      "Episode 90500/300000 ( TD_error: 1.678753649942745, reward: 15.0,-10.0)\n",
      "Episode 90600/300000 ( TD_error: -0.1751959800702858, reward: -16.0,-11.0)\n",
      "Episode 90700/300000 ( TD_error: 2.356691987106728, reward: 14.0,13.0)\n",
      "Episode 90800/300000 ( TD_error: 2.4800180203117925, reward: 15.0,-10.0)\n",
      "Episode 90900/300000 ( TD_error: -0.14925397597471957, reward: -12.0,-10.0)\n",
      "Episode 91000/300000 ( TD_error: 1.5335256183137926, reward: 10.0,-13.0)\n",
      "Episode 91100/300000 ( TD_error: -0.13963976450814286, reward: -12.0,15.0)\n",
      "Episode 91200/300000 ( TD_error: -0.1669352619459019, reward: -12.0,13.0)\n",
      "Episode 91300/300000 ( TD_error: -10.486594751143485, reward: -10.0,13.0)\n",
      "Episode 91400/300000 ( TD_error: 1.8997275350245157, reward: 12.0,-10.0)\n",
      "Episode 91500/300000 ( TD_error: 4.61392787928127, reward: -10.0,10.0)\n",
      "Episode 91600/300000 ( TD_error: -2.113299406299028, reward: -19.0,14.0)\n",
      "Episode 91700/300000 ( TD_error: -0.138153892827944, reward: -13.0,-11.0)\n",
      "Episode 91800/300000 ( TD_error: -0.18937353564405246, reward: -11.0,-15.0)\n",
      "Episode 91900/300000 ( TD_error: -0.5023144606368284, reward: -10.0,-10.0)\n",
      "Episode 92000/300000 ( TD_error: -0.09590288625955523, reward: -11.0,-15.0)\n",
      "Episode 92100/300000 ( TD_error: 1.903047544824608, reward: 13.0,15.0)\n",
      "Episode 92200/300000 ( TD_error: 0.6496091529168382, reward: -10.0,-13.0)\n",
      "Episode 92300/300000 ( TD_error: 0.6589181105106583, reward: -10.0,-13.0)\n",
      "Episode 92400/300000 ( TD_error: -1.1396687071875888, reward: -21.0,-10.0)\n",
      "Episode 92500/300000 ( TD_error: 0.017606746651456007, reward: -11.0,15.0)\n",
      "Episode 92600/300000 ( TD_error: 2.5284945593575436, reward: 12.0,13.0)\n",
      "Episode 92700/300000 ( TD_error: -0.11572090365524712, reward: -12.0,-11.0)\n",
      "Episode 92800/300000 ( TD_error: 0.024736665283253245, reward: -10.0,15.0)\n",
      "Episode 92900/300000 ( TD_error: -0.24958724110084862, reward: -12.0,-11.0)\n",
      "Episode 93000/300000 ( TD_error: -0.2854025128140707, reward: -11.0,13.0)\n",
      "Episode 93100/300000 ( TD_error: 0.44117564297679657, reward: -10.0,-14.0)\n",
      "Episode 93200/300000 ( TD_error: -10.483512172876297, reward: -10.0,-10.0)\n",
      "Episode 93300/300000 ( TD_error: 1.3134115018616703, reward: 15.0,-11.0)\n",
      "Episode 93400/300000 ( TD_error: -9.929119588815912, reward: -10.0,-10.0)\n",
      "Episode 93500/300000 ( TD_error: 1.4717709407089639, reward: 10.0,-10.0)\n",
      "Episode 93600/300000 ( TD_error: -0.04977059180213672, reward: -11.0,-21.0)\n",
      "Episode 93700/300000 ( TD_error: 1.046449405458282, reward: 13.0,-13.0)\n",
      "Episode 93800/300000 ( TD_error: -0.1954914499471485, reward: -13.0,-10.0)\n",
      "Episode 93900/300000 ( TD_error: 2.158733243514411, reward: 14.0,14.0)\n",
      "Episode 94000/300000 ( TD_error: 1.3180092065950952, reward: 15.0,-11.0)\n",
      "Episode 94100/300000 ( TD_error: -9.916872323213695, reward: -10.0,14.0)\n",
      "Episode 94200/300000 ( TD_error: -9.918002610562553, reward: -10.0,-10.0)\n",
      "Episode 94300/300000 ( TD_error: 0.05690492453293672, reward: -46.0,10.0)\n",
      "Episode 94400/300000 ( TD_error: -0.2337780719490894, reward: -11.0,-12.0)\n",
      "Episode 94500/300000 ( TD_error: 1.0514027001372224, reward: 6.0,10.0)\n",
      "Episode 94600/300000 ( TD_error: -0.3780104305327896, reward: -11.0,-11.0)\n",
      "Episode 94700/300000 ( TD_error: -0.36076592719914835, reward: -12.0,13.0)\n",
      "Episode 94800/300000 ( TD_error: -0.2654051894346612, reward: -15.0,-11.0)\n",
      "Episode 94900/300000 ( TD_error: -2.422065231230457, reward: -19.0,8.0)\n",
      "Episode 95000/300000 ( TD_error: 0.8967257681561733, reward: 12.0,-20.0)\n",
      "Episode 95100/300000 ( TD_error: -0.4614697777577188, reward: -12.0,-16.0)\n",
      "Episode 95200/300000 ( TD_error: -1.1142927422714646, reward: -48.0,15.0)\n",
      "Episode 95300/300000 ( TD_error: -1.1522936360564398, reward: -44.0,-14.0)\n",
      "Episode 95400/300000 ( TD_error: -0.20389225590702686, reward: -10.0,-15.0)\n",
      "Episode 95500/300000 ( TD_error: 1.9420274312416255, reward: 12.0,14.0)\n",
      "Episode 95600/300000 ( TD_error: -0.16232312071934718, reward: -12.0,13.0)\n",
      "Episode 95700/300000 ( TD_error: -0.1673481420641112, reward: -14.0,10.0)\n",
      "Episode 95800/300000 ( TD_error: 1.8220428652970542, reward: 15.0,14.0)\n",
      "Episode 95900/300000 ( TD_error: -1.2612596102464195, reward: -38.0,-52.0)\n",
      "Episode 96000/300000 ( TD_error: 1.2958977078525504, reward: 10.0,-11.0)\n",
      "Episode 96100/300000 ( TD_error: -0.19143849144516079, reward: -15.0,14.0)\n",
      "Episode 96200/300000 ( TD_error: -0.859439098278381, reward: -10.0,-10.0)\n",
      "Episode 96300/300000 ( TD_error: -3.6037540932781944, reward: -11.0,15.0)\n",
      "Episode 96400/300000 ( TD_error: 1.3562178681808184, reward: 14.0,-15.0)\n",
      "Episode 96500/300000 ( TD_error: -0.14664590229396968, reward: -11.0,-10.0)\n",
      "Episode 96600/300000 ( TD_error: 1.2594451114585796, reward: 11.0,-12.0)\n",
      "Episode 96700/300000 ( TD_error: 4.045766765924041, reward: -12.0,-11.0)\n",
      "Episode 96800/300000 ( TD_error: -2.9268560202941325, reward: -11.0,-12.0)\n",
      "Episode 96900/300000 ( TD_error: 1.1531340758192274, reward: 14.0,13.0)\n",
      "Episode 97000/300000 ( TD_error: -0.27743579706710797, reward: -17.0,-33.0)\n",
      "Episode 97100/300000 ( TD_error: -0.23616634093213218, reward: -17.0,11.0)\n",
      "Episode 97200/300000 ( TD_error: 1.0277353354185523, reward: 13.0,-19.0)\n",
      "Episode 97300/300000 ( TD_error: 0.9527780486642654, reward: 12.0,10.0)\n",
      "Episode 97400/300000 ( TD_error: 1.3590544716872262, reward: 14.0,-16.0)\n",
      "Episode 97500/300000 ( TD_error: -0.21452972809531268, reward: -15.0,13.0)\n",
      "Episode 97600/300000 ( TD_error: -0.14239084822605186, reward: -18.0,-10.0)\n",
      "Episode 97700/300000 ( TD_error: 1.1871914483201973, reward: 14.0,15.0)\n",
      "Episode 97800/300000 ( TD_error: -0.06154223268958248, reward: -19.0,-13.0)\n",
      "Episode 97900/300000 ( TD_error: 0.47722821830658546, reward: -10.0,13.0)\n",
      "Episode 98000/300000 ( TD_error: -10.509120229706019, reward: -10.0,-15.0)\n",
      "Episode 98100/300000 ( TD_error: 1.377911034380269, reward: 8.0,-11.0)\n",
      "Episode 98200/300000 ( TD_error: -0.06444783040439805, reward: -11.0,11.0)\n",
      "Episode 98300/300000 ( TD_error: -0.15124957698802355, reward: -10.0,-17.0)\n",
      "Episode 98400/300000 ( TD_error: 4.6517430628865455, reward: -10.0,15.0)\n",
      "Episode 98500/300000 ( TD_error: -0.16553331585167985, reward: -13.0,14.0)\n",
      "Episode 98600/300000 ( TD_error: 0.8877241569608465, reward: -25.0,-10.0)\n",
      "Episode 98700/300000 ( TD_error: 6.946742630584936, reward: -10.0,-16.0)\n",
      "Episode 98800/300000 ( TD_error: -0.3014356878117468, reward: -10.0,-10.0)\n",
      "Episode 98900/300000 ( TD_error: 7.000780850918977, reward: -10.0,-19.0)\n",
      "Episode 99000/300000 ( TD_error: -0.5878205495033573, reward: -12.0,10.0)\n",
      "Episode 99100/300000 ( TD_error: -0.3393048280333275, reward: -10.0,-11.0)\n",
      "Episode 99200/300000 ( TD_error: 0.6563552880264343, reward: -10.0,-10.0)\n",
      "Episode 99300/300000 ( TD_error: 0.7389069946592977, reward: 14.0,-12.0)\n",
      "Episode 99400/300000 ( TD_error: 0.8361933828938319, reward: -83.0,-15.0)\n",
      "Episode 99500/300000 ( TD_error: 0.6101969356962762, reward: -1.0,-10.0)\n",
      "Episode 99600/300000 ( TD_error: -4.995935382483902, reward: -15.0,-12.0)\n",
      "Episode 99700/300000 ( TD_error: -1.4251699558178235, reward: -10.0,-14.0)\n",
      "Episode 99800/300000 ( TD_error: -0.13086219673606525, reward: -16.0,15.0)\n",
      "Episode 99900/300000 ( TD_error: 0.55031580603168, reward: -23.0,15.0)\n",
      "Episode 100000/300000 ( TD_error: -0.08889976410833622, reward: -10.0,10.0)\n",
      "Episode 100100/300000 ( TD_error: -0.11765739321758861, reward: -10.0,-13.0)\n",
      "Episode 100200/300000 ( TD_error: 0.02212878935836038, reward: -10.0,-19.0)\n",
      "Episode 100300/300000 ( TD_error: -10.510447543999915, reward: -10.0,-10.0)\n",
      "Episode 100400/300000 ( TD_error: -0.07038270188403839, reward: -13.0,-11.0)\n",
      "Episode 100500/300000 ( TD_error: 1.903101503599415, reward: 14.0,-12.0)\n",
      "Episode 100600/300000 ( TD_error: -0.0916457461917668, reward: -13.0,-10.0)\n",
      "Episode 100700/300000 ( TD_error: -1.0799616590362788, reward: -15.0,-12.0)\n",
      "Episode 100800/300000 ( TD_error: -1.1206146669206447, reward: -64.0,-10.0)\n",
      "Episode 100900/300000 ( TD_error: 1.2776633848876773, reward: 15.0,15.0)\n",
      "Episode 101000/300000 ( TD_error: -0.1547667957065606, reward: -11.0,-11.0)\n",
      "Episode 101100/300000 ( TD_error: -0.0008822887973627402, reward: -10.0,11.0)\n",
      "Episode 101200/300000 ( TD_error: 0.7781972604059835, reward: -15.0,14.0)\n",
      "Episode 101300/300000 ( TD_error: 1.417764904968338, reward: 13.0,-11.0)\n",
      "Episode 101400/300000 ( TD_error: -0.11118710341333848, reward: -10.0,-10.0)\n",
      "Episode 101500/300000 ( TD_error: -0.2173496137698292, reward: -16.0,-10.0)\n",
      "Episode 101600/300000 ( TD_error: 1.0806152043953268, reward: 12.0,-10.0)\n",
      "Episode 101700/300000 ( TD_error: 0.887234223276872, reward: 11.0,-10.0)\n",
      "Episode 101800/300000 ( TD_error: 2.4158425602764044, reward: 12.0,-11.0)\n",
      "Episode 101900/300000 ( TD_error: -0.2432330337926052, reward: -12.0,-10.0)\n",
      "Episode 102000/300000 ( TD_error: 1.4232186333872563, reward: 10.0,-14.0)\n",
      "Episode 102100/300000 ( TD_error: -0.124882336936472, reward: -14.0,11.0)\n",
      "Episode 102200/300000 ( TD_error: -3.0106064930512257, reward: -12.0,12.0)\n",
      "Episode 102300/300000 ( TD_error: -0.29886382351786533, reward: -13.0,15.0)\n",
      "Episode 102400/300000 ( TD_error: -0.5223748176117411, reward: -11.0,-61.0)\n",
      "Episode 102500/300000 ( TD_error: -0.618766557740642, reward: -11.0,-10.0)\n",
      "Episode 102600/300000 ( TD_error: 1.0436516477259037, reward: 15.0,-10.0)\n",
      "Episode 102700/300000 ( TD_error: -0.5743075012026226, reward: -14.0,10.0)\n",
      "Episode 102800/300000 ( TD_error: -0.3848216019888051, reward: -10.0,-12.0)\n",
      "Episode 102900/300000 ( TD_error: 0.8702808411042224, reward: 13.0,10.0)\n",
      "Episode 103000/300000 ( TD_error: -0.20940757491987227, reward: -10.0,-13.0)\n",
      "Episode 103100/300000 ( TD_error: 1.129154551194779, reward: 13.0,-33.0)\n",
      "Episode 103200/300000 ( TD_error: -1.2653169054759896, reward: -14.0,-11.0)\n",
      "Episode 103300/300000 ( TD_error: 0.9808617088529186, reward: 13.0,-10.0)\n",
      "Episode 103400/300000 ( TD_error: -0.12759820925292864, reward: -11.0,-10.0)\n",
      "Episode 103500/300000 ( TD_error: -0.9295335498628141, reward: -11.0,-15.0)\n",
      "Episode 103600/300000 ( TD_error: 0.5832984093433424, reward: -10.0,15.0)\n",
      "Episode 103700/300000 ( TD_error: -0.25430705550453325, reward: -14.0,-15.0)\n",
      "Episode 103800/300000 ( TD_error: -10.491200372962847, reward: -10.0,-13.0)\n",
      "Episode 103900/300000 ( TD_error: -0.13797711834190096, reward: -15.0,15.0)\n",
      "Episode 104000/300000 ( TD_error: -0.25454261483241414, reward: -12.0,12.0)\n",
      "Episode 104100/300000 ( TD_error: 1.9137973608522802, reward: -10.0,-16.0)\n",
      "Episode 104200/300000 ( TD_error: -0.5972259763913801, reward: -12.0,-10.0)\n",
      "Episode 104300/300000 ( TD_error: -0.6130013357050155, reward: -11.0,-14.0)\n",
      "Episode 104400/300000 ( TD_error: 0.9952342459965449, reward: 13.0,-14.0)\n",
      "Episode 104500/300000 ( TD_error: -0.7868729511479113, reward: -13.0,-10.0)\n",
      "Episode 104600/300000 ( TD_error: -0.9964360845524798, reward: -20.0,-16.0)\n",
      "Episode 104700/300000 ( TD_error: -0.3644561085918543, reward: -38.0,15.0)\n",
      "Episode 104800/300000 ( TD_error: -0.7017357309667069, reward: -38.0,-10.0)\n",
      "Episode 104900/300000 ( TD_error: -0.6911274545368036, reward: -24.0,-10.0)\n",
      "Episode 105000/300000 ( TD_error: 1.472975461437819, reward: 15.0,-10.0)\n",
      "Episode 105100/300000 ( TD_error: -0.5354177426552829, reward: -12.0,-10.0)\n",
      "Episode 105200/300000 ( TD_error: 0.7203864344954507, reward: 11.0,-16.0)\n",
      "Episode 105300/300000 ( TD_error: -0.2845204243073969, reward: -26.0,-12.0)\n",
      "Episode 105400/300000 ( TD_error: 0.039550370968039594, reward: -11.0,-16.0)\n",
      "Episode 105500/300000 ( TD_error: 0.7208504665528341, reward: -10.0,-10.0)\n",
      "Episode 105600/300000 ( TD_error: 1.8354988844598243, reward: 13.0,12.0)\n",
      "Episode 105700/300000 ( TD_error: 1.611936843525203, reward: 10.0,15.0)\n",
      "Episode 105800/300000 ( TD_error: 1.560191661815165, reward: 15.0,15.0)\n",
      "Episode 105900/300000 ( TD_error: -0.14727337406186702, reward: -12.0,12.0)\n",
      "Episode 106000/300000 ( TD_error: -1.1520261552655402, reward: -27.0,-13.0)\n",
      "Episode 106100/300000 ( TD_error: 1.2397770752861579, reward: 15.0,10.0)\n",
      "Episode 106200/300000 ( TD_error: -0.29427413913752787, reward: -12.0,-13.0)\n",
      "Episode 106300/300000 ( TD_error: -0.27690088993117, reward: -14.0,15.0)\n",
      "Episode 106400/300000 ( TD_error: 1.0808137777758802, reward: 14.0,11.0)\n",
      "Episode 106500/300000 ( TD_error: -0.20911404173031123, reward: -15.0,-13.0)\n",
      "Episode 106600/300000 ( TD_error: -0.19299308261014936, reward: -13.0,-14.0)\n",
      "Episode 106700/300000 ( TD_error: 1.1773872169706072, reward: 12.0,-10.0)\n",
      "Episode 106800/300000 ( TD_error: 1.1883669906987562, reward: 13.0,-10.0)\n",
      "Episode 106900/300000 ( TD_error: -0.13912920419594244, reward: -17.0,12.0)\n",
      "Episode 107000/300000 ( TD_error: 1.3553926486500365, reward: 13.0,-17.0)\n",
      "Episode 107100/300000 ( TD_error: -0.1245932230921758, reward: -13.0,-11.0)\n",
      "Episode 107200/300000 ( TD_error: 0.018745922583948804, reward: -10.0,-10.0)\n",
      "Episode 107300/300000 ( TD_error: -0.9981511019064797, reward: -10.0,-15.0)\n",
      "Episode 107400/300000 ( TD_error: 1.639287469804791, reward: 14.0,-13.0)\n",
      "Episode 107500/300000 ( TD_error: -10.487779275715898, reward: -10.0,-10.0)\n",
      "Episode 107600/300000 ( TD_error: 0.013842019453053744, reward: -11.0,-10.0)\n",
      "Episode 107700/300000 ( TD_error: -0.11881214068960677, reward: -14.0,-10.0)\n",
      "Episode 107800/300000 ( TD_error: -9.98251069423716, reward: -10.0,-10.0)\n",
      "Episode 107900/300000 ( TD_error: -0.5719946202459445, reward: -11.0,15.0)\n",
      "Episode 108000/300000 ( TD_error: 1.0194017741527017, reward: 11.0,-14.0)\n",
      "Episode 108100/300000 ( TD_error: 1.055841162741988, reward: 14.0,-14.0)\n",
      "Episode 108200/300000 ( TD_error: -0.23640435992010111, reward: -12.0,-10.0)\n",
      "Episode 108300/300000 ( TD_error: -0.21502689927984786, reward: -12.0,-11.0)\n",
      "Episode 108400/300000 ( TD_error: -0.392651532582887, reward: -10.0,-12.0)\n",
      "Episode 108500/300000 ( TD_error: 0.4081949163815146, reward: -11.0,15.0)\n",
      "Episode 108600/300000 ( TD_error: -1.2740254672140416, reward: -11.0,-13.0)\n",
      "Episode 108700/300000 ( TD_error: -0.0026312870728482096, reward: -10.0,-11.0)\n",
      "Episode 108800/300000 ( TD_error: 0.025051399669811403, reward: -11.0,8.0)\n",
      "Episode 108900/300000 ( TD_error: 0.06343274830861478, reward: -10.0,-11.0)\n",
      "Episode 109000/300000 ( TD_error: 1.3031452697420294, reward: 15.0,-10.0)\n",
      "Episode 109100/300000 ( TD_error: 0.6030295250596538, reward: -12.0,13.0)\n",
      "Episode 109200/300000 ( TD_error: -0.18354269756826547, reward: -15.0,-16.0)\n",
      "Episode 109300/300000 ( TD_error: -0.2180313241875229, reward: -10.0,-13.0)\n",
      "Episode 109400/300000 ( TD_error: -0.2830021480056626, reward: -12.0,-11.0)\n",
      "Episode 109500/300000 ( TD_error: -2.3796773242925156, reward: -15.0,13.0)\n",
      "Episode 109600/300000 ( TD_error: 2.4612599664131425, reward: 14.0,-11.0)\n",
      "Episode 109700/300000 ( TD_error: -1.2453106479478215, reward: -14.0,-17.0)\n",
      "Episode 109800/300000 ( TD_error: -0.15705986655643578, reward: -14.0,14.0)\n",
      "Episode 109900/300000 ( TD_error: -0.17758337975454808, reward: -11.0,-10.0)\n",
      "Episode 110000/300000 ( TD_error: 0.011406078545766363, reward: -11.0,-10.0)\n",
      "Episode 110100/300000 ( TD_error: 0.9730765021082064, reward: 13.0,14.0)\n",
      "Episode 110200/300000 ( TD_error: 1.2824130067109887, reward: 15.0,-16.0)\n",
      "Episode 110300/300000 ( TD_error: -4.0263827337469165, reward: -10.0,-12.0)\n",
      "Episode 110400/300000 ( TD_error: -0.23449203911359273, reward: -10.0,-10.0)\n",
      "Episode 110500/300000 ( TD_error: 0.9162112165712539, reward: 12.0,-14.0)\n",
      "Episode 110600/300000 ( TD_error: -1.332603627976761, reward: -16.0,13.0)\n",
      "Episode 110700/300000 ( TD_error: 0.7830653502077287, reward: 11.0,-10.0)\n",
      "Episode 110800/300000 ( TD_error: -0.6214909779464808, reward: -14.0,13.0)\n",
      "Episode 110900/300000 ( TD_error: -0.48774876315833016, reward: -12.0,-13.0)\n",
      "Episode 111000/300000 ( TD_error: -0.002369078114693224, reward: -10.0,13.0)\n",
      "Episode 111100/300000 ( TD_error: -1.1336101299950112, reward: -11.0,-10.0)\n",
      "Episode 111200/300000 ( TD_error: 1.8094824165074215, reward: 13.0,12.0)\n",
      "Episode 111300/300000 ( TD_error: -0.22126613021953556, reward: -12.0,12.0)\n",
      "Episode 111400/300000 ( TD_error: -0.08884150682513248, reward: -11.0,-12.0)\n",
      "Episode 111500/300000 ( TD_error: 1.0779803012009515, reward: 10.0,-10.0)\n",
      "Episode 111600/300000 ( TD_error: 5.0205748674620505, reward: -10.0,-10.0)\n",
      "Episode 111700/300000 ( TD_error: -0.7005998190665803, reward: -22.0,-10.0)\n",
      "Episode 111800/300000 ( TD_error: -9.97455056432256, reward: -10.0,13.0)\n",
      "Episode 111900/300000 ( TD_error: 16.269760936348064, reward: 15.0,-15.0)\n",
      "Episode 112000/300000 ( TD_error: -2.9040659782274982, reward: -18.0,-10.0)\n",
      "Episode 112100/300000 ( TD_error: -1.1443002083134992, reward: -16.0,-13.0)\n",
      "Episode 112200/300000 ( TD_error: 0.6154253906926987, reward: 15.0,-10.0)\n",
      "Episode 112300/300000 ( TD_error: -0.5710829388933352, reward: -17.0,-10.0)\n",
      "Episode 112400/300000 ( TD_error: -0.3694671858081122, reward: -13.0,-10.0)\n",
      "Episode 112500/300000 ( TD_error: 0.21686325420545582, reward: -10.0,-12.0)\n",
      "Episode 112600/300000 ( TD_error: 0.2689178810378987, reward: -10.0,13.0)\n",
      "Episode 112700/300000 ( TD_error: -10.476102866835104, reward: -10.0,-16.0)\n",
      "Episode 112800/300000 ( TD_error: -0.23641945046533408, reward: -14.0,13.0)\n",
      "Episode 112900/300000 ( TD_error: 0.02318647960619913, reward: -11.0,15.0)\n",
      "Episode 113000/300000 ( TD_error: -0.13151619665744807, reward: -11.0,13.0)\n",
      "Episode 113100/300000 ( TD_error: 0.3643517706948529, reward: -13.0,15.0)\n",
      "Episode 113200/300000 ( TD_error: -0.12326390660080389, reward: -12.0,-17.0)\n",
      "Episode 113300/300000 ( TD_error: -0.08034725141492949, reward: -10.0,-10.0)\n",
      "Episode 113400/300000 ( TD_error: 2.3129840811392595, reward: 10.0,5.0)\n",
      "Episode 113500/300000 ( TD_error: -0.06979838148380146, reward: -10.0,-11.0)\n",
      "Episode 113600/300000 ( TD_error: -3.0263057517907637, reward: -11.0,-14.0)\n",
      "Episode 113700/300000 ( TD_error: -9.955910413871745, reward: -10.0,-11.0)\n",
      "Episode 113800/300000 ( TD_error: -1.4260110099243928, reward: -11.0,15.0)\n",
      "Episode 113900/300000 ( TD_error: 0.6864755410010561, reward: -10.0,15.0)\n",
      "Episode 114000/300000 ( TD_error: 0.8363978331655746, reward: 13.0,15.0)\n",
      "Episode 114100/300000 ( TD_error: -0.2713947720575387, reward: -23.0,14.0)\n",
      "Episode 114200/300000 ( TD_error: 4.7878708483832195, reward: -10.0,13.0)\n",
      "Episode 114300/300000 ( TD_error: -2.475819206813819, reward: -24.0,13.0)\n",
      "Episode 114400/300000 ( TD_error: 0.7420515736630611, reward: 15.0,-12.0)\n",
      "Episode 114500/300000 ( TD_error: 0.4792152979023072, reward: -10.0,-11.0)\n",
      "Episode 114600/300000 ( TD_error: -0.3917046594391618, reward: -13.0,-15.0)\n",
      "Episode 114700/300000 ( TD_error: -0.28179316599001947, reward: -13.0,-10.0)\n",
      "Episode 114800/300000 ( TD_error: -0.2836613213881227, reward: -15.0,-11.0)\n",
      "Episode 114900/300000 ( TD_error: -0.24839815160994227, reward: -17.0,-13.0)\n",
      "Episode 115000/300000 ( TD_error: 0.06487836300657968, reward: -12.0,-15.0)\n",
      "Episode 115100/300000 ( TD_error: 1.9760888199851228, reward: 14.0,-16.0)\n",
      "Episode 115200/300000 ( TD_error: -9.965899331864804, reward: -10.0,-12.0)\n",
      "Episode 115300/300000 ( TD_error: 1.8332851972782915, reward: 14.0,-25.0)\n",
      "Episode 115400/300000 ( TD_error: -0.26121416655500873, reward: -10.0,-13.0)\n",
      "Episode 115500/300000 ( TD_error: -0.3647812918589244, reward: -13.0,-10.0)\n",
      "Episode 115600/300000 ( TD_error: -0.39228489796062505, reward: -14.0,-12.0)\n",
      "Episode 115700/300000 ( TD_error: -0.30002261468226266, reward: -17.0,-37.0)\n",
      "Episode 115800/300000 ( TD_error: -0.21002081954984142, reward: -13.0,-12.0)\n",
      "Episode 115900/300000 ( TD_error: -0.2100591138114094, reward: -10.0,8.0)\n",
      "Episode 116000/300000 ( TD_error: -10.493908686873132, reward: -10.0,-11.0)\n",
      "Episode 116100/300000 ( TD_error: 1.0728899688145153, reward: 13.0,-13.0)\n",
      "Episode 116200/300000 ( TD_error: 0.9849088065850076, reward: 14.0,-11.0)\n",
      "Episode 116300/300000 ( TD_error: -0.4546448772683034, reward: -10.0,-14.0)\n",
      "Episode 116400/300000 ( TD_error: 0.4609613379018107, reward: -11.0,11.0)\n",
      "Episode 116500/300000 ( TD_error: -2.778695734490883, reward: -13.0,-10.0)\n",
      "Episode 116600/300000 ( TD_error: 0.017864196996796977, reward: -10.0,-10.0)\n",
      "Episode 116700/300000 ( TD_error: 1.516360302801913, reward: 15.0,-13.0)\n",
      "Episode 116800/300000 ( TD_error: 0.7780897214552001, reward: 10.0,11.0)\n",
      "Episode 116900/300000 ( TD_error: 0.6858544878736756, reward: 14.0,-13.0)\n",
      "Episode 117000/300000 ( TD_error: -2.6319826482466286, reward: -31.0,-15.0)\n",
      "Episode 117100/300000 ( TD_error: -0.7787913478298343, reward: -12.0,-16.0)\n",
      "Episode 117200/300000 ( TD_error: -0.509143891607156, reward: -16.0,-10.0)\n",
      "Episode 117300/300000 ( TD_error: -0.38550824950542584, reward: -12.0,-29.0)\n",
      "Episode 117400/300000 ( TD_error: -0.287051893085847, reward: -11.0,-10.0)\n",
      "Episode 117500/300000 ( TD_error: -0.24116014114193973, reward: -13.0,10.0)\n",
      "Episode 117600/300000 ( TD_error: 0.7055963674084573, reward: 8.0,-10.0)\n",
      "Episode 117700/300000 ( TD_error: -9.9531905714076, reward: -10.0,12.0)\n",
      "Episode 117800/300000 ( TD_error: 0.19518676159268544, reward: -10.0,14.0)\n",
      "Episode 117900/300000 ( TD_error: -0.5683223270483619, reward: -26.0,7.0)\n",
      "Episode 118000/300000 ( TD_error: 0.6555107818280366, reward: 13.0,-10.0)\n",
      "Episode 118100/300000 ( TD_error: 0.6766998143840359, reward: 7.0,-65.0)\n",
      "Episode 118200/300000 ( TD_error: 0.7424063015267888, reward: 14.0,15.0)\n",
      "Episode 118300/300000 ( TD_error: 1.323477463843504, reward: 9.0,-17.0)\n",
      "Episode 118400/300000 ( TD_error: -0.4358114881680688, reward: -10.0,8.0)\n",
      "Episode 118500/300000 ( TD_error: 0.8703192086104607, reward: 9.0,15.0)\n",
      "Episode 118600/300000 ( TD_error: 0.6700335005515834, reward: 15.0,15.0)\n",
      "Episode 118700/300000 ( TD_error: 0.5871317671305616, reward: 7.0,-12.0)\n",
      "Episode 118800/300000 ( TD_error: 0.5677578880984799, reward: 15.0,-18.0)\n",
      "Episode 118900/300000 ( TD_error: 1.1514457029923122, reward: 3.0,-10.0)\n",
      "Episode 119000/300000 ( TD_error: 1.0888437003423146, reward: 5.0,-36.0)\n",
      "Episode 119100/300000 ( TD_error: 1.043921778874045, reward: 7.0,10.0)\n",
      "Episode 119200/300000 ( TD_error: 0.7898905931837281, reward: 13.0,-22.0)\n",
      "Episode 119300/300000 ( TD_error: 0.14297037988777284, reward: -22.0,15.0)\n",
      "Episode 119400/300000 ( TD_error: 5.034525308967803, reward: -10.0,-10.0)\n",
      "Episode 119500/300000 ( TD_error: -10.458702552272342, reward: -10.0,12.0)\n",
      "Episode 119600/300000 ( TD_error: -0.9595407492979344, reward: -10.0,6.0)\n",
      "Episode 119700/300000 ( TD_error: 0.5782798664005835, reward: 7.0,-11.0)\n",
      "Episode 119800/300000 ( TD_error: 0.4054345870269742, reward: -11.0,9.0)\n",
      "Episode 119900/300000 ( TD_error: -0.9983809969018331, reward: -18.0,-21.0)\n",
      "Episode 120000/300000 ( TD_error: 0.7820678597407049, reward: 8.0,5.0)\n",
      "Episode 120100/300000 ( TD_error: 16.311418103799326, reward: 15.0,-10.0)\n",
      "Episode 120200/300000 ( TD_error: 0.7280965461272495, reward: 2.0,-10.0)\n",
      "Episode 120300/300000 ( TD_error: -2.876660527819652, reward: -20.0,-11.0)\n",
      "Episode 120400/300000 ( TD_error: 0.5606962328348075, reward: 7.0,12.0)\n",
      "Episode 120500/300000 ( TD_error: 1.078725756957017, reward: 14.0,-10.0)\n",
      "Episode 120600/300000 ( TD_error: 0.795453099699805, reward: 15.0,-10.0)\n",
      "Episode 120700/300000 ( TD_error: 1.3757386953626534, reward: 5.0,15.0)\n",
      "Episode 120800/300000 ( TD_error: -0.8907101973136822, reward: -17.0,-10.0)\n",
      "Episode 120900/300000 ( TD_error: -10.02142467112514, reward: -10.0,-11.0)\n",
      "Episode 121000/300000 ( TD_error: 0.581703692683007, reward: -10.0,7.0)\n",
      "Episode 121100/300000 ( TD_error: 0.7174272844655434, reward: 15.0,12.0)\n",
      "Episode 121200/300000 ( TD_error: 0.687094518770651, reward: 15.0,5.0)\n",
      "Episode 121300/300000 ( TD_error: 0.6169031604417308, reward: 15.0,-42.0)\n",
      "Episode 121400/300000 ( TD_error: 0.5050546995516201, reward: 11.0,9.0)\n",
      "Episode 121500/300000 ( TD_error: -1.1726351390706578, reward: -11.0,-10.0)\n",
      "Episode 121600/300000 ( TD_error: 0.4868722754916006, reward: 8.0,7.0)\n",
      "Episode 121700/300000 ( TD_error: 0.5617718804608112, reward: 12.0,13.0)\n",
      "Episode 121800/300000 ( TD_error: -0.3144553299817563, reward: -11.0,-11.0)\n",
      "Episode 121900/300000 ( TD_error: 0.5452565473780169, reward: -20.0,-14.0)\n",
      "Episode 122000/300000 ( TD_error: 0.5276901071107485, reward: 13.0,7.0)\n",
      "Episode 122100/300000 ( TD_error: 0.6027539907158723, reward: 13.0,-10.0)\n",
      "Episode 122200/300000 ( TD_error: 0.022414009583943795, reward: -10.0,-14.0)\n",
      "Episode 122300/300000 ( TD_error: 0.49896954556942585, reward: 7.0,2.0)\n",
      "Episode 122400/300000 ( TD_error: 0.45092922532269286, reward: 14.0,-15.0)\n",
      "Episode 122500/300000 ( TD_error: -0.5663276568905484, reward: -11.0,-10.0)\n",
      "Episode 122600/300000 ( TD_error: -0.7300468326707623, reward: -13.0,-10.0)\n",
      "Episode 122700/300000 ( TD_error: 0.5619482981387831, reward: -1.0,-14.0)\n",
      "Episode 122800/300000 ( TD_error: 16.337241918711907, reward: 15.0,-19.0)\n",
      "Episode 122900/300000 ( TD_error: 0.44738332554984783, reward: 9.0,10.0)\n",
      "Episode 123000/300000 ( TD_error: 1.6022964098757404, reward: 8.0,1.0)\n",
      "Episode 123100/300000 ( TD_error: -0.5539122692511196, reward: -12.0,8.0)\n",
      "Episode 123200/300000 ( TD_error: -0.05893789552694173, reward: -14.0,9.0)\n",
      "Episode 123300/300000 ( TD_error: -10.037884278593769, reward: -10.0,6.0)\n",
      "Episode 123400/300000 ( TD_error: -10.03775537913702, reward: -10.0,-10.0)\n",
      "Episode 123500/300000 ( TD_error: 0.5204830643164611, reward: 10.0,-10.0)\n",
      "Episode 123600/300000 ( TD_error: 0.5122857230834033, reward: -10.0,-12.0)\n",
      "Episode 123700/300000 ( TD_error: 2.5197931909094713, reward: -16.0,-52.0)\n",
      "Episode 123800/300000 ( TD_error: -0.7453719535735868, reward: -15.0,-10.0)\n",
      "Episode 123900/300000 ( TD_error: -1.6024558213018274, reward: -36.0,7.0)\n",
      "Episode 124000/300000 ( TD_error: 1.1975036273423418, reward: 8.0,-10.0)\n",
      "Episode 124100/300000 ( TD_error: -0.2503737892399007, reward: -22.0,-22.0)\n",
      "Episode 124200/300000 ( TD_error: 0.7815236176798801, reward: 6.0,15.0)\n",
      "Episode 124300/300000 ( TD_error: 0.020184183737203654, reward: -13.0,13.0)\n",
      "Episode 124400/300000 ( TD_error: 0.4995823131096504, reward: -10.0,-19.0)\n",
      "Episode 124500/300000 ( TD_error: 0.5033575143439433, reward: 6.0,-10.0)\n",
      "Episode 124600/300000 ( TD_error: -5.117177472265329, reward: -16.0,-10.0)\n",
      "Episode 124700/300000 ( TD_error: 0.5493752490977584, reward: 15.0,-10.0)\n",
      "Episode 124800/300000 ( TD_error: 0.5059653719040478, reward: 11.0,-33.0)\n",
      "Episode 124900/300000 ( TD_error: 0.5258235676347804, reward: 5.0,8.0)\n",
      "Episode 125000/300000 ( TD_error: 0.47707000765912877, reward: 11.0,13.0)\n",
      "Episode 125100/300000 ( TD_error: -0.16640573930725022, reward: -11.0,-15.0)\n",
      "Episode 125200/300000 ( TD_error: -0.3363415891687467, reward: -12.0,9.0)\n",
      "Episode 125300/300000 ( TD_error: 0.48153022889550456, reward: 12.0,14.0)\n",
      "Episode 125400/300000 ( TD_error: -10.042043659100399, reward: -10.0,8.0)\n",
      "Episode 125500/300000 ( TD_error: -10.042166948887377, reward: -10.0,5.0)\n",
      "Episode 125600/300000 ( TD_error: 0.40600204446047883, reward: 10.0,-13.0)\n",
      "Episode 125700/300000 ( TD_error: 0.9261102907143366, reward: 15.0,8.0)\n",
      "Episode 125800/300000 ( TD_error: -2.9927666030995415, reward: -12.0,11.0)\n",
      "Episode 125900/300000 ( TD_error: 0.46201905399045984, reward: 15.0,-10.0)\n",
      "Episode 126000/300000 ( TD_error: -10.4424367718597, reward: -10.0,-21.0)\n",
      "Episode 126100/300000 ( TD_error: 0.47415883895898503, reward: -18.0,-39.0)\n",
      "Episode 126200/300000 ( TD_error: -10.443029294362802, reward: -10.0,14.0)\n",
      "Episode 126300/300000 ( TD_error: 1.103342639066248, reward: 14.0,9.0)\n",
      "Episode 126400/300000 ( TD_error: 0.8096804859783173, reward: 12.0,12.0)\n",
      "Episode 126500/300000 ( TD_error: -10.454921625045023, reward: -10.0,3.0)\n",
      "Episode 126600/300000 ( TD_error: 0.53590636859309, reward: -12.0,-12.0)\n",
      "Episode 126700/300000 ( TD_error: -10.425502331333252, reward: -10.0,-10.0)\n",
      "Episode 126800/300000 ( TD_error: 0.4957681804892573, reward: 8.0,8.0)\n",
      "Episode 126900/300000 ( TD_error: 0.4932275484020425, reward: 7.0,-10.0)\n",
      "Episode 127000/300000 ( TD_error: -10.409582719199607, reward: -10.0,-16.0)\n",
      "Episode 127100/300000 ( TD_error: -10.422629627126334, reward: -10.0,6.0)\n",
      "Episode 127200/300000 ( TD_error: 4.853020616775902, reward: -10.0,-14.0)\n",
      "Episode 127300/300000 ( TD_error: 0.42874358399503043, reward: 3.0,-22.0)\n",
      "Episode 127400/300000 ( TD_error: 0.4351651618184831, reward: 15.0,10.0)\n",
      "Episode 127500/300000 ( TD_error: 0.40367744721174326, reward: 10.0,15.0)\n",
      "Episode 127600/300000 ( TD_error: -10.053977106230544, reward: -10.0,7.0)\n",
      "Episode 127700/300000 ( TD_error: 0.432750197982505, reward: 8.0,-10.0)\n",
      "Episode 127800/300000 ( TD_error: 1.509918331595651, reward: 15.0,14.0)\n",
      "Episode 127900/300000 ( TD_error: 1.0164670228678503, reward: 14.0,0.0)\n",
      "Episode 128000/300000 ( TD_error: 0.8216658906361372, reward: 4.0,8.0)\n",
      "Episode 128100/300000 ( TD_error: 1.6019133242457713, reward: 7.0,-10.0)\n",
      "Episode 128200/300000 ( TD_error: -0.25056063907427983, reward: -10.0,-13.0)\n",
      "Episode 128300/300000 ( TD_error: 1.4055408476953197, reward: 7.0,6.0)\n",
      "Episode 128400/300000 ( TD_error: 1.6552376896969627, reward: 5.0,14.0)\n",
      "Episode 128500/300000 ( TD_error: 1.2492217089292188, reward: 13.0,15.0)\n",
      "Episode 128600/300000 ( TD_error: -10.46965042548129, reward: -10.0,-11.0)\n",
      "Episode 128700/300000 ( TD_error: -1.8344573970901585, reward: -29.0,15.0)\n",
      "Episode 128800/300000 ( TD_error: 1.5288266201641871, reward: 13.0,14.0)\n",
      "Episode 128900/300000 ( TD_error: -10.077201774635554, reward: -10.0,6.0)\n",
      "Episode 129000/300000 ( TD_error: -10.483187892947477, reward: -10.0,8.0)\n",
      "Episode 129100/300000 ( TD_error: 0.6837427814282604, reward: 10.0,2.0)\n",
      "Episode 129200/300000 ( TD_error: 0.7833265361405943, reward: 9.0,12.0)\n",
      "Episode 129300/300000 ( TD_error: -1.7964018358711975, reward: -14.0,13.0)\n",
      "Episode 129400/300000 ( TD_error: -10.471621139066997, reward: -10.0,7.0)\n",
      "Episode 129500/300000 ( TD_error: 0.6571691565836142, reward: 11.0,-10.0)\n",
      "Episode 129600/300000 ( TD_error: 0.4737580414343019, reward: 14.0,-10.0)\n",
      "Episode 129700/300000 ( TD_error: 0.4605009473333572, reward: 9.0,13.0)\n",
      "Episode 129800/300000 ( TD_error: 0.4594783001657947, reward: 15.0,-10.0)\n",
      "Episode 129900/300000 ( TD_error: 0.3965548821692275, reward: 0.0,-18.0)\n",
      "Episode 130000/300000 ( TD_error: 0.9210828195885115, reward: 15.0,6.0)\n",
      "Episode 130100/300000 ( TD_error: 0.49532957144834633, reward: 9.0,-10.0)\n",
      "Episode 130200/300000 ( TD_error: 0.4178135304731736, reward: 7.0,9.0)\n",
      "Episode 130300/300000 ( TD_error: -0.16878116452463487, reward: -11.0,-11.0)\n",
      "Episode 130400/300000 ( TD_error: -10.476832092675574, reward: -10.0,-21.0)\n",
      "Episode 130500/300000 ( TD_error: 0.6089283807852035, reward: 12.0,11.0)\n",
      "Episode 130600/300000 ( TD_error: 0.9883004947819036, reward: 14.0,15.0)\n",
      "Episode 130700/300000 ( TD_error: 0.6679759515812949, reward: 6.0,11.0)\n",
      "Episode 130800/300000 ( TD_error: -0.5080713076692813, reward: -13.0,13.0)\n",
      "Episode 130900/300000 ( TD_error: 1.4375392305958368, reward: -11.0,11.0)\n",
      "Episode 131000/300000 ( TD_error: 16.334171760066454, reward: 15.0,7.0)\n",
      "Episode 131100/300000 ( TD_error: 0.4302548821388812, reward: 9.0,-17.0)\n",
      "Episode 131200/300000 ( TD_error: 0.48436614514236886, reward: 6.0,-10.0)\n",
      "Episode 131300/300000 ( TD_error: 0.3717075597806221, reward: 14.0,8.0)\n",
      "Episode 131400/300000 ( TD_error: 0.32640503963883694, reward: 3.0,13.0)\n",
      "Episode 131500/300000 ( TD_error: -1.0468149171486054, reward: -21.0,8.0)\n",
      "Episode 131600/300000 ( TD_error: 0.40641969307681336, reward: 12.0,-10.0)\n",
      "Episode 131700/300000 ( TD_error: 0.4395023133530498, reward: 13.0,10.0)\n",
      "Episode 131800/300000 ( TD_error: -10.485135468826982, reward: -10.0,-10.0)\n",
      "Episode 131900/300000 ( TD_error: 0.39353586404893504, reward: 5.0,-14.0)\n",
      "Episode 132000/300000 ( TD_error: 0.3480579138894435, reward: 15.0,-12.0)\n",
      "Episode 132100/300000 ( TD_error: 0.3628620294961644, reward: 2.0,6.0)\n",
      "Episode 132200/300000 ( TD_error: -10.080499914267044, reward: -10.0,-10.0)\n",
      "Episode 132300/300000 ( TD_error: 0.03167463391849523, reward: -17.0,-10.0)\n",
      "Episode 132400/300000 ( TD_error: 0.30709759761449495, reward: 10.0,-16.0)\n",
      "Episode 132500/300000 ( TD_error: 1.1615858586907593, reward: 15.0,-10.0)\n",
      "Episode 132600/300000 ( TD_error: 0.29492254364981196, reward: 3.0,-10.0)\n",
      "Episode 132700/300000 ( TD_error: -0.06105378484851798, reward: -10.0,4.0)\n",
      "Episode 132800/300000 ( TD_error: 0.9499630275655524, reward: 12.0,-15.0)\n",
      "Episode 132900/300000 ( TD_error: -0.7375388142916002, reward: -18.0,-21.0)\n",
      "Episode 133000/300000 ( TD_error: -1.7594055597923397, reward: -14.0,-16.0)\n",
      "Episode 133100/300000 ( TD_error: -0.09505383297940107, reward: -11.0,-11.0)\n",
      "Episode 133200/300000 ( TD_error: 1.051635082770432, reward: 15.0,-10.0)\n",
      "Episode 133300/300000 ( TD_error: -10.07393946599678, reward: -10.0,9.0)\n",
      "Episode 133400/300000 ( TD_error: 1.185389178893173, reward: -2.0,-10.0)\n",
      "Episode 133500/300000 ( TD_error: 1.0697319950717925, reward: 10.0,-10.0)\n",
      "Episode 133600/300000 ( TD_error: 0.06550179994188365, reward: -11.0,-11.0)\n",
      "Episode 133700/300000 ( TD_error: -10.508916846937229, reward: -10.0,7.0)\n",
      "Episode 133800/300000 ( TD_error: 1.786146600661288, reward: 14.0,-16.0)\n",
      "Episode 133900/300000 ( TD_error: 1.0336493552384387, reward: 6.0,8.0)\n",
      "Episode 134000/300000 ( TD_error: -1.69545983007621, reward: -10.0,-10.0)\n",
      "Episode 134100/300000 ( TD_error: 1.0920235168954031, reward: 8.0,-10.0)\n",
      "Episode 134200/300000 ( TD_error: 0.36223010745461437, reward: -15.0,-30.0)\n",
      "Episode 134300/300000 ( TD_error: 1.6819269182275498, reward: 7.0,-10.0)\n",
      "Episode 134400/300000 ( TD_error: 0.9454948581271565, reward: 5.0,6.0)\n",
      "Episode 134500/300000 ( TD_error: -1.9445527033357006, reward: -10.0,-14.0)\n",
      "Episode 134600/300000 ( TD_error: 1.352477548725786, reward: 13.0,14.0)\n",
      "Episode 134700/300000 ( TD_error: 0.8762646172832413, reward: 12.0,-10.0)\n",
      "Episode 134800/300000 ( TD_error: 1.128461445466689, reward: -19.0,3.0)\n",
      "Episode 134900/300000 ( TD_error: 0.5657284897645813, reward: 5.0,8.0)\n",
      "Episode 135000/300000 ( TD_error: 0.4916299107210067, reward: 9.0,15.0)\n",
      "Episode 135100/300000 ( TD_error: 0.47977466406592484, reward: 15.0,7.0)\n",
      "Episode 135200/300000 ( TD_error: 0.7110364055944327, reward: 13.0,13.0)\n",
      "Episode 135300/300000 ( TD_error: -0.3817056462086317, reward: -10.0,10.0)\n",
      "Episode 135400/300000 ( TD_error: -10.076141800030044, reward: -10.0,3.0)\n",
      "Episode 135500/300000 ( TD_error: 2.8195241400822226, reward: -10.0,-10.0)\n",
      "Episode 135600/300000 ( TD_error: -0.23205341693680737, reward: -10.0,15.0)\n",
      "Episode 135700/300000 ( TD_error: 0.39411501225499235, reward: 14.0,6.0)\n",
      "Episode 135800/300000 ( TD_error: 0.3932769337840445, reward: 12.0,4.0)\n",
      "Episode 135900/300000 ( TD_error: -10.078794445884911, reward: -10.0,15.0)\n",
      "Episode 136000/300000 ( TD_error: 0.7076282060793293, reward: 14.0,3.0)\n",
      "Episode 136100/300000 ( TD_error: 0.16763984348790117, reward: -18.0,6.0)\n",
      "Episode 136200/300000 ( TD_error: 0.6347565749573736, reward: 13.0,8.0)\n",
      "Episode 136300/300000 ( TD_error: -0.6219112004890075, reward: -43.0,10.0)\n",
      "Episode 136400/300000 ( TD_error: 0.5231081076209012, reward: 8.0,7.0)\n",
      "Episode 136500/300000 ( TD_error: 0.5418107461225743, reward: 13.0,5.0)\n",
      "Episode 136600/300000 ( TD_error: 0.518466457097948, reward: 7.0,-10.0)\n",
      "Episode 136700/300000 ( TD_error: 0.6940512271342634, reward: 9.0,-10.0)\n",
      "Episode 136800/300000 ( TD_error: 0.6344994435369067, reward: 7.0,-15.0)\n",
      "Episode 136900/300000 ( TD_error: 0.918349511811253, reward: 15.0,-11.0)\n",
      "Episode 137000/300000 ( TD_error: -1.5950172046170739, reward: -10.0,-12.0)\n",
      "Episode 137100/300000 ( TD_error: 0.544336837442605, reward: 15.0,2.0)\n",
      "Episode 137200/300000 ( TD_error: -10.413808785137773, reward: -10.0,-10.0)\n",
      "Episode 137300/300000 ( TD_error: 0.08719421477408673, reward: -15.0,-10.0)\n",
      "Episode 137400/300000 ( TD_error: 0.48634717810501726, reward: 14.0,7.0)\n",
      "Episode 137500/300000 ( TD_error: 0.4498804583539018, reward: 7.0,8.0)\n",
      "Episode 137600/300000 ( TD_error: 0.44986074322044045, reward: 5.0,13.0)\n",
      "Episode 137700/300000 ( TD_error: -10.397492415254277, reward: -10.0,9.0)\n",
      "Episode 137800/300000 ( TD_error: 1.950601131302978, reward: -13.0,-10.0)\n",
      "Episode 137900/300000 ( TD_error: 0.41530065824856477, reward: 12.0,15.0)\n",
      "Episode 138000/300000 ( TD_error: 0.42267770256656867, reward: -21.0,5.0)\n",
      "Episode 138100/300000 ( TD_error: 0.36095809003940804, reward: 4.0,-1.0)\n",
      "Episode 138200/300000 ( TD_error: -1.4910642486989358, reward: -19.0,14.0)\n",
      "Episode 138300/300000 ( TD_error: 0.3265754071875828, reward: 7.0,-16.0)\n",
      "Episode 138400/300000 ( TD_error: -3.5130965305347903, reward: -21.0,14.0)\n",
      "Episode 138500/300000 ( TD_error: 0.42425494721530743, reward: 8.0,10.0)\n",
      "Episode 138600/300000 ( TD_error: 0.32441113612455297, reward: -37.0,13.0)\n",
      "Episode 138700/300000 ( TD_error: -10.041955109295136, reward: -10.0,-11.0)\n",
      "Episode 138800/300000 ( TD_error: 0.4192655401381997, reward: 14.0,7.0)\n",
      "Episode 138900/300000 ( TD_error: 0.3719732551302126, reward: 7.0,-16.0)\n",
      "Episode 139000/300000 ( TD_error: -1.176214486772924, reward: -18.0,15.0)\n",
      "Episode 139100/300000 ( TD_error: -1.8133327892127555, reward: -19.0,6.0)\n",
      "Episode 139200/300000 ( TD_error: -3.2457805736807277, reward: -14.0,-12.0)\n",
      "Episode 139300/300000 ( TD_error: 0.3910384029329399, reward: 14.0,6.0)\n",
      "Episode 139400/300000 ( TD_error: 0.4266285048904712, reward: 3.0,-12.0)\n",
      "Episode 139500/300000 ( TD_error: -3.06015514076463, reward: -10.0,9.0)\n",
      "Episode 139600/300000 ( TD_error: 1.3950900631128444, reward: 9.0,-24.0)\n",
      "Episode 139700/300000 ( TD_error: 0.27296193680626857, reward: -19.0,-20.0)\n",
      "Episode 139800/300000 ( TD_error: -10.077975372827606, reward: -10.0,11.0)\n",
      "Episode 139900/300000 ( TD_error: 0.535846687667032, reward: 2.0,4.0)\n",
      "Episode 140000/300000 ( TD_error: 0.3899480313042174, reward: 13.0,-14.0)\n",
      "Episode 140100/300000 ( TD_error: 0.3403962633376927, reward: 13.0,4.0)\n",
      "Episode 140200/300000 ( TD_error: 0.3657414476808363, reward: 3.0,12.0)\n",
      "Episode 140300/300000 ( TD_error: 0.3729046496814039, reward: 12.0,9.0)\n",
      "Episode 140400/300000 ( TD_error: 0.5400617177928693, reward: 9.0,-14.0)\n",
      "Episode 140500/300000 ( TD_error: 0.38265453126897553, reward: 1.0,-10.0)\n",
      "Episode 140600/300000 ( TD_error: -0.363275696906622, reward: -11.0,-10.0)\n",
      "Episode 140700/300000 ( TD_error: 0.7941025699471513, reward: 7.0,-14.0)\n",
      "Episode 140800/300000 ( TD_error: 0.502534713458155, reward: 6.0,6.0)\n",
      "Episode 140900/300000 ( TD_error: 0.40920961752967067, reward: -10.0,-11.0)\n",
      "Episode 141000/300000 ( TD_error: 0.5450450157286095, reward: 0.0,15.0)\n",
      "Episode 141100/300000 ( TD_error: -1.1738017583929512, reward: -21.0,-19.0)\n",
      "Episode 141200/300000 ( TD_error: 0.35739987231001313, reward: 13.0,-10.0)\n",
      "Episode 141300/300000 ( TD_error: 7.0821450555149505, reward: -10.0,3.0)\n",
      "Episode 141400/300000 ( TD_error: -10.063070561100872, reward: -10.0,-11.0)\n",
      "Episode 141500/300000 ( TD_error: 0.33402642988098874, reward: 13.0,-14.0)\n",
      "Episode 141600/300000 ( TD_error: -0.5707849902560627, reward: -10.0,15.0)\n",
      "Episode 141700/300000 ( TD_error: 0.4011563511788716, reward: 6.0,13.0)\n",
      "Episode 141800/300000 ( TD_error: 0.34896329876308707, reward: 5.0,7.0)\n",
      "Episode 141900/300000 ( TD_error: 0.35795719470639, reward: 13.0,6.0)\n",
      "Episode 142000/300000 ( TD_error: 0.5787783614517932, reward: 0.0,15.0)\n",
      "Episode 142100/300000 ( TD_error: -0.7387493189764935, reward: -29.0,6.0)\n",
      "Episode 142200/300000 ( TD_error: 0.32206250988296903, reward: 8.0,13.0)\n",
      "Episode 142300/300000 ( TD_error: 0.9624172797425905, reward: 15.0,9.0)\n",
      "Episode 142400/300000 ( TD_error: 0.351295859737335, reward: 6.0,-10.0)\n",
      "Episode 142500/300000 ( TD_error: 0.14894646362790098, reward: -10.0,-11.0)\n",
      "Episode 142600/300000 ( TD_error: 0.3442226466656151, reward: 10.0,15.0)\n",
      "Episode 142700/300000 ( TD_error: 1.3198142786403384, reward: -21.0,14.0)\n",
      "Episode 142800/300000 ( TD_error: -1.1600458552790585, reward: -11.0,-10.0)\n",
      "Episode 142900/300000 ( TD_error: 0.6546474335065606, reward: 3.0,7.0)\n",
      "Episode 143000/300000 ( TD_error: 0.3784057514518291, reward: 5.0,-10.0)\n",
      "Episode 143100/300000 ( TD_error: -0.15309643398460082, reward: -10.0,12.0)\n",
      "Episode 143200/300000 ( TD_error: 0.4446830975557683, reward: 6.0,-33.0)\n",
      "Episode 143300/300000 ( TD_error: 0.453760640713476, reward: -4.0,-11.0)\n",
      "Episode 143400/300000 ( TD_error: 0.35046250877609353, reward: 6.0,7.0)\n",
      "Episode 143500/300000 ( TD_error: -9.143314687630571, reward: -10.0,7.0)\n",
      "Episode 143600/300000 ( TD_error: 0.2530980503231284, reward: -83.0,-12.0)\n",
      "Episode 143700/300000 ( TD_error: 4.158819116066949, reward: -10.0,7.0)\n",
      "Episode 143800/300000 ( TD_error: 0.332150922594463, reward: 3.0,13.0)\n",
      "Episode 143900/300000 ( TD_error: 0.5681465592117139, reward: 11.0,-24.0)\n",
      "Episode 144000/300000 ( TD_error: -0.7974297242474542, reward: -23.0,2.0)\n",
      "Episode 144100/300000 ( TD_error: 1.1530181504412798, reward: 4.0,-31.0)\n",
      "Episode 144200/300000 ( TD_error: 1.4895640633784186, reward: 13.0,5.0)\n",
      "Episode 144300/300000 ( TD_error: 0.8189861939465408, reward: 5.0,3.0)\n",
      "Episode 144400/300000 ( TD_error: 0.5538551626134613, reward: 7.0,-19.0)\n",
      "Episode 144500/300000 ( TD_error: -0.21977273650093831, reward: -10.0,11.0)\n",
      "Episode 144600/300000 ( TD_error: 0.5152462277786789, reward: -14.0,12.0)\n",
      "Episode 144700/300000 ( TD_error: 1.188190266579297, reward: 7.0,10.0)\n",
      "Episode 144800/300000 ( TD_error: 1.0437071293023874, reward: 8.0,15.0)\n",
      "Episode 144900/300000 ( TD_error: 0.8407599798680137, reward: 14.0,-10.0)\n",
      "Episode 145000/300000 ( TD_error: 1.300247386699673, reward: 15.0,4.0)\n",
      "Episode 145100/300000 ( TD_error: -0.11116253876794069, reward: -10.0,-15.0)\n",
      "Episode 145200/300000 ( TD_error: -0.19341886469166614, reward: -11.0,12.0)\n",
      "Episode 145300/300000 ( TD_error: 1.1512211595049844, reward: 6.0,3.0)\n",
      "Episode 145400/300000 ( TD_error: 1.1438804428056728, reward: 14.0,11.0)\n",
      "Episode 145500/300000 ( TD_error: 1.5413943048609406, reward: 5.0,6.0)\n",
      "Episode 145600/300000 ( TD_error: 0.9254031539707075, reward: -15.0,8.0)\n",
      "Episode 145700/300000 ( TD_error: 0.801357128920456, reward: -5.0,0.0)\n",
      "Episode 145800/300000 ( TD_error: 1.6055466883683263, reward: -19.0,8.0)\n",
      "Episode 145900/300000 ( TD_error: 0.8190012411739476, reward: 5.0,6.0)\n",
      "Episode 146000/300000 ( TD_error: 0.8405380195838603, reward: -19.0,15.0)\n",
      "Episode 146100/300000 ( TD_error: -1.0037013211956207, reward: -11.0,7.0)\n",
      "Episode 146200/300000 ( TD_error: -0.9060570514145105, reward: -16.0,3.0)\n",
      "Episode 146300/300000 ( TD_error: 0.9186406984153836, reward: 13.0,11.0)\n",
      "Episode 146400/300000 ( TD_error: 0.9331159071106767, reward: 15.0,1.0)\n",
      "Episode 146500/300000 ( TD_error: -0.061691018692683564, reward: -10.0,-14.0)\n",
      "Episode 146600/300000 ( TD_error: -10.098913497634056, reward: -10.0,11.0)\n",
      "Episode 146700/300000 ( TD_error: -1.3999441241898598, reward: -10.0,14.0)\n",
      "Episode 146800/300000 ( TD_error: 0.7943936859201295, reward: 11.0,-13.0)\n",
      "Episode 146900/300000 ( TD_error: 0.6873124486426025, reward: 15.0,6.0)\n",
      "Episode 147000/300000 ( TD_error: -1.2316804965434152, reward: -10.0,-10.0)\n",
      "Episode 147100/300000 ( TD_error: 4.9786395265159324, reward: -10.0,9.0)\n",
      "Episode 147200/300000 ( TD_error: -0.42134374643110384, reward: -28.0,0.0)\n",
      "Episode 147300/300000 ( TD_error: 1.2972695485858867, reward: 15.0,-10.0)\n",
      "Episode 147400/300000 ( TD_error: -0.4049552862300114, reward: -21.0,15.0)\n",
      "Episode 147500/300000 ( TD_error: -10.092512285231576, reward: -10.0,-10.0)\n",
      "Episode 147600/300000 ( TD_error: -2.336181519319135, reward: -20.0,13.0)\n",
      "Episode 147700/300000 ( TD_error: 0.5244395512598818, reward: 14.0,15.0)\n",
      "Episode 147800/300000 ( TD_error: 0.5211820222394437, reward: 13.0,-24.0)\n",
      "Episode 147900/300000 ( TD_error: 0.8569796047170657, reward: 6.0,-47.0)\n",
      "Episode 148000/300000 ( TD_error: 0.1329028287318188, reward: -12.0,-10.0)\n",
      "Episode 148100/300000 ( TD_error: 0.40533641103167417, reward: 8.0,-58.0)\n",
      "Episode 148200/300000 ( TD_error: 0.3705070608271708, reward: 7.0,12.0)\n",
      "Episode 148300/300000 ( TD_error: 0.4720724218793442, reward: 14.0,11.0)\n",
      "Episode 148400/300000 ( TD_error: -0.6462309090008773, reward: -13.0,-14.0)\n",
      "Episode 148500/300000 ( TD_error: 0.010224903899812787, reward: -15.0,-10.0)\n",
      "Episode 148600/300000 ( TD_error: -2.2177276333252056, reward: -10.0,-68.0)\n",
      "Episode 148700/300000 ( TD_error: 0.5330293238931358, reward: 10.0,-14.0)\n",
      "Episode 148800/300000 ( TD_error: -0.17722475669091153, reward: -10.0,-10.0)\n",
      "Episode 148900/300000 ( TD_error: 0.07877244190881072, reward: -13.0,15.0)\n",
      "Episode 149000/300000 ( TD_error: 0.5259136787428873, reward: 8.0,6.0)\n",
      "Episode 149100/300000 ( TD_error: 0.5120324869061372, reward: 6.0,-10.0)\n",
      "Episode 149200/300000 ( TD_error: -1.7013609711079818, reward: -10.0,7.0)\n",
      "Episode 149300/300000 ( TD_error: 0.34287709003477174, reward: 12.0,-10.0)\n",
      "Episode 149400/300000 ( TD_error: 0.965663026188686, reward: -11.0,-11.0)\n",
      "Episode 149500/300000 ( TD_error: -2.643311369003065, reward: -10.0,-10.0)\n",
      "Episode 149600/300000 ( TD_error: 0.5102948808453083, reward: 5.0,10.0)\n",
      "Episode 149700/300000 ( TD_error: 0.5160718901185435, reward: 15.0,13.0)\n",
      "Episode 149800/300000 ( TD_error: -0.4611744567682088, reward: -10.0,7.0)\n",
      "Episode 149900/300000 ( TD_error: -0.0718665184956695, reward: -13.0,5.0)\n",
      "Episode 150000/300000 ( TD_error: -0.3562584479665718, reward: -11.0,13.0)\n",
      "Episode 150100/300000 ( TD_error: -10.500255345810942, reward: -10.0,-29.0)\n",
      "Episode 150200/300000 ( TD_error: -2.4021207057747676, reward: -15.0,8.0)\n",
      "Episode 150300/300000 ( TD_error: -1.559296305388541, reward: -20.0,10.0)\n",
      "Episode 150400/300000 ( TD_error: 0.27134121807624245, reward: 10.0,7.0)\n",
      "Episode 150500/300000 ( TD_error: 0.285800894375297, reward: 3.0,-10.0)\n",
      "Episode 150600/300000 ( TD_error: 0.43358219268025255, reward: 2.0,3.0)\n",
      "Episode 150700/300000 ( TD_error: 0.32605915205980374, reward: 5.0,8.0)\n",
      "Episode 150800/300000 ( TD_error: 0.29982503967701746, reward: 6.0,-13.0)\n",
      "Episode 150900/300000 ( TD_error: 16.40180671608121, reward: 15.0,4.0)\n",
      "Episode 151000/300000 ( TD_error: 0.3090296152460481, reward: 13.0,-11.0)\n",
      "Episode 151100/300000 ( TD_error: 1.0940195860370148, reward: 7.0,-23.0)\n",
      "Episode 151200/300000 ( TD_error: 1.0673609478733868, reward: 15.0,13.0)\n",
      "Episode 151300/300000 ( TD_error: -10.065789446295948, reward: -10.0,5.0)\n",
      "Episode 151400/300000 ( TD_error: 0.4039403366453316, reward: 4.0,-10.0)\n",
      "Episode 151500/300000 ( TD_error: -3.738665924736818, reward: -10.0,1.0)\n",
      "Episode 151600/300000 ( TD_error: 0.31124855311825783, reward: 12.0,10.0)\n",
      "Episode 151700/300000 ( TD_error: -10.477338028604319, reward: -10.0,10.0)\n",
      "Episode 151800/300000 ( TD_error: 0.41018080871993456, reward: 7.0,-10.0)\n",
      "Episode 151900/300000 ( TD_error: -1.8299040663910326, reward: -27.0,3.0)\n",
      "Episode 152000/300000 ( TD_error: 0.29390679744894044, reward: 7.0,13.0)\n",
      "Episode 152100/300000 ( TD_error: 0.6890181819204528, reward: 7.0,-14.0)\n",
      "Episode 152200/300000 ( TD_error: 0.36182782266702107, reward: 12.0,-19.0)\n",
      "Episode 152300/300000 ( TD_error: -0.7836181432113367, reward: -27.0,13.0)\n",
      "Episode 152400/300000 ( TD_error: 0.388671811470207, reward: 12.0,-3.0)\n",
      "Episode 152500/300000 ( TD_error: 0.29537638552930234, reward: 9.0,8.0)\n",
      "Episode 152600/300000 ( TD_error: 0.3352416761108685, reward: -24.0,-17.0)\n",
      "Episode 152700/300000 ( TD_error: -10.05520834463419, reward: -10.0,8.0)\n",
      "Episode 152800/300000 ( TD_error: 0.4504028696691136, reward: 13.0,10.0)\n",
      "Episode 152900/300000 ( TD_error: 0.344310059115553, reward: 9.0,10.0)\n",
      "Episode 153000/300000 ( TD_error: -0.14513088814393527, reward: -10.0,15.0)\n",
      "Episode 153100/300000 ( TD_error: -2.824041203145059, reward: -10.0,3.0)\n",
      "Episode 153200/300000 ( TD_error: 1.772654039468545, reward: -12.0,2.0)\n",
      "Episode 153300/300000 ( TD_error: -10.040690361991135, reward: -10.0,-10.0)\n",
      "Episode 153400/300000 ( TD_error: 0.318747599952383, reward: 13.0,6.0)\n",
      "Episode 153500/300000 ( TD_error: 2.3262508875490227, reward: -10.0,13.0)\n",
      "Episode 153600/300000 ( TD_error: 0.23725942476370676, reward: -15.0,7.0)\n",
      "Episode 153700/300000 ( TD_error: -0.39727465317679034, reward: -11.0,13.0)\n",
      "Episode 153800/300000 ( TD_error: 1.4469172841548934, reward: 13.0,13.0)\n",
      "Episode 153900/300000 ( TD_error: 1.445844320178165, reward: 6.0,6.0)\n",
      "Episode 154000/300000 ( TD_error: 0.8893552670396883, reward: 7.0,15.0)\n",
      "Episode 154100/300000 ( TD_error: -10.422781921329296, reward: -10.0,-11.0)\n",
      "Episode 154200/300000 ( TD_error: -0.8709169998203894, reward: -10.0,8.0)\n",
      "Episode 154300/300000 ( TD_error: 0.617883858295468, reward: 6.0,3.0)\n",
      "Episode 154400/300000 ( TD_error: 0.624027361707137, reward: 9.0,7.0)\n",
      "Episode 154500/300000 ( TD_error: -0.2216873692197483, reward: -10.0,13.0)\n",
      "Episode 154600/300000 ( TD_error: 1.072310157273078, reward: -11.0,-11.0)\n",
      "Episode 154700/300000 ( TD_error: 1.4303990794147126, reward: -10.0,-10.0)\n",
      "Episode 154800/300000 ( TD_error: -0.8820995824369966, reward: -16.0,6.0)\n",
      "Episode 154900/300000 ( TD_error: 0.546916181089733, reward: -10.0,5.0)\n",
      "Episode 155000/300000 ( TD_error: -10.451643666110957, reward: -10.0,7.0)\n",
      "Episode 155100/300000 ( TD_error: 1.1316717749814051, reward: 7.0,-10.0)\n",
      "Episode 155200/300000 ( TD_error: -10.03668733696005, reward: -10.0,10.0)\n",
      "Episode 155300/300000 ( TD_error: 0.6037055527070949, reward: 8.0,7.0)\n",
      "Episode 155400/300000 ( TD_error: 1.391525711580138, reward: 4.0,14.0)\n",
      "Episode 155500/300000 ( TD_error: 0.8268989343356425, reward: 5.0,6.0)\n",
      "Episode 155600/300000 ( TD_error: 0.6885817129446696, reward: 1.0,10.0)\n",
      "Episode 155700/300000 ( TD_error: 0.431249161972163, reward: 4.0,14.0)\n",
      "Episode 155800/300000 ( TD_error: 0.4804066284185673, reward: 10.0,-10.0)\n",
      "Episode 155900/300000 ( TD_error: 0.1471098538506368, reward: -30.0,1.0)\n",
      "Episode 156000/300000 ( TD_error: 0.8228116965636683, reward: 15.0,7.0)\n",
      "Episode 156100/300000 ( TD_error: 0.9963030350079483, reward: 15.0,-20.0)\n",
      "Episode 156200/300000 ( TD_error: 0.832391866458948, reward: 15.0,-22.0)\n",
      "Episode 156300/300000 ( TD_error: 1.0337687605105677, reward: 9.0,8.0)\n",
      "Episode 156400/300000 ( TD_error: 0.6801793364810536, reward: 4.0,10.0)\n",
      "Episode 156500/300000 ( TD_error: 0.42626697540048664, reward: 13.0,5.0)\n",
      "Episode 156600/300000 ( TD_error: 1.1487192136470288, reward: 9.0,11.0)\n",
      "Episode 156700/300000 ( TD_error: -0.8185577301480045, reward: -15.0,-1.0)\n",
      "Episode 156800/300000 ( TD_error: -9.992568816654252, reward: -10.0,9.0)\n",
      "Episode 156900/300000 ( TD_error: 0.3604707113262231, reward: 10.0,-10.0)\n",
      "Episode 157000/300000 ( TD_error: -3.8638013616196716, reward: -10.0,6.0)\n",
      "Episode 157100/300000 ( TD_error: 0.3518993172358651, reward: 15.0,-11.0)\n",
      "Episode 157200/300000 ( TD_error: -0.9975763349811153, reward: -40.0,-10.0)\n",
      "Episode 157300/300000 ( TD_error: 0.33544399508289047, reward: 13.0,-10.0)\n",
      "Episode 157400/300000 ( TD_error: 0.3699920904232865, reward: 10.0,5.0)\n",
      "Episode 157500/300000 ( TD_error: 0.3757017981891835, reward: 8.0,-17.0)\n",
      "Episode 157600/300000 ( TD_error: 0.30021059322246746, reward: 10.0,6.0)\n",
      "Episode 157700/300000 ( TD_error: -0.17613817673336207, reward: -13.0,-15.0)\n",
      "Episode 157800/300000 ( TD_error: 0.3274967540413867, reward: 2.0,13.0)\n",
      "Episode 157900/300000 ( TD_error: 1.1234749831726543, reward: -11.0,6.0)\n",
      "Episode 158000/300000 ( TD_error: -1.8149473624727115, reward: -11.0,-35.0)\n",
      "Episode 158100/300000 ( TD_error: 0.7315601125329829, reward: 13.0,-10.0)\n",
      "Episode 158200/300000 ( TD_error: 0.7656329304270293, reward: 13.0,-20.0)\n",
      "Episode 158300/300000 ( TD_error: 0.8833368573651392, reward: 14.0,-11.0)\n",
      "Episode 158400/300000 ( TD_error: -0.6576909666954815, reward: -13.0,10.0)\n",
      "Episode 158500/300000 ( TD_error: -10.478234317007725, reward: -10.0,-10.0)\n",
      "Episode 158600/300000 ( TD_error: -1.4281857235695181, reward: -26.0,-17.0)\n",
      "Episode 158700/300000 ( TD_error: -0.11682374989075761, reward: -11.0,4.0)\n",
      "Episode 158800/300000 ( TD_error: -1.8789640760088697, reward: -15.0,-10.0)\n",
      "Episode 158900/300000 ( TD_error: 0.548858649527951, reward: 6.0,-10.0)\n",
      "Episode 159000/300000 ( TD_error: -3.562764414977612, reward: -10.0,-13.0)\n",
      "Episode 159100/300000 ( TD_error: 6.881346385001028, reward: -10.0,8.0)\n",
      "Episode 159200/300000 ( TD_error: 0.3620989571511384, reward: 8.0,11.0)\n",
      "Episode 159300/300000 ( TD_error: 1.6515034015827137, reward: 15.0,-10.0)\n",
      "Episode 159400/300000 ( TD_error: -0.6585309648228392, reward: -10.0,-10.0)\n",
      "Episode 159500/300000 ( TD_error: -0.7534149509229326, reward: -50.0,6.0)\n",
      "Episode 159600/300000 ( TD_error: 0.3663390788521377, reward: 13.0,14.0)\n",
      "Episode 159700/300000 ( TD_error: -0.5030969985065674, reward: -10.0,1.0)\n",
      "Episode 159800/300000 ( TD_error: 0.3645001306564226, reward: 6.0,-19.0)\n",
      "Episode 159900/300000 ( TD_error: 0.26806892881409095, reward: 13.0,-10.0)\n",
      "Episode 160000/300000 ( TD_error: 0.2441490558648649, reward: 12.0,11.0)\n",
      "Episode 160100/300000 ( TD_error: -2.1749368846507977, reward: -10.0,-10.0)\n",
      "Episode 160200/300000 ( TD_error: -2.9023397067528807, reward: -17.0,9.0)\n",
      "Episode 160300/300000 ( TD_error: 6.624975911689825, reward: -10.0,7.0)\n",
      "Episode 160400/300000 ( TD_error: 0.5109912373123171, reward: 13.0,9.0)\n",
      "Episode 160500/300000 ( TD_error: 0.3329732608918512, reward: 12.0,11.0)\n",
      "Episode 160600/300000 ( TD_error: 0.407094289109184, reward: 8.0,-15.0)\n",
      "Episode 160700/300000 ( TD_error: 0.38772460153689225, reward: 6.0,15.0)\n",
      "Episode 160800/300000 ( TD_error: 0.326375916993777, reward: 7.0,6.0)\n",
      "Episode 160900/300000 ( TD_error: 0.3884990471483101, reward: 12.0,13.0)\n",
      "Episode 161000/300000 ( TD_error: 1.573761155526594, reward: 15.0,5.0)\n",
      "Episode 161100/300000 ( TD_error: 5.752152067969626, reward: -10.0,-14.0)\n",
      "Episode 161200/300000 ( TD_error: 0.46774222335537985, reward: 5.0,12.0)\n",
      "Episode 161300/300000 ( TD_error: 0.08094360726828143, reward: -11.0,15.0)\n",
      "Episode 161400/300000 ( TD_error: 0.43169275127521933, reward: 6.0,7.0)\n",
      "Episode 161500/300000 ( TD_error: -10.017565138068322, reward: -10.0,3.0)\n",
      "Episode 161600/300000 ( TD_error: 0.31901291263588494, reward: 14.0,-16.0)\n",
      "Episode 161700/300000 ( TD_error: -10.00971387607436, reward: -10.0,6.0)\n",
      "Episode 161800/300000 ( TD_error: -10.317481027820966, reward: -10.0,-12.0)\n",
      "Episode 161900/300000 ( TD_error: -10.33254650210716, reward: -10.0,-4.0)\n",
      "Episode 162000/300000 ( TD_error: 0.3906729214349549, reward: 12.0,-21.0)\n",
      "Episode 162100/300000 ( TD_error: 0.49422616283788745, reward: 5.0,-10.0)\n",
      "Episode 162200/300000 ( TD_error: 5.368568772449565, reward: -10.0,11.0)\n",
      "Episode 162300/300000 ( TD_error: 0.31066403186710767, reward: 8.0,6.0)\n",
      "Episode 162400/300000 ( TD_error: -3.6452025518907996, reward: -78.0,7.0)\n",
      "Episode 162500/300000 ( TD_error: 0.042003248046974306, reward: -13.0,7.0)\n",
      "Episode 162600/300000 ( TD_error: -0.08432365156009602, reward: -16.0,-10.0)\n",
      "Episode 162700/300000 ( TD_error: 0.6844685247930498, reward: 6.0,13.0)\n",
      "Episode 162800/300000 ( TD_error: 0.11251632038825932, reward: -10.0,-16.0)\n",
      "Episode 162900/300000 ( TD_error: 0.5629830192956176, reward: 13.0,-10.0)\n",
      "Episode 163000/300000 ( TD_error: 0.5345108923729622, reward: 10.0,-10.0)\n",
      "Episode 163100/300000 ( TD_error: 0.4156519628080053, reward: 13.0,6.0)\n",
      "Episode 163200/300000 ( TD_error: -0.13167704507152322, reward: -10.0,-11.0)\n",
      "Episode 163300/300000 ( TD_error: 0.3257147717215503, reward: 4.0,-14.0)\n",
      "Episode 163400/300000 ( TD_error: -0.01775874089256213, reward: -14.0,15.0)\n",
      "Episode 163500/300000 ( TD_error: 0.9004468090153002, reward: 10.0,15.0)\n",
      "Episode 163600/300000 ( TD_error: 0.8016637568272724, reward: 5.0,7.0)\n",
      "Episode 163700/300000 ( TD_error: -1.092111731663767, reward: -19.0,14.0)\n",
      "Episode 163800/300000 ( TD_error: -10.022115753178435, reward: -10.0,5.0)\n",
      "Episode 163900/300000 ( TD_error: 1.5262774873993052, reward: -19.0,-10.0)\n",
      "Episode 164000/300000 ( TD_error: -0.6820893967171404, reward: -15.0,7.0)\n",
      "Episode 164100/300000 ( TD_error: 0.9219104474006672, reward: 8.0,3.0)\n",
      "Episode 164200/300000 ( TD_error: 0.7826013948556918, reward: -10.0,5.0)\n",
      "Episode 164300/300000 ( TD_error: -2.500990176801988, reward: -10.0,11.0)\n",
      "Episode 164400/300000 ( TD_error: 1.0566776279646217, reward: 14.0,11.0)\n",
      "Episode 164500/300000 ( TD_error: -10.361742165249224, reward: -10.0,5.0)\n",
      "Episode 164600/300000 ( TD_error: -0.14812344131300126, reward: -10.0,13.0)\n",
      "Episode 164700/300000 ( TD_error: 0.5898390339446404, reward: -10.0,-10.0)\n",
      "Episode 164800/300000 ( TD_error: -10.011573737237086, reward: -10.0,-10.0)\n",
      "Episode 164900/300000 ( TD_error: 0.5073229593636372, reward: 6.0,-13.0)\n",
      "Episode 165000/300000 ( TD_error: 0.49855360289859796, reward: -32.0,13.0)\n",
      "Episode 165100/300000 ( TD_error: 0.10535953953017874, reward: -10.0,13.0)\n",
      "Episode 165200/300000 ( TD_error: -0.07228897495625475, reward: -13.0,-10.0)\n",
      "Episode 165300/300000 ( TD_error: 4.466968704683538, reward: -10.0,14.0)\n",
      "Episode 165400/300000 ( TD_error: -0.8560085975988105, reward: -18.0,5.0)\n",
      "Episode 165500/300000 ( TD_error: 0.4686486110804555, reward: 4.0,13.0)\n",
      "Episode 165600/300000 ( TD_error: 1.5818422022661025, reward: -21.0,6.0)\n",
      "Episode 165700/300000 ( TD_error: 0.4569793177742447, reward: 5.0,5.0)\n",
      "Episode 165800/300000 ( TD_error: 0.32700217993530156, reward: 6.0,15.0)\n",
      "Episode 165900/300000 ( TD_error: -0.5561334109317988, reward: -10.0,7.0)\n",
      "Episode 166000/300000 ( TD_error: 16.309617966463826, reward: 15.0,13.0)\n",
      "Episode 166100/300000 ( TD_error: 0.2969254988947929, reward: 4.0,-10.0)\n",
      "Episode 166200/300000 ( TD_error: 0.5426346185614177, reward: 6.0,-12.0)\n",
      "Episode 166300/300000 ( TD_error: 1.5989638611589259, reward: 15.0,-18.0)\n",
      "Episode 166400/300000 ( TD_error: 0.487426196658832, reward: 7.0,5.0)\n",
      "Episode 166500/300000 ( TD_error: 0.3307832941178859, reward: 5.0,8.0)\n",
      "Episode 166600/300000 ( TD_error: -1.0956134831620155, reward: -26.0,-15.0)\n",
      "Episode 166700/300000 ( TD_error: -3.0085201938860298, reward: -20.0,5.0)\n",
      "Episode 166800/300000 ( TD_error: 1.2898975650015974, reward: -17.0,14.0)\n",
      "Episode 166900/300000 ( TD_error: 1.6350119225876112, reward: 11.0,14.0)\n",
      "Episode 167000/300000 ( TD_error: -0.26208413640712447, reward: -10.0,13.0)\n",
      "Episode 167100/300000 ( TD_error: -0.9453720620066157, reward: -74.0,-17.0)\n",
      "Episode 167200/300000 ( TD_error: -0.9942931120525031, reward: -38.0,-10.0)\n",
      "Episode 167300/300000 ( TD_error: -0.6865752591051848, reward: -19.0,-10.0)\n",
      "Episode 167400/300000 ( TD_error: 1.7489157168971943, reward: -11.0,5.0)\n",
      "Episode 167500/300000 ( TD_error: 0.4650014721388023, reward: 6.0,-12.0)\n",
      "Episode 167600/300000 ( TD_error: 0.6236860716230477, reward: 13.0,-10.0)\n",
      "Episode 167700/300000 ( TD_error: 1.6513474147643539, reward: -16.0,0.0)\n",
      "Episode 167800/300000 ( TD_error: 0.055836210190122415, reward: -17.0,-10.0)\n",
      "Episode 167900/300000 ( TD_error: 0.48547990614404446, reward: 15.0,9.0)\n",
      "Episode 168000/300000 ( TD_error: 0.8787949868738218, reward: -5.0,14.0)\n",
      "Episode 168100/300000 ( TD_error: 0.4456466920155453, reward: 2.0,6.0)\n",
      "Episode 168200/300000 ( TD_error: -0.21465857126221977, reward: -10.0,9.0)\n",
      "Episode 168300/300000 ( TD_error: -1.0588504706073927, reward: -15.0,-15.0)\n",
      "Episode 168400/300000 ( TD_error: -2.5481983854715766, reward: -11.0,-10.0)\n",
      "Episode 168500/300000 ( TD_error: 0.8022791185733049, reward: 6.0,-10.0)\n",
      "Episode 168600/300000 ( TD_error: -10.010781581282227, reward: -10.0,15.0)\n",
      "Episode 168700/300000 ( TD_error: 0.9110234514192781, reward: 5.0,-15.0)\n",
      "Episode 168800/300000 ( TD_error: 0.8354491768530377, reward: 13.0,-11.0)\n",
      "Episode 168900/300000 ( TD_error: 0.5319661142178793, reward: 4.0,-12.0)\n",
      "Episode 169000/300000 ( TD_error: 0.46142092010001523, reward: 14.0,15.0)\n",
      "Episode 169100/300000 ( TD_error: 0.5491379671320011, reward: 13.0,-10.0)\n",
      "Episode 169200/300000 ( TD_error: 0.6733653829930666, reward: 7.0,-17.0)\n",
      "Episode 169300/300000 ( TD_error: 0.4196197039638818, reward: 11.0,15.0)\n",
      "Episode 169400/300000 ( TD_error: 0.7790622435741019, reward: 13.0,-35.0)\n",
      "Episode 169500/300000 ( TD_error: 0.4001588513708012, reward: 9.0,-16.0)\n",
      "Episode 169600/300000 ( TD_error: 0.6443210203292837, reward: -19.0,-10.0)\n",
      "Episode 169700/300000 ( TD_error: 4.755805599442148, reward: -10.0,8.0)\n",
      "Episode 169800/300000 ( TD_error: -10.351379571338073, reward: -10.0,8.0)\n",
      "Episode 169900/300000 ( TD_error: 0.3929359228410698, reward: 8.0,-10.0)\n",
      "Episode 170000/300000 ( TD_error: -0.9677181099804244, reward: -14.0,13.0)\n",
      "Episode 170100/300000 ( TD_error: 0.6425990184448733, reward: 1.0,9.0)\n",
      "Episode 170200/300000 ( TD_error: 0.3697937260587958, reward: 6.0,5.0)\n",
      "Episode 170300/300000 ( TD_error: 0.3014941539791729, reward: 14.0,-30.0)\n",
      "Episode 170400/300000 ( TD_error: 0.8715953003966561, reward: 4.0,15.0)\n",
      "Episode 170500/300000 ( TD_error: 0.6841572027752343, reward: 13.0,13.0)\n",
      "Episode 170600/300000 ( TD_error: 1.489668836881922, reward: 15.0,5.0)\n",
      "Episode 170700/300000 ( TD_error: 0.6243136783551178, reward: 15.0,15.0)\n",
      "Episode 170800/300000 ( TD_error: 0.7294924986513576, reward: 5.0,9.0)\n",
      "Episode 170900/300000 ( TD_error: 0.5397009731689844, reward: 4.0,-19.0)\n",
      "Episode 171000/300000 ( TD_error: 0.5107621400244788, reward: 11.0,10.0)\n",
      "Episode 171100/300000 ( TD_error: 1.1232759680456392, reward: 12.0,8.0)\n",
      "Episode 171200/300000 ( TD_error: 0.8565514121014974, reward: -10.0,-10.0)\n",
      "Episode 171300/300000 ( TD_error: 0.9497400398737885, reward: 8.0,-11.0)\n",
      "Episode 171400/300000 ( TD_error: 0.7496076608748932, reward: 13.0,13.0)\n",
      "Episode 171500/300000 ( TD_error: 0.5428031769242856, reward: 6.0,10.0)\n",
      "Episode 171600/300000 ( TD_error: -0.277400786686556, reward: -10.0,-10.0)\n",
      "Episode 171700/300000 ( TD_error: 0.40445728467157993, reward: 12.0,7.0)\n",
      "Episode 171800/300000 ( TD_error: 0.061523667385053216, reward: -10.0,-19.0)\n",
      "Episode 171900/300000 ( TD_error: 0.3321756859233247, reward: 10.0,13.0)\n",
      "Episode 172000/300000 ( TD_error: -10.02456363058858, reward: -10.0,6.0)\n",
      "Episode 172100/300000 ( TD_error: 0.33852012732032977, reward: 4.0,-15.0)\n",
      "Episode 172200/300000 ( TD_error: 0.31448661392149013, reward: 3.0,1.0)\n",
      "Episode 172300/300000 ( TD_error: 1.568468106630366, reward: 15.0,7.0)\n",
      "Episode 172400/300000 ( TD_error: -0.3941352655815713, reward: -10.0,13.0)\n",
      "Episode 172500/300000 ( TD_error: -1.2778244631846363, reward: -70.0,-66.0)\n",
      "Episode 172600/300000 ( TD_error: -1.2314206095200504, reward: -121.0,-10.0)\n",
      "Episode 172700/300000 ( TD_error: 0.4398452887700617, reward: 8.0,14.0)\n",
      "Episode 172800/300000 ( TD_error: 1.1773430176987083, reward: 14.0,7.0)\n",
      "Episode 172900/300000 ( TD_error: -1.5347354849895805, reward: -10.0,4.0)\n",
      "Episode 173000/300000 ( TD_error: -0.6204462337917551, reward: -31.0,15.0)\n",
      "Episode 173100/300000 ( TD_error: -0.562089195754055, reward: -11.0,-26.0)\n",
      "Episode 173200/300000 ( TD_error: 0.7851582836326854, reward: 12.0,-20.0)\n",
      "Episode 173300/300000 ( TD_error: 0.8122034998589993, reward: 10.0,4.0)\n",
      "Episode 173400/300000 ( TD_error: 0.6799745653686311, reward: -4.0,9.0)\n",
      "Episode 173500/300000 ( TD_error: 2.6311726935850555, reward: -10.0,-17.0)\n",
      "Episode 173600/300000 ( TD_error: 0.425536748857235, reward: 5.0,13.0)\n",
      "Episode 173700/300000 ( TD_error: 0.9604271678795486, reward: 14.0,-10.0)\n",
      "Episode 173800/300000 ( TD_error: 1.4076711993675803, reward: 7.0,14.0)\n",
      "Episode 173900/300000 ( TD_error: 0.5517372595566616, reward: -13.0,8.0)\n",
      "Episode 174000/300000 ( TD_error: 0.7229599424453301, reward: 7.0,15.0)\n",
      "Episode 174100/300000 ( TD_error: 1.2653809148054442, reward: -18.0,-13.0)\n",
      "Episode 174200/300000 ( TD_error: -0.9575675881259045, reward: -15.0,14.0)\n",
      "Episode 174300/300000 ( TD_error: -0.6040556443028322, reward: -10.0,-12.0)\n",
      "Episode 174400/300000 ( TD_error: 0.36219635821562735, reward: 5.0,12.0)\n",
      "Episode 174500/300000 ( TD_error: 0.32234242036554583, reward: 7.0,13.0)\n",
      "Episode 174600/300000 ( TD_error: 0.31325328564524213, reward: 4.0,11.0)\n",
      "Episode 174700/300000 ( TD_error: -0.02147054815589655, reward: -14.0,2.0)\n",
      "Episode 174800/300000 ( TD_error: 0.7242243282055778, reward: -12.0,-14.0)\n",
      "Episode 174900/300000 ( TD_error: -0.8081662798713278, reward: -18.0,-11.0)\n",
      "Episode 175000/300000 ( TD_error: 0.8812879165745153, reward: 7.0,-50.0)\n",
      "Episode 175100/300000 ( TD_error: -0.8521467653665322, reward: -14.0,8.0)\n",
      "Episode 175200/300000 ( TD_error: 0.5611531256057427, reward: 10.0,-10.0)\n",
      "Episode 175300/300000 ( TD_error: 0.4254367626976654, reward: 13.0,15.0)\n",
      "Episode 175400/300000 ( TD_error: -0.8467230332088889, reward: -17.0,5.0)\n",
      "Episode 175500/300000 ( TD_error: 0.4464259005654232, reward: 6.0,15.0)\n",
      "Episode 175600/300000 ( TD_error: 0.33692879528156805, reward: 13.0,8.0)\n",
      "Episode 175700/300000 ( TD_error: 0.4520622251142221, reward: 14.0,3.0)\n",
      "Episode 175800/300000 ( TD_error: 0.46156897903075667, reward: 8.0,10.0)\n",
      "Episode 175900/300000 ( TD_error: 0.3360613734898381, reward: 5.0,-22.0)\n",
      "Episode 176000/300000 ( TD_error: -0.22306536438598457, reward: -10.0,3.0)\n",
      "Episode 176100/300000 ( TD_error: -1.3572226572306025, reward: -10.0,-28.0)\n",
      "Episode 176200/300000 ( TD_error: 0.8121000525301008, reward: 12.0,13.0)\n",
      "Episode 176300/300000 ( TD_error: 0.7804454231522908, reward: 13.0,9.0)\n",
      "Episode 176400/300000 ( TD_error: 1.3823190548281192, reward: 5.0,5.0)\n",
      "Episode 176500/300000 ( TD_error: 0.8199672707714405, reward: 13.0,-47.0)\n",
      "Episode 176600/300000 ( TD_error: 0.692718540918996, reward: 13.0,-17.0)\n",
      "Episode 176700/300000 ( TD_error: 0.23233454758435101, reward: -30.0,-12.0)\n",
      "Episode 176800/300000 ( TD_error: -2.101789566144679, reward: -18.0,-24.0)\n",
      "Episode 176900/300000 ( TD_error: 0.9513438569361718, reward: 15.0,8.0)\n",
      "Episode 177000/300000 ( TD_error: 0.8865234819052721, reward: 10.0,8.0)\n",
      "Episode 177100/300000 ( TD_error: 1.1988359884903899, reward: 10.0,5.0)\n",
      "Episode 177200/300000 ( TD_error: 0.7261527330418871, reward: 8.0,12.0)\n",
      "Episode 177300/300000 ( TD_error: 0.5109209323030113, reward: 7.0,14.0)\n",
      "Episode 177400/300000 ( TD_error: 0.9781065853243351, reward: 6.0,14.0)\n",
      "Episode 177500/300000 ( TD_error: 0.7955093296119959, reward: 10.0,15.0)\n",
      "Episode 177600/300000 ( TD_error: 0.8414905644071742, reward: 5.0,-10.0)\n",
      "Episode 177700/300000 ( TD_error: -10.34965359434994, reward: -10.0,8.0)\n",
      "Episode 177800/300000 ( TD_error: 0.4678106844867811, reward: 9.0,-10.0)\n",
      "Episode 177900/300000 ( TD_error: 0.37119168246477274, reward: 5.0,9.0)\n",
      "Episode 178000/300000 ( TD_error: 0.6967925829642421, reward: 14.0,4.0)\n",
      "Episode 178100/300000 ( TD_error: -2.4211012344552767, reward: -10.0,3.0)\n",
      "Episode 178200/300000 ( TD_error: -9.99622055547987, reward: -10.0,-10.0)\n",
      "Episode 178300/300000 ( TD_error: -10.337689563068057, reward: -10.0,15.0)\n",
      "Episode 178400/300000 ( TD_error: -1.009066706303706, reward: -16.0,8.0)\n",
      "Episode 178500/300000 ( TD_error: 0.7944077538468419, reward: 15.0,-10.0)\n",
      "Episode 178600/300000 ( TD_error: 0.505664146796772, reward: 13.0,13.0)\n",
      "Episode 178700/300000 ( TD_error: -0.7039862520936815, reward: -12.0,0.0)\n",
      "Episode 178800/300000 ( TD_error: 2.916105797415006, reward: -10.0,1.0)\n",
      "Episode 178900/300000 ( TD_error: 0.37724035489313223, reward: 12.0,-10.0)\n",
      "Episode 179000/300000 ( TD_error: -10.362424254924417, reward: -10.0,8.0)\n",
      "Episode 179100/300000 ( TD_error: 0.5683846602998219, reward: 3.0,-15.0)\n",
      "Episode 179200/300000 ( TD_error: -10.359371245914202, reward: -10.0,13.0)\n",
      "Episode 179300/300000 ( TD_error: 0.38915845313362096, reward: 8.0,13.0)\n",
      "Episode 179400/300000 ( TD_error: -10.359405344409083, reward: -10.0,-14.0)\n",
      "Episode 179500/300000 ( TD_error: 1.5226576319753384, reward: -18.0,9.0)\n",
      "Episode 179600/300000 ( TD_error: -0.3362856607022149, reward: -15.0,13.0)\n",
      "Episode 179700/300000 ( TD_error: 2.0428490148794904, reward: 14.0,11.0)\n",
      "Episode 179800/300000 ( TD_error: 0.9470401590524795, reward: 10.0,-23.0)\n",
      "Episode 179900/300000 ( TD_error: -2.355672161588341, reward: -22.0,-10.0)\n",
      "Episode 180000/300000 ( TD_error: 0.2731531386175874, reward: -11.0,8.0)\n",
      "Episode 180100/300000 ( TD_error: 1.0317201122072635, reward: 14.0,-13.0)\n",
      "Episode 180200/300000 ( TD_error: -0.2956723743693672, reward: -18.0,15.0)\n",
      "Episode 180300/300000 ( TD_error: 0.5045798845250884, reward: 8.0,-24.0)\n",
      "Episode 180400/300000 ( TD_error: -2.4104650821974944, reward: -16.0,13.0)\n",
      "Episode 180500/300000 ( TD_error: 0.4930251500168783, reward: -14.0,4.0)\n",
      "Episode 180600/300000 ( TD_error: -9.973329200805647, reward: -10.0,8.0)\n",
      "Episode 180700/300000 ( TD_error: 1.119397181423392, reward: 13.0,11.0)\n",
      "Episode 180800/300000 ( TD_error: -0.6136288802238603, reward: -14.0,-24.0)\n",
      "Episode 180900/300000 ( TD_error: 1.527690439989573, reward: 5.0,-10.0)\n",
      "Episode 181000/300000 ( TD_error: 0.31739891466376413, reward: -10.0,-11.0)\n",
      "Episode 181100/300000 ( TD_error: 1.004160913486372, reward: 15.0,-13.0)\n",
      "Episode 181200/300000 ( TD_error: -2.125600382794631, reward: -18.0,-14.0)\n",
      "Episode 181300/300000 ( TD_error: 0.9595758629135185, reward: 10.0,15.0)\n",
      "Episode 181400/300000 ( TD_error: 0.7592510899798288, reward: 13.0,15.0)\n",
      "Episode 181500/300000 ( TD_error: 0.689990116711285, reward: 12.0,1.0)\n",
      "Episode 181600/300000 ( TD_error: -0.7929805568197832, reward: -11.0,2.0)\n",
      "Episode 181700/300000 ( TD_error: 1.03770244961926, reward: 8.0,15.0)\n",
      "Episode 181800/300000 ( TD_error: 0.5651012392787935, reward: 3.0,8.0)\n",
      "Episode 181900/300000 ( TD_error: 0.5417062038174696, reward: 5.0,15.0)\n",
      "Episode 182000/300000 ( TD_error: 0.3757358097128187, reward: 11.0,-10.0)\n",
      "Episode 182100/300000 ( TD_error: 1.3304195583558105, reward: -15.0,5.0)\n",
      "Episode 182200/300000 ( TD_error: 0.5190382080266485, reward: 3.0,15.0)\n",
      "Episode 182300/300000 ( TD_error: 0.3403988029337892, reward: 15.0,7.0)\n",
      "Episode 182400/300000 ( TD_error: -10.382725410620132, reward: -10.0,-15.0)\n",
      "Episode 182500/300000 ( TD_error: -0.6703117195337374, reward: -11.0,-10.0)\n",
      "Episode 182600/300000 ( TD_error: 0.34181399599854334, reward: 6.0,-31.0)\n",
      "Episode 182700/300000 ( TD_error: 0.7784356517545139, reward: 7.0,-10.0)\n",
      "Episode 182800/300000 ( TD_error: 0.5668387361544363, reward: 13.0,-10.0)\n",
      "Episode 182900/300000 ( TD_error: 0.14154251109895455, reward: -30.0,-17.0)\n",
      "Episode 183000/300000 ( TD_error: 0.4999597609485269, reward: 11.0,-13.0)\n",
      "Episode 183100/300000 ( TD_error: -2.443318585588581, reward: -12.0,13.0)\n",
      "Episode 183200/300000 ( TD_error: -10.415830522870532, reward: -10.0,-10.0)\n",
      "Episode 183300/300000 ( TD_error: 0.29072982342836795, reward: -10.0,3.0)\n",
      "Episode 183400/300000 ( TD_error: 0.6870606296985451, reward: 8.0,-6.0)\n",
      "Episode 183500/300000 ( TD_error: 0.6433254003035507, reward: 10.0,-16.0)\n",
      "Episode 183600/300000 ( TD_error: 0.6998334523215961, reward: 15.0,-14.0)\n",
      "Episode 183700/300000 ( TD_error: -7.940588202347337, reward: -10.0,14.0)\n",
      "Episode 183800/300000 ( TD_error: 0.36565521466043593, reward: 10.0,4.0)\n",
      "Episode 183900/300000 ( TD_error: -2.075225034960427, reward: -11.0,14.0)\n",
      "Episode 184000/300000 ( TD_error: 1.184512089903361, reward: -23.0,-11.0)\n",
      "Episode 184100/300000 ( TD_error: 0.42512480783713347, reward: 12.0,12.0)\n",
      "Episode 184200/300000 ( TD_error: 0.07055313258923857, reward: -10.0,-10.0)\n",
      "Episode 184300/300000 ( TD_error: -0.672332259847968, reward: -19.0,4.0)\n",
      "Episode 184400/300000 ( TD_error: 0.30776272531743, reward: 3.0,15.0)\n",
      "Episode 184500/300000 ( TD_error: 0.6412502677000385, reward: 5.0,-12.0)\n",
      "Episode 184600/300000 ( TD_error: 0.8706262918167313, reward: 5.0,-10.0)\n",
      "Episode 184700/300000 ( TD_error: 1.0089279813037417, reward: 6.0,-10.0)\n",
      "Episode 184800/300000 ( TD_error: 0.9772671999940918, reward: 2.0,11.0)\n",
      "Episode 184900/300000 ( TD_error: 0.9037136578889937, reward: 0.0,-10.0)\n",
      "Episode 185000/300000 ( TD_error: 1.383206955347477, reward: -21.0,15.0)\n",
      "Episode 185100/300000 ( TD_error: 0.9187808437160832, reward: 2.0,8.0)\n",
      "Episode 185200/300000 ( TD_error: 1.6092020017242954, reward: 5.0,-13.0)\n",
      "Episode 185300/300000 ( TD_error: 1.300607037775546, reward: 6.0,10.0)\n",
      "Episode 185400/300000 ( TD_error: 1.652001392356536, reward: 14.0,-16.0)\n",
      "Episode 185500/300000 ( TD_error: -0.6042582545065418, reward: -18.0,-23.0)\n",
      "Episode 185600/300000 ( TD_error: 1.6436912867031936, reward: 11.0,-11.0)\n",
      "Episode 185700/300000 ( TD_error: -0.6144432625933653, reward: -29.0,-14.0)\n",
      "Episode 185800/300000 ( TD_error: 0.988774556728719, reward: 15.0,-10.0)\n",
      "Episode 185900/300000 ( TD_error: 0.7658996975494392, reward: 15.0,13.0)\n",
      "Episode 186000/300000 ( TD_error: -9.98522520250619, reward: -10.0,13.0)\n",
      "Episode 186100/300000 ( TD_error: 5.283403750641904, reward: -10.0,-16.0)\n",
      "Episode 186200/300000 ( TD_error: 0.4689543687578488, reward: 13.0,13.0)\n",
      "Episode 186300/300000 ( TD_error: 1.2003288613392609, reward: 15.0,3.0)\n",
      "Episode 186400/300000 ( TD_error: -0.4553744840488747, reward: -26.0,-10.0)\n",
      "Episode 186500/300000 ( TD_error: 0.3272584789641906, reward: 6.0,-10.0)\n",
      "Episode 186600/300000 ( TD_error: -0.28402373386683344, reward: -10.0,7.0)\n",
      "Episode 186700/300000 ( TD_error: 1.3109964875930848, reward: 15.0,-11.0)\n",
      "Episode 186800/300000 ( TD_error: 0.5685873083197195, reward: 13.0,-10.0)\n",
      "Episode 186900/300000 ( TD_error: 0.8299198350511086, reward: 3.0,7.0)\n",
      "Episode 187000/300000 ( TD_error: 0.7990028541733798, reward: 12.0,-10.0)\n",
      "Episode 187100/300000 ( TD_error: 0.9458920794000925, reward: 13.0,-10.0)\n",
      "Episode 187200/300000 ( TD_error: 0.9380181609056515, reward: 2.0,-10.0)\n",
      "Episode 187300/300000 ( TD_error: 0.6124772545064165, reward: 5.0,13.0)\n",
      "Episode 187400/300000 ( TD_error: 1.462153911331281, reward: 15.0,12.0)\n",
      "Episode 187500/300000 ( TD_error: 1.4912557201185397, reward: -29.0,2.0)\n",
      "Episode 187600/300000 ( TD_error: -9.984393836854034, reward: -10.0,9.0)\n",
      "Episode 187700/300000 ( TD_error: -1.7602804730869899, reward: -17.0,3.0)\n",
      "Episode 187800/300000 ( TD_error: -2.6407105740153987, reward: -13.0,11.0)\n",
      "Episode 187900/300000 ( TD_error: 0.45440551069538326, reward: 6.0,-18.0)\n",
      "Episode 188000/300000 ( TD_error: 0.3501883521537352, reward: 5.0,15.0)\n",
      "Episode 188100/300000 ( TD_error: 0.3762183221756459, reward: 12.0,-10.0)\n",
      "Episode 188200/300000 ( TD_error: 1.3745270492954962, reward: 15.0,-19.0)\n",
      "Episode 188300/300000 ( TD_error: 0.48640327530912986, reward: 10.0,13.0)\n",
      "Episode 188400/300000 ( TD_error: 0.763041334972677, reward: 14.0,3.0)\n",
      "Episode 188500/300000 ( TD_error: 0.41746416113458595, reward: 1.0,5.0)\n",
      "Episode 188600/300000 ( TD_error: 0.3355057353938431, reward: -11.0,-44.0)\n",
      "Episode 188700/300000 ( TD_error: 0.3993420169078856, reward: 4.0,13.0)\n",
      "Episode 188800/300000 ( TD_error: 1.433588058749999, reward: 10.0,-10.0)\n",
      "Episode 188900/300000 ( TD_error: 1.1551011543325567, reward: 14.0,-10.0)\n",
      "Episode 189000/300000 ( TD_error: 0.3609836989493047, reward: -30.0,-10.0)\n",
      "Episode 189100/300000 ( TD_error: -3.3089086210248286, reward: -10.0,-10.0)\n",
      "Episode 189200/300000 ( TD_error: -0.7520059352942816, reward: -46.0,6.0)\n",
      "Episode 189300/300000 ( TD_error: 0.2543990258968023, reward: -27.0,-11.0)\n",
      "Episode 189400/300000 ( TD_error: 1.0229754771158173, reward: 12.0,-16.0)\n",
      "Episode 189500/300000 ( TD_error: 0.4047025237607009, reward: -37.0,-12.0)\n",
      "Episode 189600/300000 ( TD_error: -2.6518772675069284, reward: -17.0,-10.0)\n",
      "Episode 189700/300000 ( TD_error: 0.9046550768905872, reward: 4.0,5.0)\n",
      "Episode 189800/300000 ( TD_error: 16.309931752157397, reward: 15.0,-10.0)\n",
      "Episode 189900/300000 ( TD_error: 0.5248553597863479, reward: 0.0,-18.0)\n",
      "Episode 190000/300000 ( TD_error: 1.2988860937646751, reward: 15.0,-10.0)\n",
      "Episode 190100/300000 ( TD_error: 6.206122923490382, reward: -10.0,-10.0)\n",
      "Episode 190200/300000 ( TD_error: 0.383787377091223, reward: 14.0,5.0)\n",
      "Episode 190300/300000 ( TD_error: -10.340044858182866, reward: -10.0,2.0)\n",
      "Episode 190400/300000 ( TD_error: 0.7982216728890932, reward: 6.0,10.0)\n",
      "Episode 190500/300000 ( TD_error: 1.2858685437572683, reward: 9.0,13.0)\n",
      "Episode 190600/300000 ( TD_error: 1.2486793086354435, reward: -12.0,2.0)\n",
      "Episode 190700/300000 ( TD_error: 1.3178470151343804, reward: 7.0,14.0)\n",
      "Episode 190800/300000 ( TD_error: 0.6452441123818895, reward: 13.0,8.0)\n",
      "Episode 190900/300000 ( TD_error: 0.7556292721522557, reward: 7.0,6.0)\n",
      "Episode 191000/300000 ( TD_error: 0.41047092409414176, reward: -12.0,-12.0)\n",
      "Episode 191100/300000 ( TD_error: -0.18706274964870673, reward: -10.0,-12.0)\n",
      "Episode 191200/300000 ( TD_error: 1.0040394700036321, reward: 13.0,14.0)\n",
      "Episode 191300/300000 ( TD_error: -0.22306569401154874, reward: -10.0,7.0)\n",
      "Episode 191400/300000 ( TD_error: -9.972676446497418, reward: -10.0,14.0)\n",
      "Episode 191500/300000 ( TD_error: 0.11354536485865552, reward: -15.0,-10.0)\n",
      "Episode 191600/300000 ( TD_error: 0.7189923850976232, reward: 13.0,-12.0)\n",
      "Episode 191700/300000 ( TD_error: 0.9503867032899707, reward: 14.0,8.0)\n",
      "Episode 191800/300000 ( TD_error: -0.728220961621183, reward: -14.0,4.0)\n",
      "Episode 191900/300000 ( TD_error: -0.12556202747276224, reward: -10.0,-10.0)\n",
      "Episode 192000/300000 ( TD_error: -0.7931579040009709, reward: -10.0,15.0)\n",
      "Episode 192100/300000 ( TD_error: 0.15589251704936835, reward: -10.0,5.0)\n",
      "Episode 192200/300000 ( TD_error: 0.1404219565094209, reward: -21.0,-14.0)\n",
      "Episode 192300/300000 ( TD_error: 0.34995962535848024, reward: 5.0,7.0)\n",
      "Episode 192400/300000 ( TD_error: 0.361118971973843, reward: 15.0,8.0)\n",
      "Episode 192500/300000 ( TD_error: -3.0729729872000107, reward: -10.0,5.0)\n",
      "Episode 192600/300000 ( TD_error: -0.9565345770863054, reward: -10.0,13.0)\n",
      "Episode 192700/300000 ( TD_error: 0.34201481591565575, reward: 10.0,10.0)\n",
      "Episode 192800/300000 ( TD_error: -0.46192731964483436, reward: -10.0,-16.0)\n",
      "Episode 192900/300000 ( TD_error: 0.4615613573048911, reward: -10.0,14.0)\n",
      "Episode 193000/300000 ( TD_error: 0.8771707746128099, reward: 11.0,6.0)\n",
      "Episode 193100/300000 ( TD_error: -0.5984942330135663, reward: -21.0,13.0)\n",
      "Episode 193200/300000 ( TD_error: -0.9916043472667688, reward: -44.0,8.0)\n",
      "Episode 193300/300000 ( TD_error: -0.7657574478570126, reward: -18.0,13.0)\n",
      "Episode 193400/300000 ( TD_error: 1.691148294762813, reward: 15.0,6.0)\n",
      "Episode 193500/300000 ( TD_error: 0.3938018727107693, reward: 7.0,12.0)\n",
      "Episode 193600/300000 ( TD_error: 0.3194758083353477, reward: 3.0,15.0)\n",
      "Episode 193700/300000 ( TD_error: 0.41068869515905915, reward: 13.0,15.0)\n",
      "Episode 193800/300000 ( TD_error: 0.3731051847732729, reward: 11.0,-10.0)\n",
      "Episode 193900/300000 ( TD_error: 0.28294244358208953, reward: 12.0,8.0)\n",
      "Episode 194000/300000 ( TD_error: 0.2729115120374357, reward: -45.0,-23.0)\n",
      "Episode 194100/300000 ( TD_error: 0.2410267268031836, reward: 3.0,15.0)\n",
      "Episode 194200/300000 ( TD_error: 0.3108656360262776, reward: 5.0,5.0)\n",
      "Episode 194300/300000 ( TD_error: 0.33047052937127575, reward: 13.0,7.0)\n",
      "Episode 194400/300000 ( TD_error: 0.35346423445053476, reward: -27.0,-10.0)\n",
      "Episode 194500/300000 ( TD_error: 0.03258743734673786, reward: -19.0,-14.0)\n",
      "Episode 194600/300000 ( TD_error: 0.28887447289899537, reward: 10.0,6.0)\n",
      "Episode 194700/300000 ( TD_error: -9.983993256225435, reward: -10.0,12.0)\n",
      "Episode 194800/300000 ( TD_error: 0.4787161650721292, reward: 6.0,12.0)\n",
      "Episode 194900/300000 ( TD_error: 0.9408190214113854, reward: 5.0,11.0)\n",
      "Episode 195000/300000 ( TD_error: 0.9255460116229757, reward: 4.0,8.0)\n",
      "Episode 195100/300000 ( TD_error: 0.7607525571791185, reward: 13.0,-10.0)\n",
      "Episode 195200/300000 ( TD_error: 0.9277559298532414, reward: 14.0,5.0)\n",
      "Episode 195300/300000 ( TD_error: 0.9495765011424333, reward: 13.0,-13.0)\n",
      "Episode 195400/300000 ( TD_error: -0.879232396819047, reward: -10.0,6.0)\n",
      "Episode 195500/300000 ( TD_error: 0.14468823074747927, reward: -52.0,5.0)\n",
      "Episode 195600/300000 ( TD_error: -0.03102949685159473, reward: -15.0,14.0)\n",
      "Episode 195700/300000 ( TD_error: -9.9847776832484, reward: -10.0,-19.0)\n",
      "Episode 195800/300000 ( TD_error: -0.4265050599594886, reward: -15.0,15.0)\n",
      "Episode 195900/300000 ( TD_error: 0.794915864167907, reward: 10.0,5.0)\n",
      "Episode 196000/300000 ( TD_error: 1.0262960958629836, reward: 7.0,-10.0)\n",
      "Episode 196100/300000 ( TD_error: 0.8195866623200514, reward: 6.0,-10.0)\n",
      "Episode 196200/300000 ( TD_error: 1.1301057787682018, reward: 12.0,-51.0)\n",
      "Episode 196300/300000 ( TD_error: 1.0609700063482324, reward: 13.0,-12.0)\n",
      "Episode 196400/300000 ( TD_error: 1.375915902100643, reward: 13.0,-23.0)\n",
      "Episode 196500/300000 ( TD_error: -0.5034928475088325, reward: -14.0,-10.0)\n",
      "Episode 196600/300000 ( TD_error: -0.6850317171958498, reward: -19.0,-11.0)\n",
      "Episode 196700/300000 ( TD_error: 1.070466552094814, reward: -10.0,14.0)\n",
      "Episode 196800/300000 ( TD_error: 1.2075352933833665, reward: 5.0,13.0)\n",
      "Episode 196900/300000 ( TD_error: 0.8970975022744172, reward: 15.0,-31.0)\n",
      "Episode 197000/300000 ( TD_error: 0.9439181370853107, reward: 7.0,13.0)\n",
      "Episode 197100/300000 ( TD_error: -0.014630085261163828, reward: -11.0,4.0)\n",
      "Episode 197200/300000 ( TD_error: -9.981135702796287, reward: -10.0,3.0)\n",
      "Episode 197300/300000 ( TD_error: -0.602097125492504, reward: -18.0,10.0)\n",
      "Episode 197400/300000 ( TD_error: 1.5693461589389615, reward: 14.0,14.0)\n",
      "Episode 197500/300000 ( TD_error: 1.0582403765491537, reward: 8.0,-45.0)\n",
      "Episode 197600/300000 ( TD_error: -0.25331062806595916, reward: -17.0,8.0)\n",
      "Episode 197700/300000 ( TD_error: 1.2394872688465401, reward: 4.0,13.0)\n",
      "Episode 197800/300000 ( TD_error: 1.3499588125082282, reward: 7.0,14.0)\n",
      "Episode 197900/300000 ( TD_error: 1.3826732927038714, reward: 14.0,-10.0)\n",
      "Episode 198000/300000 ( TD_error: -0.3963885467704493, reward: -17.0,11.0)\n",
      "Episode 198100/300000 ( TD_error: 0.7669981400058861, reward: 6.0,-11.0)\n",
      "Episode 198200/300000 ( TD_error: -0.8276432789121024, reward: -59.0,9.0)\n",
      "Episode 198300/300000 ( TD_error: -2.1988534823662773, reward: -21.0,-10.0)\n",
      "Episode 198400/300000 ( TD_error: 0.9535112619230732, reward: 10.0,-10.0)\n",
      "Episode 198500/300000 ( TD_error: -2.216429536772748, reward: -22.0,-10.0)\n",
      "Episode 198600/300000 ( TD_error: 1.4753119498300347, reward: 9.0,4.0)\n",
      "Episode 198700/300000 ( TD_error: 1.1997283094151445, reward: 4.0,9.0)\n",
      "Episode 198800/300000 ( TD_error: 0.6974590141635617, reward: 7.0,-10.0)\n",
      "Episode 198900/300000 ( TD_error: 1.0034976234691668, reward: 9.0,8.0)\n",
      "Episode 199000/300000 ( TD_error: 1.510007775600224, reward: -13.0,-11.0)\n",
      "Episode 199100/300000 ( TD_error: -0.8045775427784356, reward: -18.0,-17.0)\n",
      "Episode 199200/300000 ( TD_error: -10.367592177793798, reward: -10.0,15.0)\n",
      "Episode 199300/300000 ( TD_error: 1.0342660924407232, reward: 11.0,6.0)\n",
      "Episode 199400/300000 ( TD_error: -0.7889451511077574, reward: -12.0,-15.0)\n",
      "Episode 199500/300000 ( TD_error: 1.2445501949550897, reward: 11.0,14.0)\n",
      "Episode 199600/300000 ( TD_error: 1.083323718550698, reward: 6.0,11.0)\n",
      "Episode 199700/300000 ( TD_error: 0.5848225130707774, reward: 15.0,1.0)\n",
      "Episode 199800/300000 ( TD_error: 0.26643238271406844, reward: -14.0,-10.0)\n",
      "Episode 199900/300000 ( TD_error: 0.5419157374418044, reward: 15.0,-11.0)\n",
      "Episode 200000/300000 ( TD_error: -0.8511411561245588, reward: -14.0,-10.0)\n",
      "Episode 200100/300000 ( TD_error: 0.5308683627091235, reward: 14.0,4.0)\n",
      "Episode 200200/300000 ( TD_error: 0.6041347490733808, reward: 7.0,-9.0)\n",
      "Episode 200300/300000 ( TD_error: 0.5815897964167558, reward: -15.0,-16.0)\n",
      "Episode 200400/300000 ( TD_error: -2.441695841702437, reward: -21.0,-11.0)\n",
      "Episode 200500/300000 ( TD_error: 1.0961833652684234, reward: 11.0,10.0)\n",
      "Episode 200600/300000 ( TD_error: 1.2908544700485631, reward: 10.0,15.0)\n",
      "Episode 200700/300000 ( TD_error: 0.9295247930858799, reward: 3.0,8.0)\n",
      "Episode 200800/300000 ( TD_error: 0.5035348367196661, reward: 3.0,5.0)\n",
      "Episode 200900/300000 ( TD_error: 0.4107805375322542, reward: 13.0,5.0)\n",
      "Episode 201000/300000 ( TD_error: 0.607057687365693, reward: 10.0,9.0)\n",
      "Episode 201100/300000 ( TD_error: 0.4053432844746192, reward: 8.0,-39.0)\n",
      "Episode 201200/300000 ( TD_error: 0.3879103647025426, reward: 12.0,5.0)\n",
      "Episode 201300/300000 ( TD_error: 0.3534439418806894, reward: 5.0,1.0)\n",
      "Episode 201400/300000 ( TD_error: 0.395315917126533, reward: 15.0,13.0)\n",
      "Episode 201500/300000 ( TD_error: 0.5851572056744132, reward: -12.0,13.0)\n",
      "Episode 201600/300000 ( TD_error: 0.3721085167217466, reward: 6.0,7.0)\n",
      "Episode 201700/300000 ( TD_error: -0.8778847858372689, reward: -25.0,3.0)\n",
      "Episode 201800/300000 ( TD_error: 0.3103931986456425, reward: 4.0,15.0)\n",
      "Episode 201900/300000 ( TD_error: -0.44529715023207483, reward: -10.0,13.0)\n",
      "Episode 202000/300000 ( TD_error: -0.9289112583181858, reward: -13.0,1.0)\n",
      "Episode 202100/300000 ( TD_error: 0.37949616647755136, reward: 15.0,-11.0)\n",
      "Episode 202200/300000 ( TD_error: -10.31389062727214, reward: -10.0,12.0)\n",
      "Episode 202300/300000 ( TD_error: -0.8493252838887049, reward: -13.0,10.0)\n",
      "Episode 202400/300000 ( TD_error: 0.43415055657632173, reward: -16.0,-12.0)\n",
      "Episode 202500/300000 ( TD_error: -2.3038392441370448, reward: -16.0,5.0)\n",
      "Episode 202600/300000 ( TD_error: 1.0302301061014347, reward: 15.0,8.0)\n",
      "Episode 202700/300000 ( TD_error: 0.9997335033195682, reward: 14.0,14.0)\n",
      "Episode 202800/300000 ( TD_error: -0.4389062072098522, reward: -10.0,12.0)\n",
      "Episode 202900/300000 ( TD_error: -0.10850881661367673, reward: -12.0,1.0)\n",
      "Episode 203000/300000 ( TD_error: -10.325570004122557, reward: -10.0,4.0)\n",
      "Episode 203100/300000 ( TD_error: 0.9839848817209793, reward: 12.0,-10.0)\n",
      "Episode 203200/300000 ( TD_error: -10.315428788797416, reward: -10.0,2.0)\n",
      "Episode 203300/300000 ( TD_error: -0.4439566352739286, reward: -10.0,-11.0)\n",
      "Episode 203400/300000 ( TD_error: 1.0561057555160254, reward: 8.0,-10.0)\n",
      "Episode 203500/300000 ( TD_error: -0.3153388819275724, reward: -10.0,10.0)\n",
      "Episode 203600/300000 ( TD_error: -0.42394228552950786, reward: -12.0,-10.0)\n",
      "Episode 203700/300000 ( TD_error: 0.9994211138288209, reward: 15.0,-12.0)\n",
      "Episode 203800/300000 ( TD_error: 1.0467502862499183, reward: 14.0,-13.0)\n",
      "Episode 203900/300000 ( TD_error: -0.09663005536470592, reward: -23.0,-11.0)\n",
      "Episode 204000/300000 ( TD_error: -0.3560582996105861, reward: -21.0,-10.0)\n",
      "Episode 204100/300000 ( TD_error: 0.43192894487042777, reward: 13.0,-16.0)\n",
      "Episode 204200/300000 ( TD_error: 0.4472667068307721, reward: 7.0,-11.0)\n",
      "Episode 204300/300000 ( TD_error: 0.7373555629850213, reward: -19.0,15.0)\n",
      "Episode 204400/300000 ( TD_error: 0.4273331434963259, reward: 13.0,-15.0)\n",
      "Episode 204500/300000 ( TD_error: 0.448240574908116, reward: -21.0,8.0)\n",
      "Episode 204600/300000 ( TD_error: 0.31140971313993937, reward: 13.0,-11.0)\n",
      "Episode 204700/300000 ( TD_error: 0.286137229156461, reward: 14.0,-11.0)\n",
      "Episode 204800/300000 ( TD_error: -0.45319087888772813, reward: -10.0,3.0)\n",
      "Episode 204900/300000 ( TD_error: -0.4260409512656578, reward: -10.0,10.0)\n",
      "Episode 205000/300000 ( TD_error: 0.7230348496388412, reward: -24.0,14.0)\n",
      "Episode 205100/300000 ( TD_error: -0.29279971635788016, reward: -10.0,15.0)\n",
      "Episode 205200/300000 ( TD_error: 0.2586689853069153, reward: 0.0,-12.0)\n",
      "Episode 205300/300000 ( TD_error: 0.2588461529231405, reward: 7.0,14.0)\n",
      "Episode 205400/300000 ( TD_error: 5.684000300157555, reward: -10.0,-20.0)\n",
      "Episode 205500/300000 ( TD_error: 0.25994165088624754, reward: 11.0,12.0)\n",
      "Episode 205600/300000 ( TD_error: 0.32896025223344516, reward: 11.0,7.0)\n",
      "Episode 205700/300000 ( TD_error: 0.25798672240300924, reward: 2.0,9.0)\n",
      "Episode 205800/300000 ( TD_error: 0.26795195914900694, reward: 13.0,4.0)\n",
      "Episode 205900/300000 ( TD_error: 0.30746172684957607, reward: 11.0,-19.0)\n",
      "Episode 206000/300000 ( TD_error: 0.27088653440343613, reward: 13.0,6.0)\n",
      "Episode 206100/300000 ( TD_error: 0.2919375089721621, reward: 12.0,-10.0)\n",
      "Episode 206200/300000 ( TD_error: 2.0578506225694886, reward: 15.0,-12.0)\n",
      "Episode 206300/300000 ( TD_error: 0.21485788431873143, reward: 9.0,-10.0)\n",
      "Episode 206400/300000 ( TD_error: 0.3325780267830005, reward: 0.0,-10.0)\n",
      "Episode 206500/300000 ( TD_error: 0.2232869855577353, reward: 10.0,15.0)\n",
      "Episode 206600/300000 ( TD_error: -9.930733965889704, reward: -10.0,-10.0)\n",
      "Episode 206700/300000 ( TD_error: -0.7959349007891863, reward: -62.0,-12.0)\n",
      "Episode 206800/300000 ( TD_error: 0.3016564891737481, reward: 8.0,-14.0)\n",
      "Episode 206900/300000 ( TD_error: 0.3266638411958467, reward: 12.0,12.0)\n",
      "Episode 207000/300000 ( TD_error: 0.2694315948026551, reward: 15.0,8.0)\n",
      "Episode 207100/300000 ( TD_error: 0.22810190021120125, reward: 8.0,15.0)\n",
      "Episode 207200/300000 ( TD_error: 0.2400435951574087, reward: 12.0,10.0)\n",
      "Episode 207300/300000 ( TD_error: 6.017404326067986, reward: -10.0,-14.0)\n",
      "Episode 207400/300000 ( TD_error: -0.4128705675421642, reward: -10.0,7.0)\n",
      "Episode 207500/300000 ( TD_error: -0.8090945853437805, reward: -14.0,2.0)\n",
      "Episode 207600/300000 ( TD_error: -0.615899973471091, reward: -15.0,4.0)\n",
      "Episode 207700/300000 ( TD_error: 5.8492949475783504, reward: -10.0,4.0)\n",
      "Episode 207800/300000 ( TD_error: 0.23747734268697007, reward: 4.0,4.0)\n",
      "Episode 207900/300000 ( TD_error: -0.7171321747567543, reward: -10.0,-12.0)\n",
      "Episode 208000/300000 ( TD_error: 0.912792215626097, reward: 9.0,12.0)\n",
      "Episode 208100/300000 ( TD_error: 0.44251872548727444, reward: 8.0,6.0)\n",
      "Episode 208200/300000 ( TD_error: 0.3921469354274332, reward: 5.0,-10.0)\n",
      "Episode 208300/300000 ( TD_error: 0.6939956003497514, reward: -11.0,13.0)\n",
      "Episode 208400/300000 ( TD_error: 0.4560325733007984, reward: 7.0,3.0)\n",
      "Episode 208500/300000 ( TD_error: -0.9999038961863942, reward: -13.0,13.0)\n",
      "Episode 208600/300000 ( TD_error: -0.654938507269744, reward: -12.0,13.0)\n",
      "Episode 208700/300000 ( TD_error: 0.453760481551722, reward: -13.0,13.0)\n",
      "Episode 208800/300000 ( TD_error: 0.3215848790896785, reward: 15.0,9.0)\n",
      "Episode 208900/300000 ( TD_error: 0.36451683971520277, reward: 14.0,15.0)\n",
      "Episode 209000/300000 ( TD_error: 0.3264883254813591, reward: 2.0,-10.0)\n",
      "Episode 209100/300000 ( TD_error: 2.8540096145815, reward: -10.0,-15.0)\n",
      "Episode 209200/300000 ( TD_error: 0.31503263692361205, reward: 3.0,8.0)\n",
      "Episode 209300/300000 ( TD_error: 1.3872371699692714, reward: -10.0,-16.0)\n",
      "Episode 209400/300000 ( TD_error: -0.7876876908187445, reward: -44.0,4.0)\n",
      "Episode 209500/300000 ( TD_error: 2.7460113747901698, reward: -10.0,-10.0)\n",
      "Episode 209600/300000 ( TD_error: 0.381998596889487, reward: 9.0,15.0)\n",
      "Episode 209700/300000 ( TD_error: 0.283972058745106, reward: -17.0,7.0)\n",
      "Episode 209800/300000 ( TD_error: 0.5982652070925103, reward: 3.0,5.0)\n",
      "Episode 209900/300000 ( TD_error: -9.936094677571901, reward: -10.0,15.0)\n",
      "Episode 210000/300000 ( TD_error: 0.1665025238364315, reward: -31.0,-24.0)\n",
      "Episode 210100/300000 ( TD_error: 0.7211763655378891, reward: 12.0,14.0)\n",
      "Episode 210200/300000 ( TD_error: 0.9298751204237794, reward: 11.0,-14.0)\n",
      "Episode 210300/300000 ( TD_error: -0.061267240072576, reward: -10.0,-20.0)\n",
      "Episode 210400/300000 ( TD_error: -10.279848280840502, reward: -10.0,-11.0)\n",
      "Episode 210500/300000 ( TD_error: -10.2832767924847, reward: -10.0,6.0)\n",
      "Episode 210600/300000 ( TD_error: 0.7728922069523159, reward: 13.0,4.0)\n",
      "Episode 210700/300000 ( TD_error: 0.6007009769317104, reward: -21.0,-10.0)\n",
      "Episode 210800/300000 ( TD_error: 0.4055310205345055, reward: 9.0,2.0)\n",
      "Episode 210900/300000 ( TD_error: -0.7007851437544854, reward: -10.0,-10.0)\n",
      "Episode 211000/300000 ( TD_error: -10.281895111397311, reward: -10.0,-11.0)\n",
      "Episode 211100/300000 ( TD_error: 1.3270372635460586, reward: 14.0,10.0)\n",
      "Episode 211200/300000 ( TD_error: -0.760534565598137, reward: -10.0,4.0)\n",
      "Episode 211300/300000 ( TD_error: 1.0223590148858754, reward: 8.0,12.0)\n",
      "Episode 211400/300000 ( TD_error: 0.6715472644157541, reward: 6.0,15.0)\n",
      "Episode 211500/300000 ( TD_error: -0.12773130865630655, reward: -10.0,-16.0)\n",
      "Episode 211600/300000 ( TD_error: -0.5291005703538758, reward: -18.0,-10.0)\n",
      "Episode 211700/300000 ( TD_error: -0.8062586966406222, reward: -55.0,-10.0)\n",
      "Episode 211800/300000 ( TD_error: 0.39646755435636116, reward: 12.0,15.0)\n",
      "Episode 211900/300000 ( TD_error: 0.5718759047102981, reward: -19.0,-21.0)\n",
      "Episode 212000/300000 ( TD_error: 1.0007091127859122, reward: 15.0,12.0)\n",
      "Episode 212100/300000 ( TD_error: 0.6417102674813808, reward: 7.0,-16.0)\n",
      "Episode 212200/300000 ( TD_error: 0.9443888514634908, reward: 0.0,7.0)\n",
      "Episode 212300/300000 ( TD_error: 1.2596705666167396, reward: 2.0,13.0)\n",
      "Episode 212400/300000 ( TD_error: 0.43907415338045963, reward: 10.0,6.0)\n",
      "Episode 212500/300000 ( TD_error: 0.4844360058254118, reward: 15.0,-28.0)\n",
      "Episode 212600/300000 ( TD_error: -1.1263700132920889, reward: -25.0,15.0)\n",
      "Episode 212700/300000 ( TD_error: 0.4205284320274796, reward: 4.0,-10.0)\n",
      "Episode 212800/300000 ( TD_error: 1.6298040432939889, reward: -15.0,3.0)\n",
      "Episode 212900/300000 ( TD_error: -2.3033885645738916, reward: -13.0,14.0)\n",
      "Episode 213000/300000 ( TD_error: -0.6433078453179313, reward: -10.0,-21.0)\n",
      "Episode 213100/300000 ( TD_error: -0.6809594238334737, reward: -10.0,-11.0)\n",
      "Episode 213200/300000 ( TD_error: 0.39231276530499937, reward: 14.0,5.0)\n",
      "Episode 213300/300000 ( TD_error: -0.25809313712417037, reward: -11.0,-10.0)\n",
      "Episode 213400/300000 ( TD_error: 0.26587094795359967, reward: 11.0,-13.0)\n",
      "Episode 213500/300000 ( TD_error: 0.3341646544121537, reward: 6.0,-10.0)\n",
      "Episode 213600/300000 ( TD_error: -9.915869348267947, reward: -10.0,-10.0)\n",
      "Episode 213700/300000 ( TD_error: 1.236936422427719, reward: 12.0,4.0)\n",
      "Episode 213800/300000 ( TD_error: -0.8447670186876017, reward: -13.0,15.0)\n",
      "Episode 213900/300000 ( TD_error: 0.6606966218282881, reward: 5.0,6.0)\n",
      "Episode 214000/300000 ( TD_error: 1.571109426616343, reward: 14.0,-15.0)\n",
      "Episode 214100/300000 ( TD_error: 1.4298891277315442, reward: 14.0,13.0)\n",
      "Episode 214200/300000 ( TD_error: -0.62854661665979, reward: -11.0,-11.0)\n",
      "Episode 214300/300000 ( TD_error: 0.3422334080339464, reward: -11.0,15.0)\n",
      "Episode 214400/300000 ( TD_error: 1.2631018259026998, reward: -15.0,5.0)\n",
      "Episode 214500/300000 ( TD_error: 1.4369097356128573, reward: 4.0,-10.0)\n",
      "Episode 214600/300000 ( TD_error: 1.1425078494068766, reward: -40.0,5.0)\n",
      "Episode 214700/300000 ( TD_error: 0.8353021744133828, reward: 10.0,-27.0)\n",
      "Episode 214800/300000 ( TD_error: 0.5466466635307663, reward: 9.0,-10.0)\n",
      "Episode 214900/300000 ( TD_error: 0.3932811073232867, reward: 9.0,-23.0)\n",
      "Episode 215000/300000 ( TD_error: -2.9406837314949454, reward: -36.0,15.0)\n",
      "Episode 215100/300000 ( TD_error: 1.1641700508672144, reward: 14.0,-15.0)\n",
      "Episode 215200/300000 ( TD_error: 0.856003261754966, reward: 6.0,4.0)\n",
      "Episode 215300/300000 ( TD_error: -0.5623470318645616, reward: -33.0,3.0)\n",
      "Episode 215400/300000 ( TD_error: 1.1086683044349215, reward: 6.0,-20.0)\n",
      "Episode 215500/300000 ( TD_error: -9.92385380092218, reward: -10.0,9.0)\n",
      "Episode 215600/300000 ( TD_error: -9.91774345112457, reward: -10.0,-10.0)\n",
      "Episode 215700/300000 ( TD_error: -0.02257723817978352, reward: -10.0,13.0)\n",
      "Episode 215800/300000 ( TD_error: 1.35518091493564, reward: -6.0,-13.0)\n",
      "Episode 215900/300000 ( TD_error: 0.7704401356423234, reward: 5.0,-29.0)\n",
      "Episode 216000/300000 ( TD_error: 0.9083775419639393, reward: 9.0,5.0)\n",
      "Episode 216100/300000 ( TD_error: 0.5228856360439789, reward: 10.0,13.0)\n",
      "Episode 216200/300000 ( TD_error: -0.027862714356475138, reward: -37.0,11.0)\n",
      "Episode 216300/300000 ( TD_error: -2.0213982506621573, reward: -30.0,4.0)\n",
      "Episode 216400/300000 ( TD_error: 0.41665424996132394, reward: 14.0,10.0)\n",
      "Episode 216500/300000 ( TD_error: 0.46590531241098265, reward: -4.0,-18.0)\n",
      "Episode 216600/300000 ( TD_error: 0.4237859175222751, reward: 5.0,-13.0)\n",
      "Episode 216700/300000 ( TD_error: 0.8710014724259967, reward: -19.0,7.0)\n",
      "Episode 216800/300000 ( TD_error: 0.47069607358517374, reward: 15.0,7.0)\n",
      "Episode 216900/300000 ( TD_error: 0.3990520729591789, reward: 5.0,-10.0)\n",
      "Episode 217000/300000 ( TD_error: -0.39197113980787, reward: -25.0,-18.0)\n",
      "Episode 217100/300000 ( TD_error: 0.28032438341145083, reward: 14.0,14.0)\n",
      "Episode 217200/300000 ( TD_error: -2.4166435369098807, reward: -15.0,3.0)\n",
      "Episode 217300/300000 ( TD_error: 0.2718888807174151, reward: 8.0,11.0)\n",
      "Episode 217400/300000 ( TD_error: -0.14096270237442976, reward: -10.0,12.0)\n",
      "Episode 217500/300000 ( TD_error: 0.21363017782459393, reward: 15.0,15.0)\n",
      "Episode 217600/300000 ( TD_error: -0.20940157733860953, reward: -10.0,6.0)\n",
      "Episode 217700/300000 ( TD_error: 0.24402237833766005, reward: 2.0,11.0)\n",
      "Episode 217800/300000 ( TD_error: -0.19213140093417014, reward: -10.0,-10.0)\n",
      "Episode 217900/300000 ( TD_error: -0.2790819633889692, reward: -10.0,7.0)\n",
      "Episode 218000/300000 ( TD_error: 0.370807141085324, reward: 11.0,-17.0)\n",
      "Episode 218100/300000 ( TD_error: 0.3357802253691857, reward: 13.0,-10.0)\n",
      "Episode 218200/300000 ( TD_error: -0.014769762991004853, reward: -28.0,-17.0)\n",
      "Episode 218300/300000 ( TD_error: 0.2158112271788366, reward: 6.0,11.0)\n",
      "Episode 218400/300000 ( TD_error: -10.28043610773893, reward: -10.0,13.0)\n",
      "Episode 218500/300000 ( TD_error: 0.241340281119653, reward: 7.0,15.0)\n",
      "Episode 218600/300000 ( TD_error: 0.7696854827616821, reward: 8.0,5.0)\n",
      "Episode 218700/300000 ( TD_error: 1.0495584972916117, reward: 15.0,6.0)\n",
      "Episode 218800/300000 ( TD_error: -10.271289488062816, reward: -10.0,-12.0)\n",
      "Episode 218900/300000 ( TD_error: -0.07958683089749918, reward: -17.0,7.0)\n",
      "Episode 219000/300000 ( TD_error: -9.932082939201214, reward: -10.0,13.0)\n",
      "Episode 219100/300000 ( TD_error: -0.28797125043314153, reward: -10.0,14.0)\n",
      "Episode 219200/300000 ( TD_error: 0.5414048688681952, reward: -11.0,2.0)\n",
      "Episode 219300/300000 ( TD_error: -0.550603944326248, reward: -15.0,-10.0)\n",
      "Episode 219400/300000 ( TD_error: 1.0309872489937524, reward: 3.0,14.0)\n",
      "Episode 219500/300000 ( TD_error: -9.92754524196, reward: -10.0,-10.0)\n",
      "Episode 219600/300000 ( TD_error: 0.6377891550236985, reward: 5.0,-10.0)\n",
      "Episode 219700/300000 ( TD_error: 0.4820756272522786, reward: -16.0,5.0)\n",
      "Episode 219800/300000 ( TD_error: 0.43550759793533134, reward: 4.0,8.0)\n",
      "Episode 219900/300000 ( TD_error: -9.924580006653311, reward: -10.0,-10.0)\n",
      "Episode 220000/300000 ( TD_error: 0.3007577429233885, reward: 13.0,5.0)\n",
      "Episode 220100/300000 ( TD_error: 0.4186176822275547, reward: 7.0,7.0)\n",
      "Episode 220200/300000 ( TD_error: 0.3810974860554448, reward: 15.0,-10.0)\n",
      "Episode 220300/300000 ( TD_error: -0.3364952781676598, reward: -10.0,3.0)\n",
      "Episode 220400/300000 ( TD_error: 1.2661887405845451, reward: 15.0,15.0)\n",
      "Episode 220500/300000 ( TD_error: -0.3599266693020571, reward: -10.0,12.0)\n",
      "Episode 220600/300000 ( TD_error: -0.9739676112567732, reward: -12.0,14.0)\n",
      "Episode 220700/300000 ( TD_error: 1.2576729228614734, reward: 15.0,-10.0)\n",
      "Episode 220800/300000 ( TD_error: 0.25361418511774403, reward: 9.0,15.0)\n",
      "Episode 220900/300000 ( TD_error: 0.33429848136669715, reward: -1.0,11.0)\n",
      "Episode 221000/300000 ( TD_error: -10.23849027365377, reward: -10.0,9.0)\n",
      "Episode 221100/300000 ( TD_error: 0.4539523884508423, reward: 13.0,-10.0)\n",
      "Episode 221200/300000 ( TD_error: 0.4244116520821537, reward: 9.0,3.0)\n",
      "Episode 221300/300000 ( TD_error: 0.959332434308168, reward: -64.0,4.0)\n",
      "Episode 221400/300000 ( TD_error: 0.19627147784385413, reward: -1.0,-13.0)\n",
      "Episode 221500/300000 ( TD_error: 0.6913292987198845, reward: 12.0,14.0)\n",
      "Episode 221600/300000 ( TD_error: 1.2005185807370005, reward: 14.0,7.0)\n",
      "Episode 221700/300000 ( TD_error: 1.0594286063636393, reward: 13.0,6.0)\n",
      "Episode 221800/300000 ( TD_error: 0.6569868215938719, reward: 8.0,-10.0)\n",
      "Episode 221900/300000 ( TD_error: 1.22901876490217, reward: 14.0,5.0)\n",
      "Episode 222000/300000 ( TD_error: 1.3658864912290714, reward: 15.0,-10.0)\n",
      "Episode 222100/300000 ( TD_error: 0.8396892135219489, reward: -6.0,8.0)\n",
      "Episode 222200/300000 ( TD_error: -0.5980886473075806, reward: -10.0,3.0)\n",
      "Episode 222300/300000 ( TD_error: 0.8030260766659536, reward: 8.0,13.0)\n",
      "Episode 222400/300000 ( TD_error: 0.775328468433675, reward: 6.0,-21.0)\n",
      "Episode 222500/300000 ( TD_error: 0.9095121849865215, reward: 5.0,7.0)\n",
      "Episode 222600/300000 ( TD_error: 0.7677246656600221, reward: -4.0,-10.0)\n",
      "Episode 222700/300000 ( TD_error: -0.8080498980550672, reward: -55.0,13.0)\n",
      "Episode 222800/300000 ( TD_error: -3.6082203830482023, reward: -22.0,15.0)\n",
      "Episode 222900/300000 ( TD_error: 0.4141242010773194, reward: -19.0,-10.0)\n",
      "Episode 223000/300000 ( TD_error: 0.7216561670878274, reward: 5.0,10.0)\n",
      "Episode 223100/300000 ( TD_error: 0.4483385992670068, reward: 7.0,15.0)\n",
      "Episode 223200/300000 ( TD_error: -0.356540657024091, reward: -12.0,15.0)\n",
      "Episode 223300/300000 ( TD_error: 0.3866048218998559, reward: 3.0,-10.0)\n",
      "Episode 223400/300000 ( TD_error: 0.5378764454105145, reward: -11.0,-10.0)\n",
      "Episode 223500/300000 ( TD_error: 0.2892976544555168, reward: -4.0,-14.0)\n",
      "Episode 223600/300000 ( TD_error: 0.31177901795184404, reward: 6.0,13.0)\n",
      "Episode 223700/300000 ( TD_error: 0.31108493075778165, reward: 3.0,15.0)\n",
      "Episode 223800/300000 ( TD_error: 0.6404652861988414, reward: -14.0,8.0)\n",
      "Episode 223900/300000 ( TD_error: 0.5011181145459549, reward: -12.0,10.0)\n",
      "Episode 224000/300000 ( TD_error: 1.3116038883312995, reward: 15.0,8.0)\n",
      "Episode 224100/300000 ( TD_error: 0.3487411821529651, reward: 9.0,11.0)\n",
      "Episode 224200/300000 ( TD_error: -9.875475270909632, reward: -10.0,-10.0)\n",
      "Episode 224300/300000 ( TD_error: -1.0204798607142855, reward: -18.0,-10.0)\n",
      "Episode 224400/300000 ( TD_error: -0.005845347563333547, reward: -19.0,-10.0)\n",
      "Episode 224500/300000 ( TD_error: 0.3502563974956501, reward: 9.0,14.0)\n",
      "Episode 224600/300000 ( TD_error: -1.9127845800993137, reward: -19.0,1.0)\n",
      "Episode 224700/300000 ( TD_error: 0.6455952919157042, reward: -10.0,-11.0)\n",
      "Episode 224800/300000 ( TD_error: 0.21692389155617375, reward: 6.0,-11.0)\n",
      "Episode 224900/300000 ( TD_error: 0.20373195013162881, reward: 9.0,-11.0)\n",
      "Episode 225000/300000 ( TD_error: 0.20851871743898398, reward: 3.0,13.0)\n",
      "Episode 225100/300000 ( TD_error: 0.28893958640122674, reward: 3.0,-41.0)\n",
      "Episode 225200/300000 ( TD_error: -9.862548394061987, reward: -10.0,6.0)\n",
      "Episode 225300/300000 ( TD_error: 0.22231329969303149, reward: 13.0,-14.0)\n",
      "Episode 225400/300000 ( TD_error: -10.218846776311567, reward: -10.0,7.0)\n",
      "Episode 225500/300000 ( TD_error: 0.29986070799954145, reward: 2.0,15.0)\n",
      "Episode 225600/300000 ( TD_error: 0.44879931798346107, reward: 7.0,-17.0)\n",
      "Episode 225700/300000 ( TD_error: 0.8393572640595428, reward: 13.0,15.0)\n",
      "Episode 225800/300000 ( TD_error: 1.2607558444558569, reward: 14.0,14.0)\n",
      "Episode 225900/300000 ( TD_error: 0.384047644817624, reward: -10.0,-10.0)\n",
      "Episode 226000/300000 ( TD_error: -9.863286452184392, reward: -10.0,-12.0)\n",
      "Episode 226100/300000 ( TD_error: 0.48662733248084056, reward: 3.0,-14.0)\n",
      "Episode 226200/300000 ( TD_error: 0.444304275023768, reward: 1.0,-10.0)\n",
      "Episode 226300/300000 ( TD_error: 0.38046160271514395, reward: 13.0,-16.0)\n",
      "Episode 226400/300000 ( TD_error: -0.9952314919149821, reward: -14.0,-10.0)\n",
      "Episode 226500/300000 ( TD_error: 0.23836705539428582, reward: 8.0,13.0)\n",
      "Episode 226600/300000 ( TD_error: 0.28761410685209876, reward: 14.0,13.0)\n",
      "Episode 226700/300000 ( TD_error: -9.864183028709897, reward: -10.0,4.0)\n",
      "Episode 226800/300000 ( TD_error: -9.864917197281471, reward: -10.0,15.0)\n",
      "Episode 226900/300000 ( TD_error: 0.20732119883148936, reward: 10.0,15.0)\n",
      "Episode 227000/300000 ( TD_error: 0.22014845037412112, reward: 11.0,-10.0)\n",
      "Episode 227100/300000 ( TD_error: 0.26916946051079416, reward: 10.0,2.0)\n",
      "Episode 227200/300000 ( TD_error: 0.4780912092772822, reward: 13.0,0.0)\n",
      "Episode 227300/300000 ( TD_error: 0.3948968852650516, reward: 7.0,-26.0)\n",
      "Episode 227400/300000 ( TD_error: 0.2882855905420558, reward: 3.0,10.0)\n",
      "Episode 227500/300000 ( TD_error: 0.2936361944510968, reward: 3.0,5.0)\n",
      "Episode 227600/300000 ( TD_error: -0.5373474357701848, reward: -67.0,14.0)\n",
      "Episode 227700/300000 ( TD_error: 0.297357051776697, reward: 13.0,-10.0)\n",
      "Episode 227800/300000 ( TD_error: 0.22011341526811234, reward: 5.0,-23.0)\n",
      "Episode 227900/300000 ( TD_error: 0.27868518910231455, reward: 6.0,-17.0)\n",
      "Episode 228000/300000 ( TD_error: -10.196340658652439, reward: -10.0,-11.0)\n",
      "Episode 228100/300000 ( TD_error: 4.371501981377403, reward: -10.0,12.0)\n",
      "Episode 228200/300000 ( TD_error: -0.20403758561554497, reward: -13.0,15.0)\n",
      "Episode 228300/300000 ( TD_error: 2.0686508260901935, reward: 15.0,-19.0)\n",
      "Episode 228400/300000 ( TD_error: 0.22926624532242856, reward: 4.0,-11.0)\n",
      "Episode 228500/300000 ( TD_error: 0.21819929875944855, reward: 11.0,-10.0)\n",
      "Episode 228600/300000 ( TD_error: 5.053254994118641, reward: -10.0,5.0)\n",
      "Episode 228700/300000 ( TD_error: 0.4060061045772163, reward: 1.0,-10.0)\n",
      "Episode 228800/300000 ( TD_error: 0.8420612638822509, reward: 14.0,5.0)\n",
      "Episode 228900/300000 ( TD_error: 0.5459160688709424, reward: 12.0,-21.0)\n",
      "Episode 229000/300000 ( TD_error: -1.0717401095350407, reward: -13.0,-26.0)\n",
      "Episode 229100/300000 ( TD_error: 0.39919335499629804, reward: 15.0,-16.0)\n",
      "Episode 229200/300000 ( TD_error: 0.3415895079693252, reward: 13.0,12.0)\n",
      "Episode 229300/300000 ( TD_error: 1.366191886445879, reward: 15.0,-10.0)\n",
      "Episode 229400/300000 ( TD_error: -0.49566788052577415, reward: -11.0,-20.0)\n",
      "Episode 229500/300000 ( TD_error: 0.3093197505403191, reward: 15.0,2.0)\n",
      "Episode 229600/300000 ( TD_error: -0.10965997776529157, reward: -17.0,11.0)\n",
      "Episode 229700/300000 ( TD_error: -9.841706735504825, reward: -10.0,-13.0)\n",
      "Episode 229800/300000 ( TD_error: -0.5761593464869321, reward: -12.0,8.0)\n",
      "Episode 229900/300000 ( TD_error: 0.33875230190422023, reward: 10.0,7.0)\n",
      "Episode 230000/300000 ( TD_error: -3.7977941473296886, reward: -14.0,15.0)\n",
      "Episode 230100/300000 ( TD_error: 0.7689235696612577, reward: 15.0,15.0)\n",
      "Episode 230200/300000 ( TD_error: -0.17000325494918123, reward: -21.0,4.0)\n",
      "Episode 230300/300000 ( TD_error: -0.7273378815751776, reward: -20.0,3.0)\n",
      "Episode 230400/300000 ( TD_error: 0.8179740823222126, reward: 15.0,-16.0)\n",
      "Episode 230500/300000 ( TD_error: 0.6865380432255748, reward: 14.0,13.0)\n",
      "Episode 230600/300000 ( TD_error: -9.843743566545458, reward: -10.0,6.0)\n",
      "Episode 230700/300000 ( TD_error: 0.9430081658998057, reward: 10.0,-95.0)\n",
      "Episode 230800/300000 ( TD_error: 0.4135323334385763, reward: -1.0,-10.0)\n",
      "Episode 230900/300000 ( TD_error: 0.737938952896493, reward: 5.0,1.0)\n",
      "Episode 231000/300000 ( TD_error: 0.4326940122548084, reward: 5.0,6.0)\n",
      "Episode 231100/300000 ( TD_error: 0.663081931723398, reward: 15.0,15.0)\n",
      "Episode 231200/300000 ( TD_error: 0.3021104239995216, reward: 3.0,13.0)\n",
      "Episode 231300/300000 ( TD_error: -10.19475937131746, reward: -10.0,15.0)\n",
      "Episode 231400/300000 ( TD_error: -1.209816148274749, reward: -22.0,8.0)\n",
      "Episode 231500/300000 ( TD_error: 0.36146335533223883, reward: 4.0,6.0)\n",
      "Episode 231600/300000 ( TD_error: -0.0794363955226558, reward: -16.0,12.0)\n",
      "Episode 231700/300000 ( TD_error: 0.2664872296873999, reward: 13.0,5.0)\n",
      "Episode 231800/300000 ( TD_error: 1.96920767195132, reward: 15.0,12.0)\n",
      "Episode 231900/300000 ( TD_error: -3.3564648028968893, reward: -20.0,13.0)\n",
      "Episode 232000/300000 ( TD_error: 0.3678204835028698, reward: 15.0,-10.0)\n",
      "Episode 232100/300000 ( TD_error: 0.18379458242534596, reward: 3.0,15.0)\n",
      "Episode 232200/300000 ( TD_error: 0.7582967106925018, reward: -18.0,-13.0)\n",
      "Episode 232300/300000 ( TD_error: 0.24944498536117532, reward: 8.0,13.0)\n",
      "Episode 232400/300000 ( TD_error: 0.297010982607925, reward: -12.0,4.0)\n",
      "Episode 232500/300000 ( TD_error: 0.2602321532349112, reward: 13.0,8.0)\n",
      "Episode 232600/300000 ( TD_error: 2.3410251845590384, reward: 15.0,-48.0)\n",
      "Episode 232700/300000 ( TD_error: 0.2237726427207214, reward: 4.0,8.0)\n",
      "Episode 232800/300000 ( TD_error: -0.1251625040697757, reward: -10.0,-10.0)\n",
      "Episode 232900/300000 ( TD_error: 0.2155385143059858, reward: 13.0,6.0)\n",
      "Episode 233000/300000 ( TD_error: 0.25579970058972235, reward: 14.0,15.0)\n",
      "Episode 233100/300000 ( TD_error: 0.22462597895887626, reward: 3.0,12.0)\n",
      "Episode 233200/300000 ( TD_error: 0.5816425991842094, reward: 11.0,-15.0)\n",
      "Episode 233300/300000 ( TD_error: 0.5282108964679795, reward: 8.0,-107.0)\n",
      "Episode 233400/300000 ( TD_error: 0.85638459088038, reward: 14.0,-14.0)\n",
      "Episode 233500/300000 ( TD_error: 1.2363591673452174, reward: 14.0,10.0)\n",
      "Episode 233600/300000 ( TD_error: 0.9758675199334976, reward: 11.0,2.0)\n",
      "Episode 233700/300000 ( TD_error: -10.231379871015905, reward: -10.0,9.0)\n",
      "Episode 233800/300000 ( TD_error: 0.8603008004260424, reward: 14.0,9.0)\n",
      "Episode 233900/300000 ( TD_error: 1.0048057300157769, reward: -10.0,-10.0)\n",
      "Episode 234000/300000 ( TD_error: 0.39201802943803576, reward: 10.0,-10.0)\n",
      "Episode 234100/300000 ( TD_error: 0.3590149985875879, reward: -1.0,15.0)\n",
      "Episode 234200/300000 ( TD_error: -10.198453444645333, reward: -10.0,-19.0)\n",
      "Episode 234300/300000 ( TD_error: -0.6404068308276134, reward: -12.0,-21.0)\n",
      "Episode 234400/300000 ( TD_error: 0.3345092837445871, reward: 13.0,9.0)\n",
      "Episode 234500/300000 ( TD_error: 0.26139660088796557, reward: 14.0,8.0)\n",
      "Episode 234600/300000 ( TD_error: 0.39957626214571107, reward: -14.0,6.0)\n",
      "Episode 234700/300000 ( TD_error: 1.0420335474410392, reward: 8.0,-12.0)\n",
      "Episode 234800/300000 ( TD_error: 0.7657405221313933, reward: 11.0,11.0)\n",
      "Episode 234900/300000 ( TD_error: -0.6257139897196673, reward: -13.0,13.0)\n",
      "Episode 235000/300000 ( TD_error: 0.8552662406682732, reward: -17.0,-16.0)\n",
      "Episode 235100/300000 ( TD_error: 0.3003884990024468, reward: 13.0,15.0)\n",
      "Episode 235200/300000 ( TD_error: 0.4715416335074609, reward: 3.0,11.0)\n",
      "Episode 235300/300000 ( TD_error: 0.04194310651120148, reward: -11.0,4.0)\n",
      "Episode 235400/300000 ( TD_error: 0.2954504703177325, reward: 8.0,-17.0)\n",
      "Episode 235500/300000 ( TD_error: 0.31799449293036597, reward: 6.0,1.0)\n",
      "Episode 235600/300000 ( TD_error: -3.1967985260731435, reward: -12.0,-12.0)\n",
      "Episode 235700/300000 ( TD_error: -0.4329895169022038, reward: -10.0,15.0)\n",
      "Episode 235800/300000 ( TD_error: 0.844767170829575, reward: 15.0,7.0)\n",
      "Episode 235900/300000 ( TD_error: 1.164871613125574, reward: 10.0,8.0)\n",
      "Episode 236000/300000 ( TD_error: 1.0932163787640645, reward: 14.0,15.0)\n",
      "Episode 236100/300000 ( TD_error: 1.1999644706774237, reward: 6.0,12.0)\n",
      "Episode 236200/300000 ( TD_error: 1.23874295146032, reward: 8.0,-10.0)\n",
      "Episode 236300/300000 ( TD_error: 1.2591729999927739, reward: 10.0,-10.0)\n",
      "Episode 236400/300000 ( TD_error: -9.829936571420296, reward: -10.0,6.0)\n",
      "Episode 236500/300000 ( TD_error: 1.1177996008606272, reward: 14.0,11.0)\n",
      "Episode 236600/300000 ( TD_error: -1.0122349554198813, reward: -11.0,14.0)\n",
      "Episode 236700/300000 ( TD_error: 1.7426130693022714, reward: 14.0,-10.0)\n",
      "Episode 236800/300000 ( TD_error: -0.18110910710391792, reward: -10.0,-19.0)\n",
      "Episode 236900/300000 ( TD_error: 1.3750634173109542, reward: 14.0,-11.0)\n",
      "Episode 237000/300000 ( TD_error: 1.1312832896088558, reward: -2.0,11.0)\n",
      "Episode 237100/300000 ( TD_error: 1.1498479548987293, reward: 14.0,12.0)\n",
      "Episode 237200/300000 ( TD_error: 0.8047428270700756, reward: 8.0,12.0)\n",
      "Episode 237300/300000 ( TD_error: 0.6487079796224702, reward: -11.0,6.0)\n",
      "Episode 237400/300000 ( TD_error: -0.5443580323636397, reward: -13.0,-17.0)\n",
      "Episode 237500/300000 ( TD_error: 1.0119200531063592, reward: 9.0,-10.0)\n",
      "Episode 237600/300000 ( TD_error: 1.0623132189745221, reward: 5.0,-10.0)\n",
      "Episode 237700/300000 ( TD_error: 0.491423847385414, reward: 13.0,10.0)\n",
      "Episode 237800/300000 ( TD_error: 1.4355230861749817, reward: 11.0,13.0)\n",
      "Episode 237900/300000 ( TD_error: 1.0077992119805756, reward: 8.0,12.0)\n",
      "Episode 238000/300000 ( TD_error: 1.1787991351480542, reward: -15.0,-15.0)\n",
      "Episode 238100/300000 ( TD_error: -0.1094771919861035, reward: -10.0,7.0)\n",
      "Episode 238200/300000 ( TD_error: -0.7939932411751798, reward: -11.0,-10.0)\n",
      "Episode 238300/300000 ( TD_error: 0.6296554571595325, reward: 15.0,-10.0)\n",
      "Episode 238400/300000 ( TD_error: 1.550088576634164, reward: 5.0,-10.0)\n",
      "Episode 238500/300000 ( TD_error: -9.814818912624151, reward: -10.0,15.0)\n",
      "Episode 238600/300000 ( TD_error: 1.4046561343032842, reward: 3.0,-17.0)\n",
      "Episode 238700/300000 ( TD_error: -2.438524185901599, reward: -11.0,11.0)\n",
      "Episode 238800/300000 ( TD_error: 0.6498001159036559, reward: 7.0,0.0)\n",
      "Episode 238900/300000 ( TD_error: -10.238807622785519, reward: -10.0,15.0)\n",
      "Episode 239000/300000 ( TD_error: 0.5795368576292295, reward: 15.0,10.0)\n",
      "Episode 239100/300000 ( TD_error: 1.3641066577127416, reward: 14.0,-12.0)\n",
      "Episode 239200/300000 ( TD_error: 0.18146989595269236, reward: -11.0,15.0)\n",
      "Episode 239300/300000 ( TD_error: -0.763898378222418, reward: -40.0,14.0)\n",
      "Episode 239400/300000 ( TD_error: 0.7074869576347216, reward: 4.0,7.0)\n",
      "Episode 239500/300000 ( TD_error: 5.752281189382469, reward: -10.0,5.0)\n",
      "Episode 239600/300000 ( TD_error: -1.1702943935948547, reward: -18.0,6.0)\n",
      "Episode 239700/300000 ( TD_error: 1.0567364623439186, reward: 15.0,8.0)\n",
      "Episode 239800/300000 ( TD_error: 0.9659478321094825, reward: 13.0,7.0)\n",
      "Episode 239900/300000 ( TD_error: 1.017581223740219, reward: -13.0,8.0)\n",
      "Episode 240000/300000 ( TD_error: 0.09271186821376887, reward: -32.0,-13.0)\n",
      "Episode 240100/300000 ( TD_error: 0.4482300547002245, reward: 13.0,15.0)\n",
      "Episode 240200/300000 ( TD_error: -10.26276843211587, reward: -10.0,-28.0)\n",
      "Episode 240300/300000 ( TD_error: -0.008787696809505974, reward: -27.0,15.0)\n",
      "Episode 240400/300000 ( TD_error: 0.4744899798860427, reward: 8.0,14.0)\n",
      "Episode 240500/300000 ( TD_error: 0.4623225215764406, reward: 6.0,-10.0)\n",
      "Episode 240600/300000 ( TD_error: 0.4090799708376651, reward: 10.0,-14.0)\n",
      "Episode 240700/300000 ( TD_error: 0.3067083632744847, reward: 6.0,4.0)\n",
      "Episode 240800/300000 ( TD_error: 0.39379559002144315, reward: 5.0,-17.0)\n",
      "Episode 240900/300000 ( TD_error: -9.833127158557504, reward: -10.0,2.0)\n",
      "Episode 241000/300000 ( TD_error: 4.602534849325799, reward: -10.0,-8.0)\n",
      "Episode 241100/300000 ( TD_error: 0.5280252981173028, reward: 13.0,-10.0)\n",
      "Episode 241200/300000 ( TD_error: 0.38478582442903564, reward: 13.0,-14.0)\n",
      "Episode 241300/300000 ( TD_error: 0.3838694116799526, reward: 7.0,3.0)\n",
      "Episode 241400/300000 ( TD_error: 0.22019416485518928, reward: 3.0,13.0)\n",
      "Episode 241500/300000 ( TD_error: -2.1026322166093125, reward: -20.0,15.0)\n",
      "Episode 241600/300000 ( TD_error: 0.33544939383017347, reward: -3.0,-10.0)\n",
      "Episode 241700/300000 ( TD_error: -0.6014588306974744, reward: -14.0,-20.0)\n",
      "Episode 241800/300000 ( TD_error: -9.827360703905587, reward: -10.0,15.0)\n",
      "Episode 241900/300000 ( TD_error: -0.8138192949750813, reward: -14.0,-22.0)\n",
      "Episode 242000/300000 ( TD_error: 2.7493034049903304, reward: -10.0,-10.0)\n",
      "Episode 242100/300000 ( TD_error: 0.7060210743522304, reward: 8.0,-20.0)\n",
      "Episode 242200/300000 ( TD_error: 0.5613497814736483, reward: -11.0,-30.0)\n",
      "Episode 242300/300000 ( TD_error: 0.3816451306276898, reward: 8.0,-31.0)\n",
      "Episode 242400/300000 ( TD_error: 0.2698854355996243, reward: -12.0,1.0)\n",
      "Episode 242500/300000 ( TD_error: -0.6748250479861753, reward: -24.0,-21.0)\n",
      "Episode 242600/300000 ( TD_error: 0.3523724073848915, reward: 7.0,-11.0)\n",
      "Episode 242700/300000 ( TD_error: 0.3634150549938955, reward: 12.0,13.0)\n",
      "Episode 242800/300000 ( TD_error: 0.2943697229316844, reward: 15.0,5.0)\n",
      "Episode 242900/300000 ( TD_error: -0.5160068546093619, reward: -11.0,-4.0)\n",
      "Episode 243000/300000 ( TD_error: 0.9212162971147091, reward: -13.0,13.0)\n",
      "Episode 243100/300000 ( TD_error: 0.5923964578306422, reward: 6.0,-15.0)\n",
      "Episode 243200/300000 ( TD_error: 0.647725974702217, reward: -15.0,13.0)\n",
      "Episode 243300/300000 ( TD_error: 0.4115408628244013, reward: 6.0,-10.0)\n",
      "Episode 243400/300000 ( TD_error: -10.184258124470304, reward: -10.0,7.0)\n",
      "Episode 243500/300000 ( TD_error: 0.21858166600194462, reward: 8.0,15.0)\n",
      "Episode 243600/300000 ( TD_error: 0.7285132887027665, reward: 13.0,-49.0)\n",
      "Episode 243700/300000 ( TD_error: 1.1743843418294198, reward: 13.0,-47.0)\n",
      "Episode 243800/300000 ( TD_error: 0.38468987515749165, reward: -21.0,-10.0)\n",
      "Episode 243900/300000 ( TD_error: -0.06907477952923813, reward: -19.0,6.0)\n",
      "Episode 244000/300000 ( TD_error: 0.3217183209466672, reward: 12.0,3.0)\n",
      "Episode 244100/300000 ( TD_error: -2.684297349786677, reward: -17.0,-10.0)\n",
      "Episode 244200/300000 ( TD_error: 0.22366890493216873, reward: 10.0,5.0)\n",
      "Episode 244300/300000 ( TD_error: 1.03822282099045, reward: -92.0,5.0)\n",
      "Episode 244400/300000 ( TD_error: 0.3342124147668608, reward: 12.0,-10.0)\n",
      "Episode 244500/300000 ( TD_error: 0.3744090943468086, reward: 12.0,-13.0)\n",
      "Episode 244600/300000 ( TD_error: 0.36926566561732255, reward: 15.0,-13.0)\n",
      "Episode 244700/300000 ( TD_error: 0.6012027175978254, reward: 5.0,5.0)\n",
      "Episode 244800/300000 ( TD_error: 0.05157092129996599, reward: -16.0,10.0)\n",
      "Episode 244900/300000 ( TD_error: 2.2323031890969274, reward: 15.0,8.0)\n",
      "Episode 245000/300000 ( TD_error: 1.1038030177029667, reward: 9.0,12.0)\n",
      "Episode 245100/300000 ( TD_error: 0.8647938211005841, reward: 1.0,-10.0)\n",
      "Episode 245200/300000 ( TD_error: 1.1762294124148287, reward: -23.0,-21.0)\n",
      "Episode 245300/300000 ( TD_error: 0.4211537209433547, reward: 6.0,6.0)\n",
      "Episode 245400/300000 ( TD_error: -10.173167216919161, reward: -10.0,4.0)\n",
      "Episode 245500/300000 ( TD_error: -2.128193006024131, reward: -12.0,7.0)\n",
      "Episode 245600/300000 ( TD_error: -1.0687479201473025, reward: -14.0,7.0)\n",
      "Episode 245700/300000 ( TD_error: 1.9475842721626813, reward: 15.0,-10.0)\n",
      "Episode 245800/300000 ( TD_error: 0.21467566491990997, reward: 3.0,-10.0)\n",
      "Episode 245900/300000 ( TD_error: 0.25950317289039626, reward: -44.0,14.0)\n",
      "Episode 246000/300000 ( TD_error: 1.0506031320246878, reward: 11.0,12.0)\n",
      "Episode 246100/300000 ( TD_error: -0.05201075684688128, reward: -10.0,-10.0)\n",
      "Episode 246200/300000 ( TD_error: 0.5084807273293621, reward: 12.0,12.0)\n",
      "Episode 246300/300000 ( TD_error: 0.3511697128793312, reward: 7.0,14.0)\n",
      "Episode 246400/300000 ( TD_error: 0.3301343425171068, reward: 9.0,8.0)\n",
      "Episode 246500/300000 ( TD_error: 0.25736651668155996, reward: 7.0,5.0)\n",
      "Episode 246600/300000 ( TD_error: 0.2156730851123645, reward: 15.0,11.0)\n",
      "Episode 246700/300000 ( TD_error: 0.35544674209662963, reward: 1.0,4.0)\n",
      "Episode 246800/300000 ( TD_error: 0.2615529612086829, reward: 6.0,6.0)\n",
      "Episode 246900/300000 ( TD_error: 0.2195398123406851, reward: 7.0,7.0)\n",
      "Episode 247000/300000 ( TD_error: -2.0105896066017195, reward: -10.0,-10.0)\n",
      "Episode 247100/300000 ( TD_error: 0.4492926897338245, reward: 13.0,15.0)\n",
      "Episode 247200/300000 ( TD_error: 0.984144195999276, reward: 11.0,8.0)\n",
      "Episode 247300/300000 ( TD_error: -1.0251920286369174, reward: -16.0,-10.0)\n",
      "Episode 247400/300000 ( TD_error: 0.8355756970407162, reward: 14.0,11.0)\n",
      "Episode 247500/300000 ( TD_error: 4.741435392844593, reward: -10.0,-25.0)\n",
      "Episode 247600/300000 ( TD_error: 0.7391897918122354, reward: 5.0,9.0)\n",
      "Episode 247700/300000 ( TD_error: -0.5339263367590359, reward: -29.0,7.0)\n",
      "Episode 247800/300000 ( TD_error: -0.6156006170496084, reward: -12.0,15.0)\n",
      "Episode 247900/300000 ( TD_error: -9.816990603698324, reward: -10.0,-10.0)\n",
      "Episode 248000/300000 ( TD_error: 0.4409553564178532, reward: 3.0,15.0)\n",
      "Episode 248100/300000 ( TD_error: 0.27968472859624516, reward: 12.0,11.0)\n",
      "Episode 248200/300000 ( TD_error: -0.45790934130119076, reward: -10.0,-10.0)\n",
      "Episode 248300/300000 ( TD_error: 0.46903379716056515, reward: -9.0,-14.0)\n",
      "Episode 248400/300000 ( TD_error: -1.1394872049241567, reward: -13.0,6.0)\n",
      "Episode 248500/300000 ( TD_error: 0.3467102774878228, reward: 4.0,-17.0)\n",
      "Episode 248600/300000 ( TD_error: 0.6500576256510122, reward: -11.0,5.0)\n",
      "Episode 248700/300000 ( TD_error: -0.29931411845972455, reward: -19.0,-16.0)\n",
      "Episode 248800/300000 ( TD_error: 1.8040175151996491, reward: 6.0,14.0)\n",
      "Episode 248900/300000 ( TD_error: -1.9159093650465788, reward: -14.0,8.0)\n",
      "Episode 249000/300000 ( TD_error: -0.1543859169115933, reward: -13.0,15.0)\n",
      "Episode 249100/300000 ( TD_error: 0.4420548811146112, reward: 11.0,10.0)\n",
      "Episode 249200/300000 ( TD_error: 0.3815429156178274, reward: 14.0,-19.0)\n",
      "Episode 249300/300000 ( TD_error: 0.38973782341423213, reward: 8.0,12.0)\n",
      "Episode 249400/300000 ( TD_error: -9.818779063225167, reward: -10.0,10.0)\n",
      "Episode 249500/300000 ( TD_error: -0.5276380172936435, reward: -14.0,15.0)\n",
      "Episode 249600/300000 ( TD_error: 0.44933645333781946, reward: 2.0,-13.0)\n",
      "Episode 249700/300000 ( TD_error: 0.6682109370349396, reward: 11.0,-11.0)\n",
      "Episode 249800/300000 ( TD_error: -0.2766079467842655, reward: -20.0,-10.0)\n",
      "Episode 249900/300000 ( TD_error: 0.7410022986713476, reward: 15.0,-10.0)\n",
      "Episode 250000/300000 ( TD_error: 0.5230934449113613, reward: 7.0,5.0)\n",
      "Episode 250100/300000 ( TD_error: 0.7651821148694062, reward: 15.0,15.0)\n",
      "Episode 250200/300000 ( TD_error: 0.27342470703077026, reward: 10.0,-31.0)\n",
      "Episode 250300/300000 ( TD_error: -0.09816487806792118, reward: -11.0,-10.0)\n",
      "Episode 250400/300000 ( TD_error: 0.2901994094195999, reward: 13.0,-10.0)\n",
      "Episode 250500/300000 ( TD_error: -0.9696155982298755, reward: -28.0,-11.0)\n",
      "Episode 250600/300000 ( TD_error: 0.5995744851690898, reward: 8.0,-18.0)\n",
      "Episode 250700/300000 ( TD_error: -10.171132721157715, reward: -10.0,14.0)\n",
      "Episode 250800/300000 ( TD_error: -9.812584168474972, reward: -10.0,11.0)\n",
      "Episode 250900/300000 ( TD_error: 0.7930626605082796, reward: 15.0,14.0)\n",
      "Episode 251000/300000 ( TD_error: -1.1244562526752517, reward: -20.0,-13.0)\n",
      "Episode 251100/300000 ( TD_error: -0.05541633752165254, reward: -10.0,-44.0)\n",
      "Episode 251200/300000 ( TD_error: 0.6606497463957357, reward: 10.0,7.0)\n",
      "Episode 251300/300000 ( TD_error: 1.4262682156554631, reward: 3.0,15.0)\n",
      "Episode 251400/300000 ( TD_error: -0.75095218859955, reward: -12.0,8.0)\n",
      "Episode 251500/300000 ( TD_error: 0.5062787844061849, reward: 13.0,1.0)\n",
      "Episode 251600/300000 ( TD_error: 0.899773082012838, reward: 14.0,4.0)\n",
      "Episode 251700/300000 ( TD_error: 1.2706309851319297, reward: 12.0,-15.0)\n",
      "Episode 251800/300000 ( TD_error: 0.79201146137054, reward: 7.0,-10.0)\n",
      "Episode 251900/300000 ( TD_error: 0.6935472467661543, reward: 5.0,13.0)\n",
      "Episode 252000/300000 ( TD_error: -9.813876108743568, reward: -10.0,2.0)\n",
      "Episode 252100/300000 ( TD_error: 0.8339212817162993, reward: -2.0,3.0)\n",
      "Episode 252200/300000 ( TD_error: -0.8282101505504542, reward: -11.0,12.0)\n",
      "Episode 252300/300000 ( TD_error: 0.3799690864101972, reward: 8.0,7.0)\n",
      "Episode 252400/300000 ( TD_error: 1.594950989672908, reward: -57.0,-12.0)\n",
      "Episode 252500/300000 ( TD_error: 0.382347803606609, reward: 4.0,4.0)\n",
      "Episode 252600/300000 ( TD_error: 0.25813571105027533, reward: 8.0,15.0)\n",
      "Episode 252700/300000 ( TD_error: -0.48571371172951316, reward: -12.0,-12.0)\n",
      "Episode 252800/300000 ( TD_error: 1.4041277862670434, reward: -10.0,2.0)\n",
      "Episode 252900/300000 ( TD_error: 0.2423599892865962, reward: 7.0,11.0)\n",
      "Episode 253000/300000 ( TD_error: 0.27646534129608735, reward: 3.0,-43.0)\n",
      "Episode 253100/300000 ( TD_error: 0.11931309622652186, reward: -10.0,-10.0)\n",
      "Episode 253200/300000 ( TD_error: -0.41644243917383506, reward: -17.0,12.0)\n",
      "Episode 253300/300000 ( TD_error: 0.4307695490637924, reward: 6.0,14.0)\n",
      "Episode 253400/300000 ( TD_error: 0.5153886590911632, reward: 12.0,-10.0)\n",
      "Episode 253500/300000 ( TD_error: 0.3166143624903084, reward: 10.0,13.0)\n",
      "Episode 253600/300000 ( TD_error: 0.11162070077342356, reward: -10.0,-10.0)\n",
      "Episode 253700/300000 ( TD_error: -0.9876614257810417, reward: -14.0,6.0)\n",
      "Episode 253800/300000 ( TD_error: -2.8294683222812687, reward: -12.0,-15.0)\n",
      "Episode 253900/300000 ( TD_error: -0.4292361373427518, reward: -12.0,3.0)\n",
      "Episode 254000/300000 ( TD_error: 1.5074306936810236, reward: 12.0,15.0)\n",
      "Episode 254100/300000 ( TD_error: -9.821696841420646, reward: -10.0,8.0)\n",
      "Episode 254200/300000 ( TD_error: 0.6688226766498504, reward: 12.0,8.0)\n",
      "Episode 254300/300000 ( TD_error: 1.2988032244535543, reward: 7.0,3.0)\n",
      "Episode 254400/300000 ( TD_error: 1.6188746025425294, reward: 15.0,-10.0)\n",
      "Episode 254500/300000 ( TD_error: 0.8404275462612816, reward: 14.0,5.0)\n",
      "Episode 254600/300000 ( TD_error: 0.5265589511576909, reward: -17.0,-16.0)\n",
      "Episode 254700/300000 ( TD_error: -9.811480978050383, reward: -10.0,-10.0)\n",
      "Episode 254800/300000 ( TD_error: 0.4377743396876457, reward: -3.0,-10.0)\n",
      "Episode 254900/300000 ( TD_error: 0.2811709188114886, reward: 12.0,13.0)\n",
      "Episode 255000/300000 ( TD_error: -0.8500164406215394, reward: -14.0,9.0)\n",
      "Episode 255100/300000 ( TD_error: -2.2126864880941755, reward: -13.0,15.0)\n",
      "Episode 255200/300000 ( TD_error: -9.812596078932932, reward: -10.0,-10.0)\n",
      "Episode 255300/300000 ( TD_error: 0.14381548867955019, reward: -33.0,-11.0)\n",
      "Episode 255400/300000 ( TD_error: 0.11815591636821576, reward: -10.0,-10.0)\n",
      "Episode 255500/300000 ( TD_error: 16.373189564543523, reward: 15.0,14.0)\n",
      "Episode 255600/300000 ( TD_error: -1.1808637606390704, reward: -12.0,13.0)\n",
      "Episode 255700/300000 ( TD_error: 0.1292749330553935, reward: -10.0,-16.0)\n",
      "Episode 255800/300000 ( TD_error: 1.144921669732092, reward: -38.0,-18.0)\n",
      "Episode 255900/300000 ( TD_error: 0.9962637372743051, reward: 10.0,-16.0)\n",
      "Episode 256000/300000 ( TD_error: 0.5328516996626096, reward: 5.0,-15.0)\n",
      "Episode 256100/300000 ( TD_error: 0.6413080671183158, reward: 14.0,6.0)\n",
      "Episode 256200/300000 ( TD_error: -5.257392173600449, reward: -10.0,-60.0)\n",
      "Episode 256300/300000 ( TD_error: 0.27288285979241067, reward: 8.0,9.0)\n",
      "Episode 256400/300000 ( TD_error: 0.049790246952203354, reward: -10.0,14.0)\n",
      "Episode 256500/300000 ( TD_error: 0.22542326286466308, reward: 4.0,6.0)\n",
      "Episode 256600/300000 ( TD_error: 0.7538385415117581, reward: -12.0,-44.0)\n",
      "Episode 256700/300000 ( TD_error: 0.7872906739880428, reward: 4.0,11.0)\n",
      "Episode 256800/300000 ( TD_error: 0.038928625351164925, reward: -10.0,-10.0)\n",
      "Episode 256900/300000 ( TD_error: -0.4939081207605014, reward: -30.0,9.0)\n",
      "Episode 257000/300000 ( TD_error: 1.0569010690272809, reward: 11.0,-10.0)\n",
      "Episode 257100/300000 ( TD_error: 0.7238865571024853, reward: 5.0,12.0)\n",
      "Episode 257200/300000 ( TD_error: 0.8876601713452974, reward: 12.0,14.0)\n",
      "Episode 257300/300000 ( TD_error: 1.3137869862762277, reward: 7.0,-10.0)\n",
      "Episode 257400/300000 ( TD_error: -9.819018991160616, reward: -10.0,-10.0)\n",
      "Episode 257500/300000 ( TD_error: 1.4612023100386402, reward: -12.0,-15.0)\n",
      "Episode 257600/300000 ( TD_error: 0.7598047300429944, reward: 4.0,-11.0)\n",
      "Episode 257700/300000 ( TD_error: 1.3541812485963494, reward: -24.0,-14.0)\n",
      "Episode 257800/300000 ( TD_error: 0.6287397055640369, reward: 12.0,15.0)\n",
      "Episode 257900/300000 ( TD_error: -0.04821278082249503, reward: -10.0,12.0)\n",
      "Episode 258000/300000 ( TD_error: 1.0556326179188074, reward: 13.0,-10.0)\n",
      "Episode 258100/300000 ( TD_error: -0.2063835642329348, reward: -20.0,13.0)\n",
      "Episode 258200/300000 ( TD_error: -2.5170901448203757, reward: -27.0,4.0)\n",
      "Episode 258300/300000 ( TD_error: 0.6339799315543528, reward: 8.0,-38.0)\n",
      "Episode 258400/300000 ( TD_error: -0.7372297209836027, reward: -11.0,3.0)\n",
      "Episode 258500/300000 ( TD_error: 0.7816271609122936, reward: -17.0,-13.0)\n",
      "Episode 258600/300000 ( TD_error: 0.6360917975104527, reward: 15.0,-11.0)\n",
      "Episode 258700/300000 ( TD_error: -0.237633272156744, reward: -52.0,14.0)\n",
      "Episode 258800/300000 ( TD_error: 0.4657116911465966, reward: -19.0,9.0)\n",
      "Episode 258900/300000 ( TD_error: 0.7001094075850531, reward: 4.0,15.0)\n",
      "Episode 259000/300000 ( TD_error: 0.6983682844799066, reward: 15.0,-16.0)\n",
      "Episode 259100/300000 ( TD_error: -9.795620376273003, reward: -10.0,-15.0)\n",
      "Episode 259200/300000 ( TD_error: -10.26300673868763, reward: -10.0,13.0)\n",
      "Episode 259300/300000 ( TD_error: 1.3583052237429214, reward: 14.0,-9.0)\n",
      "Episode 259400/300000 ( TD_error: -0.6677111510493017, reward: -17.0,14.0)\n",
      "Episode 259500/300000 ( TD_error: 0.7131926817755088, reward: 7.0,14.0)\n",
      "Episode 259600/300000 ( TD_error: 0.5058854558889285, reward: 6.0,7.0)\n",
      "Episode 259700/300000 ( TD_error: 0.4990464883049128, reward: 13.0,12.0)\n",
      "Episode 259800/300000 ( TD_error: 0.3045552712681623, reward: 15.0,-2.0)\n",
      "Episode 259900/300000 ( TD_error: 0.3175742654185485, reward: 13.0,-10.0)\n",
      "Episode 260000/300000 ( TD_error: -10.269040354781731, reward: -10.0,-14.0)\n",
      "Episode 260100/300000 ( TD_error: -0.047484176425808045, reward: -38.0,-10.0)\n",
      "Episode 260200/300000 ( TD_error: 0.061380169770569815, reward: -10.0,7.0)\n",
      "Episode 260300/300000 ( TD_error: -1.850034539136745, reward: -10.0,-12.0)\n",
      "Episode 260400/300000 ( TD_error: 0.2507369163004207, reward: 10.0,15.0)\n",
      "Episode 260500/300000 ( TD_error: -0.4922368223524227, reward: -10.0,-10.0)\n",
      "Episode 260600/300000 ( TD_error: 4.057185555227507, reward: -10.0,-10.0)\n",
      "Episode 260700/300000 ( TD_error: 0.3571672641036314, reward: 13.0,7.0)\n",
      "Episode 260800/300000 ( TD_error: -0.44748963987120405, reward: -14.0,3.0)\n",
      "Episode 260900/300000 ( TD_error: 0.26059720078054704, reward: 6.0,11.0)\n",
      "Episode 261000/300000 ( TD_error: 0.2817341783207943, reward: 5.0,-17.0)\n",
      "Episode 261100/300000 ( TD_error: 0.2960317467204252, reward: 9.0,-13.0)\n",
      "Episode 261200/300000 ( TD_error: 0.21980209866323897, reward: 0.0,-10.0)\n",
      "Episode 261300/300000 ( TD_error: 0.16000338489573274, reward: 14.0,12.0)\n",
      "Episode 261400/300000 ( TD_error: 4.2362959072743624, reward: -10.0,-15.0)\n",
      "Episode 261500/300000 ( TD_error: 0.5104210371794045, reward: 6.0,-47.0)\n",
      "Episode 261600/300000 ( TD_error: 0.4326695946587704, reward: 15.0,-10.0)\n",
      "Episode 261700/300000 ( TD_error: 0.4186734217832262, reward: 6.0,-10.0)\n",
      "Episode 261800/300000 ( TD_error: 0.3662938184764153, reward: 13.0,7.0)\n",
      "Episode 261900/300000 ( TD_error: -0.725175517685658, reward: -29.0,-25.0)\n",
      "Episode 262000/300000 ( TD_error: 0.258999135416893, reward: 10.0,7.0)\n",
      "Episode 262100/300000 ( TD_error: -1.018927630231186, reward: -10.0,-10.0)\n",
      "Episode 262200/300000 ( TD_error: -0.16963266495610796, reward: -10.0,-22.0)\n",
      "Episode 262300/300000 ( TD_error: 0.35740022017562545, reward: 13.0,-10.0)\n",
      "Episode 262400/300000 ( TD_error: 0.22890842842993475, reward: 8.0,14.0)\n",
      "Episode 262500/300000 ( TD_error: -4.2058428480292545, reward: -10.0,13.0)\n",
      "Episode 262600/300000 ( TD_error: 2.0005576960696176, reward: 15.0,5.0)\n",
      "Episode 262700/300000 ( TD_error: 0.5530408961981674, reward: 4.0,-16.0)\n",
      "Episode 262800/300000 ( TD_error: -0.31802500061926864, reward: -11.0,-10.0)\n",
      "Episode 262900/300000 ( TD_error: 16.35077204072416, reward: 15.0,-11.0)\n",
      "Episode 263000/300000 ( TD_error: 1.0171948711707244, reward: 12.0,3.0)\n",
      "Episode 263100/300000 ( TD_error: 0.3707461741822753, reward: 12.0,-17.0)\n",
      "Episode 263200/300000 ( TD_error: -0.8920823596038545, reward: -113.0,-10.0)\n",
      "Episode 263300/300000 ( TD_error: 0.5583242696410888, reward: 5.0,8.0)\n",
      "Episode 263400/300000 ( TD_error: 0.7181644184339624, reward: 14.0,-13.0)\n",
      "Episode 263500/300000 ( TD_error: 1.0057849817905362, reward: 8.0,-13.0)\n",
      "Episode 263600/300000 ( TD_error: -0.7090624467206315, reward: -30.0,15.0)\n",
      "Episode 263700/300000 ( TD_error: 0.8304994937699264, reward: 14.0,11.0)\n",
      "Episode 263800/300000 ( TD_error: 1.102171614003181, reward: 14.0,-12.0)\n",
      "Episode 263900/300000 ( TD_error: 1.1649544857973275, reward: 15.0,-15.0)\n",
      "Episode 264000/300000 ( TD_error: 0.5369917866595122, reward: 8.0,-21.0)\n",
      "Episode 264100/300000 ( TD_error: 0.4916652475448853, reward: -10.0,-11.0)\n",
      "Episode 264200/300000 ( TD_error: 0.9392670507836907, reward: 15.0,10.0)\n",
      "Episode 264300/300000 ( TD_error: 0.9479270697390065, reward: 9.0,1.0)\n",
      "Episode 264400/300000 ( TD_error: 1.1864433145289657, reward: 15.0,12.0)\n",
      "Episode 264500/300000 ( TD_error: 1.2163827125552702, reward: 9.0,15.0)\n",
      "Episode 264600/300000 ( TD_error: -0.9536452904592334, reward: -14.0,-30.0)\n",
      "Episode 264700/300000 ( TD_error: 1.0456418614246932, reward: 13.0,-13.0)\n",
      "Episode 264800/300000 ( TD_error: 0.6776049614393678, reward: -18.0,13.0)\n",
      "Episode 264900/300000 ( TD_error: 1.0385735772139224, reward: -14.0,14.0)\n",
      "Episode 265000/300000 ( TD_error: 0.9741863175940892, reward: 5.0,-10.0)\n",
      "Episode 265100/300000 ( TD_error: 0.7847860451140245, reward: 15.0,-41.0)\n",
      "Episode 265200/300000 ( TD_error: 0.5256405477180057, reward: 12.0,-31.0)\n",
      "Episode 265300/300000 ( TD_error: -0.8428876355716106, reward: -11.0,15.0)\n",
      "Episode 265400/300000 ( TD_error: 1.1168634947701865, reward: 6.0,9.0)\n",
      "Episode 265500/300000 ( TD_error: 0.7167409265788462, reward: 3.0,-14.0)\n",
      "Episode 265600/300000 ( TD_error: 0.4925363714605009, reward: -10.0,-10.0)\n",
      "Episode 265700/300000 ( TD_error: 0.40638063527148294, reward: 8.0,13.0)\n",
      "Episode 265800/300000 ( TD_error: 2.037166239691812, reward: -10.0,7.0)\n",
      "Episode 265900/300000 ( TD_error: 0.3769450998435433, reward: 5.0,15.0)\n",
      "Episode 266000/300000 ( TD_error: -9.776218343797508, reward: -10.0,-10.0)\n",
      "Episode 266100/300000 ( TD_error: 0.31316789011901225, reward: 2.0,6.0)\n",
      "Episode 266200/300000 ( TD_error: 0.5638775536453391, reward: 6.0,14.0)\n",
      "Episode 266300/300000 ( TD_error: 0.3532817074191561, reward: 1.0,14.0)\n",
      "Episode 266400/300000 ( TD_error: 0.2948423508765776, reward: 10.0,6.0)\n",
      "Episode 266500/300000 ( TD_error: 0.41411992400691267, reward: 8.0,13.0)\n",
      "Episode 266600/300000 ( TD_error: -10.151446524415157, reward: -10.0,10.0)\n",
      "Episode 266700/300000 ( TD_error: 0.34149157647945794, reward: 8.0,8.0)\n",
      "Episode 266800/300000 ( TD_error: 0.27788921965306335, reward: 8.0,-11.0)\n",
      "Episode 266900/300000 ( TD_error: 0.3533023938119553, reward: 15.0,-10.0)\n",
      "Episode 267000/300000 ( TD_error: 0.3078492796623373, reward: -7.0,-10.0)\n",
      "Episode 267100/300000 ( TD_error: 0.2719088887821819, reward: 3.0,15.0)\n",
      "Episode 267200/300000 ( TD_error: -10.169293865271836, reward: -10.0,13.0)\n",
      "Episode 267300/300000 ( TD_error: 0.2283992742068408, reward: 15.0,-16.0)\n",
      "Episode 267400/300000 ( TD_error: -0.13748680949759873, reward: -52.0,-14.0)\n",
      "Episode 267500/300000 ( TD_error: -9.784707252318254, reward: -10.0,10.0)\n",
      "Episode 267600/300000 ( TD_error: 0.2499068375994562, reward: -8.0,-10.0)\n",
      "Episode 267700/300000 ( TD_error: 1.8733499314446753, reward: -48.0,-21.0)\n",
      "Episode 267800/300000 ( TD_error: -1.0596017844703312, reward: -14.0,15.0)\n",
      "Episode 267900/300000 ( TD_error: 0.36035124869481594, reward: 8.0,7.0)\n",
      "Episode 268000/300000 ( TD_error: -0.2989001533368718, reward: -10.0,-16.0)\n",
      "Episode 268100/300000 ( TD_error: -0.8654504613066791, reward: -32.0,-17.0)\n",
      "Episode 268200/300000 ( TD_error: 1.5807117077405746, reward: 14.0,6.0)\n",
      "Episode 268300/300000 ( TD_error: -0.4375571939289493, reward: -13.0,-58.0)\n",
      "Episode 268400/300000 ( TD_error: 0.7453531514957592, reward: 15.0,-13.0)\n",
      "Episode 268500/300000 ( TD_error: 0.4104596200633486, reward: 12.0,9.0)\n",
      "Episode 268600/300000 ( TD_error: -0.2398204097285621, reward: -10.0,13.0)\n",
      "Episode 268700/300000 ( TD_error: 0.5875528419573177, reward: 7.0,15.0)\n",
      "Episode 268800/300000 ( TD_error: 0.9353785195617812, reward: 15.0,15.0)\n",
      "Episode 268900/300000 ( TD_error: 0.6021212664787572, reward: -2.0,4.0)\n",
      "Episode 269000/300000 ( TD_error: 1.1344953609012514, reward: -14.0,6.0)\n",
      "Episode 269100/300000 ( TD_error: 1.1472485132542884, reward: 8.0,11.0)\n",
      "Episode 269200/300000 ( TD_error: 0.8836605458212814, reward: 7.0,-10.0)\n",
      "Episode 269300/300000 ( TD_error: -0.021823877378160716, reward: -11.0,15.0)\n",
      "Episode 269400/300000 ( TD_error: 1.6466112427376078, reward: 15.0,-13.0)\n",
      "Episode 269500/300000 ( TD_error: 0.6195732646290102, reward: -11.0,13.0)\n",
      "Episode 269600/300000 ( TD_error: 1.587953521978678, reward: 12.0,-17.0)\n",
      "Episode 269700/300000 ( TD_error: 1.0581526276609283, reward: 15.0,0.0)\n",
      "Episode 269800/300000 ( TD_error: 1.135444222035174, reward: -28.0,7.0)\n",
      "Episode 269900/300000 ( TD_error: -0.09337674325587564, reward: -15.0,3.0)\n",
      "Episode 270000/300000 ( TD_error: 0.7132923741532249, reward: 14.0,-13.0)\n",
      "Episode 270100/300000 ( TD_error: 0.9222567284550394, reward: -12.0,-10.0)\n",
      "Episode 270200/300000 ( TD_error: -0.04410649761594598, reward: -10.0,9.0)\n",
      "Episode 270300/300000 ( TD_error: 1.2850689562040993, reward: 7.0,-10.0)\n",
      "Episode 270400/300000 ( TD_error: 0.5180089651948592, reward: 9.0,-17.0)\n",
      "Episode 270500/300000 ( TD_error: 0.39590804197223095, reward: 4.0,10.0)\n",
      "Episode 270600/300000 ( TD_error: -0.9038739740334449, reward: -18.0,13.0)\n",
      "Episode 270700/300000 ( TD_error: 0.7217006896817244, reward: 5.0,13.0)\n",
      "Episode 270800/300000 ( TD_error: 0.9457873048417564, reward: 8.0,12.0)\n",
      "Episode 270900/300000 ( TD_error: -10.20564031318525, reward: -10.0,-23.0)\n",
      "Episode 271000/300000 ( TD_error: 0.743755412281601, reward: -20.0,-26.0)\n",
      "Episode 271100/300000 ( TD_error: 0.4270530982239831, reward: 10.0,9.0)\n",
      "Episode 271200/300000 ( TD_error: 0.2795634631502253, reward: 14.0,9.0)\n",
      "Episode 271300/300000 ( TD_error: 0.26843210379339055, reward: 14.0,15.0)\n",
      "Episode 271400/300000 ( TD_error: -3.9389655060075146, reward: -10.0,10.0)\n",
      "Episode 271500/300000 ( TD_error: 0.25330045128005185, reward: 9.0,15.0)\n",
      "Episode 271600/300000 ( TD_error: -2.745403827352666, reward: -12.0,-11.0)\n",
      "Episode 271700/300000 ( TD_error: -9.78269210513079, reward: -10.0,6.0)\n",
      "Episode 271800/300000 ( TD_error: 0.2080923579283791, reward: 14.0,-18.0)\n",
      "Episode 271900/300000 ( TD_error: 0.19912924554449862, reward: 8.0,13.0)\n",
      "Episode 272000/300000 ( TD_error: -9.779221156789525, reward: -10.0,15.0)\n",
      "Episode 272100/300000 ( TD_error: 0.41470681510090746, reward: 2.0,-14.0)\n",
      "Episode 272200/300000 ( TD_error: -0.05139223757221956, reward: -21.0,13.0)\n",
      "Episode 272300/300000 ( TD_error: 1.0869774552662883, reward: 15.0,-10.0)\n",
      "Episode 272400/300000 ( TD_error: 0.9113138757269375, reward: 7.0,-29.0)\n",
      "Episode 272500/300000 ( TD_error: -2.2951791057943467, reward: -11.0,6.0)\n",
      "Episode 272600/300000 ( TD_error: 0.7444017786001091, reward: 15.0,3.0)\n",
      "Episode 272700/300000 ( TD_error: -2.2854719759131736, reward: -10.0,8.0)\n",
      "Episode 272800/300000 ( TD_error: -0.512434583057459, reward: -24.0,8.0)\n",
      "Episode 272900/300000 ( TD_error: 0.3759422908701513, reward: 9.0,12.0)\n",
      "Episode 273000/300000 ( TD_error: 0.6170202181869469, reward: 15.0,4.0)\n",
      "Episode 273100/300000 ( TD_error: -0.6604538077851156, reward: -56.0,-11.0)\n",
      "Episode 273200/300000 ( TD_error: 0.9573820603365037, reward: 7.0,13.0)\n",
      "Episode 273300/300000 ( TD_error: 0.854802492990903, reward: 9.0,13.0)\n",
      "Episode 273400/300000 ( TD_error: -7.611026570184867, reward: -10.0,1.0)\n",
      "Episode 273500/300000 ( TD_error: 0.8189325751951202, reward: 12.0,8.0)\n",
      "Episode 273600/300000 ( TD_error: 1.170656044122971, reward: 13.0,-10.0)\n",
      "Episode 273700/300000 ( TD_error: 0.7988629694779772, reward: 15.0,-14.0)\n",
      "Episode 273800/300000 ( TD_error: 0.47937632901663996, reward: 4.0,-41.0)\n",
      "Episode 273900/300000 ( TD_error: 0.7004081565230651, reward: 6.0,13.0)\n",
      "Episode 274000/300000 ( TD_error: 1.1500185195004453, reward: 14.0,-22.0)\n",
      "Episode 274100/300000 ( TD_error: -0.08145850396714138, reward: -10.0,-2.0)\n",
      "Episode 274200/300000 ( TD_error: 0.8598909615051682, reward: 8.0,8.0)\n",
      "Episode 274300/300000 ( TD_error: 0.589860721824091, reward: 9.0,-13.0)\n",
      "Episode 274400/300000 ( TD_error: -0.7031951139440942, reward: -15.0,5.0)\n",
      "Episode 274500/300000 ( TD_error: 0.5213867944565038, reward: 15.0,7.0)\n",
      "Episode 274600/300000 ( TD_error: 5.680558405169068, reward: -10.0,-21.0)\n",
      "Episode 274700/300000 ( TD_error: 0.32983522606118143, reward: 8.0,13.0)\n",
      "Episode 274800/300000 ( TD_error: -1.339257631054247, reward: -10.0,13.0)\n",
      "Episode 274900/300000 ( TD_error: 0.33017320474878176, reward: 7.0,6.0)\n",
      "Episode 275000/300000 ( TD_error: -10.240332208614015, reward: -10.0,-14.0)\n",
      "Episode 275100/300000 ( TD_error: -0.9486547414330762, reward: -16.0,15.0)\n",
      "Episode 275200/300000 ( TD_error: 1.1848646889805827, reward: 12.0,15.0)\n",
      "Episode 275300/300000 ( TD_error: 0.7520836220156442, reward: 11.0,-13.0)\n",
      "Episode 275400/300000 ( TD_error: 0.8873576581944245, reward: 5.0,11.0)\n",
      "Episode 275500/300000 ( TD_error: -0.841056636349995, reward: -10.0,15.0)\n",
      "Episode 275600/300000 ( TD_error: 0.732047910850901, reward: 9.0,-14.0)\n",
      "Episode 275700/300000 ( TD_error: -0.6468037864648561, reward: -11.0,-10.0)\n",
      "Episode 275800/300000 ( TD_error: 0.38238782822159534, reward: 13.0,14.0)\n",
      "Episode 275900/300000 ( TD_error: -0.512888016083572, reward: -17.0,2.0)\n",
      "Episode 276000/300000 ( TD_error: 1.0618615960254587, reward: 3.0,-14.0)\n",
      "Episode 276100/300000 ( TD_error: 0.9135346983463375, reward: 9.0,14.0)\n",
      "Episode 276200/300000 ( TD_error: 0.33346700071045987, reward: 15.0,13.0)\n",
      "Episode 276300/300000 ( TD_error: 0.45330254869162623, reward: 12.0,-1.0)\n",
      "Episode 276400/300000 ( TD_error: 0.557227102884676, reward: 2.0,-19.0)\n",
      "Episode 276500/300000 ( TD_error: 0.32414337522218384, reward: 7.0,11.0)\n",
      "Episode 276600/300000 ( TD_error: -0.3517672548131401, reward: -33.0,-10.0)\n",
      "Episode 276700/300000 ( TD_error: 0.2869612230171654, reward: 2.0,-14.0)\n",
      "Episode 276800/300000 ( TD_error: 5.175603808190793, reward: -10.0,13.0)\n",
      "Episode 276900/300000 ( TD_error: 1.007151954616786, reward: -11.0,15.0)\n",
      "Episode 277000/300000 ( TD_error: 3.02892849592293, reward: -10.0,9.0)\n",
      "Episode 277100/300000 ( TD_error: 0.49783389317606286, reward: -13.0,-53.0)\n",
      "Episode 277200/300000 ( TD_error: 0.3034155855478149, reward: 11.0,15.0)\n",
      "Episode 277300/300000 ( TD_error: 0.5973289962786015, reward: 6.0,6.0)\n",
      "Episode 277400/300000 ( TD_error: 0.2704091363613461, reward: 12.0,-10.0)\n",
      "Episode 277500/300000 ( TD_error: 0.33610740814826734, reward: 10.0,13.0)\n",
      "Episode 277600/300000 ( TD_error: 0.28644132352552454, reward: 7.0,10.0)\n",
      "Episode 277700/300000 ( TD_error: 0.3919247156945702, reward: 7.0,15.0)\n",
      "Episode 277800/300000 ( TD_error: 0.7761104446546749, reward: -14.0,6.0)\n",
      "Episode 277900/300000 ( TD_error: 0.20897229521104954, reward: 10.0,14.0)\n",
      "Episode 278000/300000 ( TD_error: 0.1642608231143834, reward: 10.0,15.0)\n",
      "Episode 278100/300000 ( TD_error: 0.21749559090533221, reward: 5.0,13.0)\n",
      "Episode 278200/300000 ( TD_error: 0.20747535035892728, reward: 8.0,13.0)\n",
      "Episode 278300/300000 ( TD_error: 0.19578852651712442, reward: 13.0,-10.0)\n",
      "Episode 278400/300000 ( TD_error: 0.16355305674816734, reward: 1.0,14.0)\n",
      "Episode 278500/300000 ( TD_error: -0.23130301657164765, reward: -58.0,-23.0)\n",
      "Episode 278600/300000 ( TD_error: 0.19363148752659765, reward: 10.0,7.0)\n",
      "Episode 278700/300000 ( TD_error: -0.6010408883338716, reward: -13.0,6.0)\n",
      "Episode 278800/300000 ( TD_error: 0.3670788291091025, reward: 11.0,4.0)\n",
      "Episode 278900/300000 ( TD_error: 0.3251073209608095, reward: 11.0,-15.0)\n",
      "Episode 279000/300000 ( TD_error: -10.276227016752063, reward: -10.0,-10.0)\n",
      "Episode 279100/300000 ( TD_error: 0.1919339497887691, reward: 3.0,-10.0)\n",
      "Episode 279200/300000 ( TD_error: -0.92465323189721, reward: -13.0,1.0)\n",
      "Episode 279300/300000 ( TD_error: 0.17804788288000584, reward: 7.0,-10.0)\n",
      "Episode 279400/300000 ( TD_error: 0.26222143215833826, reward: 14.0,-14.0)\n",
      "Episode 279500/300000 ( TD_error: 0.1528208459542708, reward: 5.0,14.0)\n",
      "Episode 279600/300000 ( TD_error: 0.8272901520764422, reward: 13.0,9.0)\n",
      "Episode 279700/300000 ( TD_error: 0.6845206277043232, reward: -12.0,6.0)\n",
      "Episode 279800/300000 ( TD_error: 1.053265043634638, reward: 14.0,-5.0)\n",
      "Episode 279900/300000 ( TD_error: -0.9474094953706658, reward: -12.0,-16.0)\n",
      "Episode 280000/300000 ( TD_error: 0.7133586397105516, reward: 4.0,3.0)\n",
      "Episode 280100/300000 ( TD_error: -0.04014723487942007, reward: -28.0,-11.0)\n",
      "Episode 280200/300000 ( TD_error: -0.9628140165303094, reward: -14.0,15.0)\n",
      "Episode 280300/300000 ( TD_error: 0.8047794670817716, reward: 15.0,-14.0)\n",
      "Episode 280400/300000 ( TD_error: 1.3006124361374416, reward: 8.0,-12.0)\n",
      "Episode 280500/300000 ( TD_error: -10.27203173981348, reward: -10.0,8.0)\n",
      "Episode 280600/300000 ( TD_error: 1.371475894833412, reward: 8.0,13.0)\n",
      "Episode 280700/300000 ( TD_error: 1.3389989176259265, reward: 7.0,-10.0)\n",
      "Episode 280800/300000 ( TD_error: 0.997913989463417, reward: 2.0,15.0)\n",
      "Episode 280900/300000 ( TD_error: 1.0239702077794524, reward: 5.0,-11.0)\n",
      "Episode 281000/300000 ( TD_error: 0.4419546511377681, reward: 13.0,-20.0)\n",
      "Episode 281100/300000 ( TD_error: 0.7703201183800532, reward: 14.0,-7.0)\n",
      "Episode 281200/300000 ( TD_error: -10.28044705325845, reward: -10.0,-10.0)\n",
      "Episode 281300/300000 ( TD_error: -0.9282183259232291, reward: -17.0,6.0)\n",
      "Episode 281400/300000 ( TD_error: 1.1165775306745649, reward: 8.0,15.0)\n",
      "Episode 281500/300000 ( TD_error: -0.008725212441626162, reward: -10.0,11.0)\n",
      "Episode 281600/300000 ( TD_error: -0.12918537834043953, reward: -17.0,10.0)\n",
      "Episode 281700/300000 ( TD_error: 0.8100723322458203, reward: 8.0,-14.0)\n",
      "Episode 281800/300000 ( TD_error: 0.91658401725292, reward: 14.0,9.0)\n",
      "Episode 281900/300000 ( TD_error: 0.9611920155524134, reward: 10.0,8.0)\n",
      "Episode 282000/300000 ( TD_error: -0.6713794250992109, reward: -39.0,15.0)\n",
      "Episode 282100/300000 ( TD_error: -1.7507160764839185, reward: -10.0,4.0)\n",
      "Episode 282200/300000 ( TD_error: -0.3125673660048367, reward: -24.0,15.0)\n",
      "Episode 282300/300000 ( TD_error: 0.4233500648558941, reward: 7.0,8.0)\n",
      "Episode 282400/300000 ( TD_error: 8.221751587817373, reward: 15.0,-11.0)\n",
      "Episode 282500/300000 ( TD_error: 0.5223784904619526, reward: 15.0,13.0)\n",
      "Episode 282600/300000 ( TD_error: -9.770585250209738, reward: -10.0,11.0)\n",
      "Episode 282700/300000 ( TD_error: 0.4964714376447703, reward: 13.0,-90.0)\n",
      "Episode 282800/300000 ( TD_error: -1.8958415221632166, reward: -11.0,-10.0)\n",
      "Episode 282900/300000 ( TD_error: 2.7776484236392385, reward: -10.0,15.0)\n",
      "Episode 283000/300000 ( TD_error: 1.534659768403161, reward: 14.0,13.0)\n",
      "Episode 283100/300000 ( TD_error: 1.1385453390205882, reward: -14.0,-10.0)\n",
      "Episode 283200/300000 ( TD_error: -1.0221942568905398, reward: -12.0,7.0)\n",
      "Episode 283300/300000 ( TD_error: 1.1427842189525372, reward: 14.0,7.0)\n",
      "Episode 283400/300000 ( TD_error: -0.06334695915953859, reward: -10.0,14.0)\n",
      "Episode 283500/300000 ( TD_error: -10.245042433045096, reward: -10.0,-19.0)\n",
      "Episode 283600/300000 ( TD_error: -9.770172576855941, reward: -10.0,-21.0)\n",
      "Episode 283700/300000 ( TD_error: -9.767420065617756, reward: -10.0,10.0)\n",
      "Episode 283800/300000 ( TD_error: 0.5700640117377134, reward: 12.0,9.0)\n",
      "Episode 283900/300000 ( TD_error: 1.094264873137321, reward: 14.0,14.0)\n",
      "Episode 284000/300000 ( TD_error: 1.4336621487846344, reward: 10.0,5.0)\n",
      "Episode 284100/300000 ( TD_error: -0.056247461325158454, reward: -10.0,6.0)\n",
      "Episode 284200/300000 ( TD_error: -0.1836025698195911, reward: -17.0,6.0)\n",
      "Episode 284300/300000 ( TD_error: 0.7122536690574668, reward: 5.0,5.0)\n",
      "Episode 284400/300000 ( TD_error: -1.1096479134401882, reward: -13.0,-10.0)\n",
      "Episode 284500/300000 ( TD_error: -0.451426684867112, reward: -13.0,14.0)\n",
      "Episode 284600/300000 ( TD_error: -1.0441211855415098, reward: -17.0,14.0)\n",
      "Episode 284700/300000 ( TD_error: -2.2156425456797804, reward: -20.0,15.0)\n",
      "Episode 284800/300000 ( TD_error: -2.1722961694537144, reward: -32.0,14.0)\n",
      "Episode 284900/300000 ( TD_error: 1.0473545975950231, reward: 3.0,13.0)\n",
      "Episode 285000/300000 ( TD_error: 0.694690079084693, reward: 4.0,7.0)\n",
      "Episode 285100/300000 ( TD_error: 0.40664950505661146, reward: 14.0,13.0)\n",
      "Episode 285200/300000 ( TD_error: -0.6493741614635162, reward: -18.0,11.0)\n",
      "Episode 285300/300000 ( TD_error: -0.532855566567866, reward: -14.0,8.0)\n",
      "Episode 285400/300000 ( TD_error: 0.32139658206507615, reward: 12.0,-11.0)\n",
      "Episode 285500/300000 ( TD_error: -0.9004884129396018, reward: -10.0,1.0)\n",
      "Episode 285600/300000 ( TD_error: -0.1995597483769913, reward: -12.0,1.0)\n",
      "Episode 285700/300000 ( TD_error: -0.2150635837707746, reward: -10.0,-10.0)\n",
      "Episode 285800/300000 ( TD_error: 0.020855622497670367, reward: -14.0,14.0)\n",
      "Episode 285900/300000 ( TD_error: 0.7861200542380122, reward: 14.0,9.0)\n",
      "Episode 286000/300000 ( TD_error: -0.09796130653660384, reward: -15.0,8.0)\n",
      "Episode 286100/300000 ( TD_error: -0.8075473638303432, reward: -11.0,3.0)\n",
      "Episode 286200/300000 ( TD_error: -1.1007261109243256, reward: -12.0,12.0)\n",
      "Episode 286300/300000 ( TD_error: 0.30030839343504123, reward: 11.0,15.0)\n",
      "Episode 286400/300000 ( TD_error: 0.32216262627364367, reward: 4.0,-10.0)\n",
      "Episode 286500/300000 ( TD_error: -10.258944473633301, reward: -10.0,-28.0)\n",
      "Episode 286600/300000 ( TD_error: -2.9344452639365244, reward: -10.0,-10.0)\n",
      "Episode 286700/300000 ( TD_error: 0.5680490010376502, reward: 8.0,11.0)\n",
      "Episode 286800/300000 ( TD_error: 0.92399835692787, reward: 14.0,7.0)\n",
      "Episode 286900/300000 ( TD_error: -1.9250633186825148, reward: -14.0,10.0)\n",
      "Episode 287000/300000 ( TD_error: 0.6350817093630288, reward: 14.0,4.0)\n",
      "Episode 287100/300000 ( TD_error: -9.754491299109267, reward: -10.0,13.0)\n",
      "Episode 287200/300000 ( TD_error: -0.4937509478385884, reward: -10.0,10.0)\n",
      "Episode 287300/300000 ( TD_error: 0.3937929660164685, reward: 7.0,3.0)\n",
      "Episode 287400/300000 ( TD_error: -0.5795070000275935, reward: -15.0,13.0)\n",
      "Episode 287500/300000 ( TD_error: 1.2550295906483266, reward: 14.0,8.0)\n",
      "Episode 287600/300000 ( TD_error: -1.0019317725531636, reward: -10.0,13.0)\n",
      "Episode 287700/300000 ( TD_error: 1.6474216141063116, reward: 8.0,-10.0)\n",
      "Episode 287800/300000 ( TD_error: 1.7191250650225298, reward: 13.0,-30.0)\n",
      "Episode 287900/300000 ( TD_error: 1.7203917928708874, reward: 14.0,12.0)\n",
      "Episode 288000/300000 ( TD_error: -10.257718273730049, reward: -10.0,-19.0)\n",
      "Episode 288100/300000 ( TD_error: 1.0282735049265859, reward: 14.0,5.0)\n",
      "Episode 288200/300000 ( TD_error: 1.0697731221007678, reward: 13.0,-10.0)\n",
      "Episode 288300/300000 ( TD_error: -0.10265423472673962, reward: -10.0,13.0)\n",
      "Episode 288400/300000 ( TD_error: 0.5802319562166756, reward: 15.0,-11.0)\n",
      "Episode 288500/300000 ( TD_error: -10.267336969926596, reward: -10.0,6.0)\n",
      "Episode 288600/300000 ( TD_error: 1.5278296166533707, reward: -24.0,15.0)\n",
      "Episode 288700/300000 ( TD_error: 0.8740998560906283, reward: 6.0,-10.0)\n",
      "Episode 288800/300000 ( TD_error: 0.9683684359817519, reward: 5.0,10.0)\n",
      "Episode 288900/300000 ( TD_error: 1.4148417972650282, reward: 9.0,-19.0)\n",
      "Episode 289000/300000 ( TD_error: -0.8349258805856064, reward: -15.0,-20.0)\n",
      "Episode 289100/300000 ( TD_error: 1.1468370065064692, reward: 14.0,15.0)\n",
      "Episode 289200/300000 ( TD_error: 1.0952099196721021, reward: 12.0,-10.0)\n",
      "Episode 289300/300000 ( TD_error: 0.6614708273485439, reward: 9.0,-10.0)\n",
      "Episode 289400/300000 ( TD_error: 1.1641291462798868, reward: -19.0,12.0)\n",
      "Episode 289500/300000 ( TD_error: -0.8582363335235694, reward: -19.0,-11.0)\n",
      "Episode 289600/300000 ( TD_error: 0.038405566503762145, reward: -10.0,-10.0)\n",
      "Episode 289700/300000 ( TD_error: 1.2615918902537753, reward: 2.0,14.0)\n",
      "Episode 289800/300000 ( TD_error: 1.304142473336949, reward: 13.0,-39.0)\n",
      "Episode 289900/300000 ( TD_error: 1.2260047569953465, reward: 13.0,8.0)\n",
      "Episode 290000/300000 ( TD_error: -0.8685092327969102, reward: -12.0,14.0)\n",
      "Episode 290100/300000 ( TD_error: -0.48840270073086245, reward: -13.0,14.0)\n",
      "Episode 290200/300000 ( TD_error: 0.998699198125955, reward: 8.0,1.0)\n",
      "Episode 290300/300000 ( TD_error: -7.195324948611831, reward: -10.0,-10.0)\n",
      "Episode 290400/300000 ( TD_error: 0.320182664476067, reward: 15.0,-10.0)\n",
      "Episode 290500/300000 ( TD_error: 0.00015841210290190588, reward: -33.0,-33.0)\n",
      "Episode 290600/300000 ( TD_error: 0.21129262377483293, reward: -13.0,7.0)\n",
      "Episode 290700/300000 ( TD_error: -0.05524156875307895, reward: -17.0,3.0)\n",
      "Episode 290800/300000 ( TD_error: 0.5150317305030887, reward: 10.0,-14.0)\n",
      "Episode 290900/300000 ( TD_error: -0.10457014109019624, reward: -12.0,-10.0)\n",
      "Episode 291000/300000 ( TD_error: 0.5044135725168051, reward: 6.0,11.0)\n",
      "Episode 291100/300000 ( TD_error: -10.21747066044421, reward: -10.0,15.0)\n",
      "Episode 291200/300000 ( TD_error: 0.5333153088846778, reward: 7.0,-12.0)\n",
      "Episode 291300/300000 ( TD_error: 0.367884523906179, reward: -12.0,-10.0)\n",
      "Episode 291400/300000 ( TD_error: 0.8277767146125887, reward: 11.0,-11.0)\n",
      "Episode 291500/300000 ( TD_error: 0.3679735794628223, reward: 10.0,9.0)\n",
      "Episode 291600/300000 ( TD_error: 0.33095207575137886, reward: 8.0,-19.0)\n",
      "Episode 291700/300000 ( TD_error: 0.2965076576042667, reward: 7.0,12.0)\n",
      "Episode 291800/300000 ( TD_error: 1.1022408837485138, reward: 15.0,-10.0)\n",
      "Episode 291900/300000 ( TD_error: -0.904005609382116, reward: -12.0,-20.0)\n",
      "Episode 292000/300000 ( TD_error: 0.7382725737118738, reward: 5.0,-10.0)\n",
      "Episode 292100/300000 ( TD_error: 0.6897271266857463, reward: 11.0,6.0)\n",
      "Episode 292200/300000 ( TD_error: 0.6128202278268482, reward: -37.0,-11.0)\n",
      "Episode 292300/300000 ( TD_error: 0.9387642251397228, reward: 15.0,-10.0)\n",
      "Episode 292400/300000 ( TD_error: -0.7000422266665147, reward: -56.0,15.0)\n",
      "Episode 292500/300000 ( TD_error: 0.35279258021715343, reward: -14.0,3.0)\n",
      "Episode 292600/300000 ( TD_error: 0.8506572457105568, reward: 13.0,11.0)\n",
      "Episode 292700/300000 ( TD_error: -0.5850861987522151, reward: -12.0,14.0)\n",
      "Episode 292800/300000 ( TD_error: 0.5337448731183105, reward: 11.0,8.0)\n",
      "Episode 292900/300000 ( TD_error: -0.5461530482551282, reward: -18.0,-12.0)\n",
      "Episode 293000/300000 ( TD_error: 0.4889918933708213, reward: 13.0,6.0)\n",
      "Episode 293100/300000 ( TD_error: -0.3276070849571564, reward: -27.0,-13.0)\n",
      "Episode 293200/300000 ( TD_error: 0.3262994667348882, reward: 9.0,9.0)\n",
      "Episode 293300/300000 ( TD_error: 0.2398171691026616, reward: 7.0,-14.0)\n",
      "Episode 293400/300000 ( TD_error: 0.2470203907308175, reward: 14.0,7.0)\n",
      "Episode 293500/300000 ( TD_error: -0.5813546974693224, reward: -11.0,14.0)\n",
      "Episode 293600/300000 ( TD_error: 0.16772138140479242, reward: 9.0,-10.0)\n",
      "Episode 293700/300000 ( TD_error: -0.164792391082055, reward: -10.0,-28.0)\n",
      "Episode 293800/300000 ( TD_error: -1.0262395102702477, reward: -12.0,7.0)\n",
      "Episode 293900/300000 ( TD_error: -2.017775145227475, reward: -18.0,7.0)\n",
      "Episode 294000/300000 ( TD_error: 0.5655560195184046, reward: -23.0,15.0)\n",
      "Episode 294100/300000 ( TD_error: 0.036084552802048364, reward: -25.0,3.0)\n",
      "Episode 294200/300000 ( TD_error: 0.23402721851046682, reward: 13.0,7.0)\n",
      "Episode 294300/300000 ( TD_error: 0.23755671332201844, reward: 8.0,7.0)\n",
      "Episode 294400/300000 ( TD_error: 0.17673591572640124, reward: 9.0,15.0)\n",
      "Episode 294500/300000 ( TD_error: 0.27051574475591034, reward: 8.0,8.0)\n",
      "Episode 294600/300000 ( TD_error: 0.27925255124789095, reward: 7.0,12.0)\n",
      "Episode 294700/300000 ( TD_error: 0.20465230217903185, reward: 10.0,-13.0)\n",
      "Episode 294800/300000 ( TD_error: -0.4987239159154715, reward: -13.0,5.0)\n",
      "Episode 294900/300000 ( TD_error: 0.4557499632580715, reward: 4.0,-10.0)\n",
      "Episode 295000/300000 ( TD_error: 0.6232900028318085, reward: 6.0,14.0)\n",
      "Episode 295100/300000 ( TD_error: 0.5441734412381702, reward: 8.0,1.0)\n",
      "Episode 295200/300000 ( TD_error: 0.5847294796266036, reward: 0.0,7.0)\n",
      "Episode 295300/300000 ( TD_error: 0.5489911644999919, reward: 8.0,8.0)\n",
      "Episode 295400/300000 ( TD_error: 1.6747509423046962, reward: 15.0,14.0)\n",
      "Episode 295500/300000 ( TD_error: 0.7930251225391944, reward: 9.0,7.0)\n",
      "Episode 295600/300000 ( TD_error: -0.11901646625644258, reward: -10.0,14.0)\n",
      "Episode 295700/300000 ( TD_error: 0.28528985559605324, reward: -18.0,-10.0)\n",
      "Episode 295800/300000 ( TD_error: -10.224745580549788, reward: -10.0,-10.0)\n",
      "Episode 295900/300000 ( TD_error: -9.7245708463156, reward: -10.0,3.0)\n",
      "Episode 296000/300000 ( TD_error: 0.055920579309498564, reward: -10.0,7.0)\n",
      "Episode 296100/300000 ( TD_error: 0.44849384949880733, reward: 5.0,-17.0)\n",
      "Episode 296200/300000 ( TD_error: 0.351473070510115, reward: 14.0,-28.0)\n",
      "Episode 296300/300000 ( TD_error: 0.3523174066917272, reward: 10.0,-30.0)\n",
      "Episode 296400/300000 ( TD_error: 0.18213513356477495, reward: 12.0,10.0)\n",
      "Episode 296500/300000 ( TD_error: 2.040144410308436, reward: 15.0,-19.0)\n",
      "Episode 296600/300000 ( TD_error: -0.38044218962617116, reward: -13.0,8.0)\n",
      "Episode 296700/300000 ( TD_error: -0.058538110143008915, reward: -10.0,-17.0)\n",
      "Episode 296800/300000 ( TD_error: -0.386707256374196, reward: -27.0,13.0)\n",
      "Episode 296900/300000 ( TD_error: 0.29829152787169155, reward: 8.0,-10.0)\n",
      "Episode 297000/300000 ( TD_error: 0.29832653474883175, reward: 14.0,2.0)\n",
      "Episode 297100/300000 ( TD_error: 0.23891527553411773, reward: 8.0,3.0)\n",
      "Episode 297200/300000 ( TD_error: 1.326896773905125, reward: 12.0,-11.0)\n",
      "Episode 297300/300000 ( TD_error: -0.680177904434327, reward: -15.0,-34.0)\n",
      "Episode 297400/300000 ( TD_error: 1.1781370735839762, reward: 11.0,5.0)\n",
      "Episode 297500/300000 ( TD_error: 1.0576094730882213, reward: 14.0,-22.0)\n",
      "Episode 297600/300000 ( TD_error: 1.0880280247048517, reward: 5.0,-10.0)\n",
      "Episode 297700/300000 ( TD_error: 1.2339431095736644, reward: 13.0,14.0)\n",
      "Episode 297800/300000 ( TD_error: 0.9619038721782494, reward: 11.0,14.0)\n",
      "Episode 297900/300000 ( TD_error: 1.4428798238542568, reward: 10.0,7.0)\n",
      "Episode 298000/300000 ( TD_error: 1.0962079773894713, reward: 8.0,12.0)\n",
      "Episode 298100/300000 ( TD_error: 1.3128364660575862, reward: 13.0,-12.0)\n",
      "Episode 298200/300000 ( TD_error: 0.6155218540420258, reward: 5.0,-14.0)\n",
      "Episode 298300/300000 ( TD_error: 0.5726612608819881, reward: 11.0,11.0)\n",
      "Episode 298400/300000 ( TD_error: -2.7386285640387857, reward: -14.0,10.0)\n",
      "Episode 298500/300000 ( TD_error: 0.7721269576149745, reward: 1.0,-37.0)\n",
      "Episode 298600/300000 ( TD_error: 0.9499298027849836, reward: 9.0,7.0)\n",
      "Episode 298700/300000 ( TD_error: -0.5424843180031456, reward: -15.0,14.0)\n",
      "Episode 298800/300000 ( TD_error: 1.8388065683064392, reward: 14.0,3.0)\n",
      "Episode 298900/300000 ( TD_error: 1.1692869024997106, reward: 10.0,-11.0)\n",
      "Episode 299000/300000 ( TD_error: 0.5555404918938645, reward: 15.0,13.0)\n",
      "Episode 299100/300000 ( TD_error: 0.326738232432894, reward: 6.0,15.0)\n",
      "Episode 299200/300000 ( TD_error: 1.6496363929432398, reward: 8.0,13.0)\n",
      "Episode 299300/300000 ( TD_error: 1.0226260381783172, reward: 5.0,6.0)\n",
      "Episode 299400/300000 ( TD_error: 1.189743348285162, reward: 14.0,-10.0)\n",
      "Episode 299500/300000 ( TD_error: 0.41391692005220326, reward: 2.0,-10.0)\n",
      "Episode 299600/300000 ( TD_error: 0.494493056384969, reward: 15.0,-12.0)\n",
      "Episode 299700/300000 ( TD_error: 0.3560987156888453, reward: 13.0,7.0)\n",
      "Episode 299800/300000 ( TD_error: 0.37979715207515685, reward: 9.0,-10.0)\n",
      "Episode 299900/300000 ( TD_error: 0.4151539774315367, reward: -19.0,14.0)\n"
     ]
    }
   ],
   "source": [
    "agent = ApproxQLearningAgent(action_space_n=env.action_n)\n",
    "\n",
    "agent.RUN(env, num_episodes=300000, episode_len=20000)\n",
    "# agent.RUN(env, num_episodes=10000, episode_len=2000)\n",
    "# num_episodes=1000, episode_len=2000  3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ [-6.986939871948687, -6.017987442664804, -12.82130229356874, -15.729371773779, -8.144584422024948] [-14.948476303672813, -5.435374676388051, -15.046405535585489, -6.820336250706031, -5.893941972127547] [-13.010697800374354, -4.895237975595911, -13.458164004250266, -7.682371150952827, -7.060598082205252] [-4.376187793479181, -4.978496690306164, -13.44546824929856, -5.358084965153643, -5.625881222719211] [-5.940826814161074, -13.499279334034895, -10.158272267571544, -4.6915123850517855, -8.736422456323695] ]\n",
      "[ [-10.871187747831273, -14.717985181560973, -6.619929242410411, -15.829675754589314, -7.972361619192998] [-7.870913434087603, -10.468485332732818, -5.559513287558136, -7.107411645213768, -10.46519223393127] [-7.283500686032866, -3.788601511111757, -3.994608392552353, -18.820609890696183, -14.56444103242526] [-5.538732867013346, -3.796469289323062, -4.476612544271437, -12.669542554741229, -4.556986414494121] [-3.190148796275834, -12.689474754339427, -4.703767319849864, -3.9887782743205054, -5.326830048489611] ]\n",
      "[ [-15.068079936456439, -12.746282825771804, -7.359648899150434, -17.937013135534425, -7.623335980658533] [-11.352424360063054, -7.969661011500367, -12.50372356919312, -14.51143076342217, -8.151096708996393] [-8.434112204900416, -12.386526526340017, -6.658761497891401, -5.716868089487036, 2.242629706380777] [-12.007561298262177, -4.7764565745495124, -5.139104740132716, -5.461237957803372, -4.581350844762903] [-2.5007413675459005, -11.657343369061563, -2.731213570471361, -3.452547725287407, -5.349604956255932] ]\n",
      "[ [-8.385868560059624, -8.868191852671602, -10.952258655909022, -17.376198821589444, -8.642400064243557] [-10.610793717370703, 2.056881119355395, -7.009069183980371, -6.774294200417474, -9.374033815703125] [-13.587914323782941, -13.99263714439523, -13.879931395858039, -13.894370446060472, -14.000360291063247] [-0.9214728191062617, -0.9159400002528783, -5.369001398051497, -5.88564453998827, -8.897118231696396] [-1.4211401158145125, -11.731408675287337, -4.777518451989271, -11.683200335984147, -1.9937535340468986] ]\n",
      "[ [-16.478659515872987, -12.035952210441357, -8.910386013116582, -17.250469699043965, -8.211799241510601] [-10.516727706335955, -5.929449632476624, -10.394893681922827, -2.9489190683587507, -2.8722487720673837] [-8.606268426329162, -1.2161117627292457, 1.714947518648767, -10.572358948913587, 1.2459052523257654] [-7.505065315543743, 0.4272143742699023, -9.648353608889057, 0.6097781376093887, -3.127074435355607] [-9.599848315344008, -9.482393891976924, -2.975491022950294, -0.5186854964624908, -1.1944137310458494] ]\n"
     ]
    }
   ],
   "source": [
    "for y in range(env.height):\n",
    "    for x in range(env.width):\n",
    "        agent.policy_improvement((y, x))\n",
    "\n",
    "Q = defaultdict(lambda: [0 for _ in range(agent.action_space_n)])\n",
    "for y in range(env.height):\n",
    "    for x in range(env.width):\n",
    "        for action in range(agent.action_space_n):\n",
    "            state = (y,x)\n",
    "            Q[state][action] = agent.estimate_q(state, action)\n",
    "print_by_dict(env, Q)\n",
    "\n",
    "# ISSUE:  X ,  y, q  ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ [0.02 0.92 0.02 0.02 0.02] [0.02 0.92 0.02 0.02 0.02] [0.02 0.92 0.02 0.02 0.02] [0.92 0.02 0.02 0.02 0.02] [0.02 0.02 0.02 0.92 0.02] ]\n",
      "[ [0.02 0.02 0.92 0.02 0.02] [0.02 0.02 0.92 0.02 0.02] [0.02 0.92 0.02 0.02 0.02] [0.02 0.92 0.02 0.02 0.02] [0.92 0.02 0.02 0.02 0.02] ]\n",
      "[ [0.02 0.02 0.92 0.02 0.02] [0.02 0.92 0.02 0.02 0.02] [0.02 0.02 0.02 0.02 0.92] [0.02 0.02 0.02 0.02 0.92] [0.92 0.02 0.02 0.02 0.02] ]\n",
      "[ [0.92 0.02 0.02 0.02 0.02] [0.02 0.92 0.02 0.02 0.02] [0.92 0.02 0.02 0.02 0.02] [0.02 0.92 0.02 0.02 0.02] [0.92 0.02 0.02 0.02 0.02] ]\n",
      "[ [0.02 0.02 0.02 0.02 0.92] [0.02 0.02 0.02 0.02 0.92] [0.02 0.02 0.92 0.02 0.02] [0.02 0.02 0.02 0.92 0.02] [0.02 0.02 0.02 0.92 0.02] ]\n",
      "\n",
      "[-8.05089112e+00  8.71125293e-01 -1.90221208e-01 -2.45791418e-01\n",
      " -1.52533256e+00 -1.92655068e+00  6.36564159e-01 -5.50471144e-01\n",
      " -3.06418769e-01 -5.58078027e-01  9.33336930e-01  7.94355503e-01\n",
      "  1.17180668e+00  9.12374136e-01  2.71454508e-01 -9.16038572e-01\n",
      " -8.59285976e-01  3.11263543e-01  2.14833366e+00 -1.26950317e-01\n",
      " -1.22969249e+00 -1.81030302e-01 -3.79548417e-01 -6.95671595e-01\n",
      " -1.64566558e+00 -5.30375266e-01  6.73127663e-01  1.01373572e+00\n",
      "  8.93151617e-02 -7.79010627e-01  3.44448207e-01 -2.72035526e-01\n",
      "  1.51772388e-01  2.08128494e-01  2.26556614e-01 -6.22622771e-03\n",
      "  7.78633897e-01  5.36103626e-01 -4.43223632e-01 -5.68955369e-01\n",
      "  6.62584043e-01  2.12262239e-01  1.01627300e-01 -8.59946263e-01\n",
      "  3.69869449e-01  1.75494515e-01 -7.62203174e-01 -1.15317449e-02\n",
      "  9.38639591e-01 -2.36678997e-01  5.24128000e-02 -4.74458830e-01\n",
      "  3.46614740e-01 -4.40213096e-01 -4.02893346e-04  4.75655288e-01\n",
      "  1.18182967e-01 -6.13501291e-01 -2.10224545e-01 -1.22317145e-01\n",
      "  2.57328431e-01  2.09382568e+00  2.58494978e-01  7.79041513e-01\n",
      " -5.96779258e-01 -8.32306532e-01  2.24359232e-01  8.17506200e-01\n",
      " -4.01780580e-01 -6.60924909e-01 -6.75581372e-01 -1.22189914e+00\n",
      "  7.41616263e-01  2.41711419e-01  1.41253810e+00  6.65321619e-01\n",
      " -1.41606733e+00  6.02116862e-01 -6.78053504e-01 -6.49769083e-01\n",
      " -1.68092998e-01  5.02019203e-01 -6.44059485e-01  4.20970077e-01\n",
      " -5.44250306e-02 -1.35750159e+00 -1.61323148e-01  1.45786456e-01\n",
      "  3.12802811e-01  4.32048628e-01  3.73658579e-01  4.74992966e-01\n",
      " -6.01523264e-01 -4.37791533e-01  2.69747456e-01  5.23891801e-01\n",
      "  6.46321110e-01 -4.44127127e-01 -3.98696144e-01  5.32849140e-02\n",
      " -1.02227547e+00  7.62627910e-01  6.16141021e-01 -5.42401107e-01\n",
      "  1.13851872e-01  1.05474852e+00  2.16261902e-01 -9.13762756e-01\n",
      " -9.79653488e-01  3.11828668e-01  1.95349289e+00 -3.95014358e-01\n",
      "  1.79104663e-01 -1.43644798e-01 -1.01655171e-01 -1.70547627e-01\n",
      "  2.32377376e-01  3.38149759e-01  9.43082689e-01 -1.29929571e-01\n",
      " -5.37887519e-01  8.76995767e-01  2.86768934e-01  1.56425323e-01\n",
      " -7.47543879e-01]\n",
      "[ 0.00 0.00 0.00 0.00 0.00 ]\n",
      "[ 0.00 -10.00 -10.00 0.00 0.00 ]\n",
      "[ 0.00 0.00 -10.00 0.00 0.00 ]\n",
      "[ 0.00 -10.00 15.00 -10.00 0.00 ]\n",
      "[ 0.00 -10.00 0.00 0.00 0.00 ]\n",
      "\n",
      "[                ]\n",
      "[                ]\n",
      "[                ]\n",
      "[                ]\n",
      "[                ]\n"
     ]
    }
   ],
   "source": [
    "print_by_dict(env, agent.policy)\n",
    "print()\n",
    "print(agent.parameters)\n",
    "\n",
    "print(env)\n",
    "for i in range(env.height):\n",
    "    print(\"[\", end=\" \")\n",
    "    for j in range(env.width):\n",
    "        state = (i, j)\n",
    "        action = agent.get_action(state, optimal=True)\n",
    "        print(env.action_mappings[action], end=\" \")\n",
    "    print(\"]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
