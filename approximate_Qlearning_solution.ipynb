{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload \n",
    "# %aimport rl_envs.grid_world_env\n",
    "\n",
    "%autoreload 2\n",
    "import math\n",
    "from torch.utils.tensorboard import SummaryWriter # type: ignore\n",
    "\n",
    "from agents.approx_Q_Learning import ApproxQLearningAgent\n",
    "from tools.helper import *\n",
    "import  gymnasium  as gym\n",
    "from rl_envs.new_gym_grid_world_env import GridWorldEnv\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCOUNTED_FACTOR = 0.999\n",
    "FORBIDDEN_REWARD = -10\n",
    "HITWALL_REWARD = -10\n",
    "TARGET_REWARD = 1\n",
    "NORMAL_REWARD = 0\n",
    "\n",
    "SEED = 666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridWorldEnv(\n",
    "    size=3,\n",
    "    fixed_map=True,\n",
    "    forbidden_grids=[(1, 1), (1, 2)],\n",
    "    target_grids=[(2, 2)],\n",
    "    forbidden_reward=FORBIDDEN_REWARD,\n",
    "    hit_wall_reward=HITWALL_REWARD,\n",
    "    target_reward=TARGET_REWARD,\n",
    "    normal_reward=NORMAL_REWARD,\n",
    ")\n",
    "# env = GridWorldEnv(fixed_map = True, forbidden_grids=[(1,1),(1,2), (2,2),(3,1),(3,3),(4,1)], target_grids=[(3,2)], forbidden_reward=FORBIDDEN_REWARD, hit_wall_reward=HITWALL_REWARD, target_reward=TARGET_REWARD, normal_reward=NORMAL_REWARD)\n",
    "agent = ApproxQLearningAgent(action_space_n=env.action_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.RUN(env, num_episodes=1000, episode_len=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env)\n",
    "print_by_dict(env, agent.policy)\n",
    "print()\n",
    "print(agent.parameters)\n",
    "\n",
    "for i in range(env.height):\n",
    "    print(\"[\", end=\" \")\n",
    "    for j in range(env.width):\n",
    "        state = (i, j)\n",
    "        action = agent.get_action(state, optimal=True)\n",
    "        print(env.action_mappings[action], end=\" \")\n",
    "    print(\"]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
